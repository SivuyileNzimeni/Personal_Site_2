---
title: "Spam Emails"
lang: "en-GB"
date: "August 18,2023"
author: "Sivuyile Nzimeni"
image: "./Spam_Detection.png"
image-alt: "An image illustrating an email folder classified as either spam or not."
description: "This post is about building a classification model for spam email detection. We explore a solution for handling an imbalanced dataset." 
categories: [data modelling,data cleaning,visualisation]
fig-dpi: 300
fig-align: 'center'
fig-cap-location: 'top'
code-copy: true
code-line-numbers: true
page-layout: 'article'
cap-location: 'margin'
number-sections: true
toc: true
lot: true
lof: true
toc-title: 'CONTENTS'
execute: 
  echo: true
  warning: false
  message: false
---

# INTRODUCTION

The [TidyTuesday](https://github.com/rfordatascience/tidytuesday) project is a weekly social data project. Each week an interesting dataset is shared with the community for members to clean, model and or visualise data. People are encouraged to share their code and posts through social media. In essence, it serves as good avenue to explore one's data skills and to learn with others. This week (2023/08/14), the dataset is comprised of spam and non-spam emails originating from [UCI Machine Learning Repository](http://archive.ics.uci.edu/dataset/94/spambase).

## IMPORT DATA

```{r Libraries}
#| message: false
#| warning: false
#| include: true

lapply(c("tidyverse","janitor","ggthemes",
         "glmnet","tidymodels","vip","ranger",
         "themis","gt","gtExtras"),
       require,character.only = TRUE) |> 
  suppressWarnings() |> 
  suppressMessages() |> 
  invisible() # <1>

Emails <- read.csv(file = "https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-15/spam.csv") |> 
  clean_names() # <2>

theme_set(theme_minimal()) # <3>
set.seed(2023)
```

1.  We load our preferred R packages. This style of loading packages is not standard. It helps to silence some of the messages and conflict warnings when loading meta packages such as `tidyverse` and `tidymodels`.

2.  We import data from the tidytuesday github repository. Again, the use of `read.csv` in place of `read_csv` or other functions boils down to preference.

3.  The `theme_set` function lets us select a theme for our visualisations.

We also import a number of auxilary packages to assist in the analysis. The imported data is relatively small only comprising of 4601 rows and 7 columns. Our outcome variable is `yesno`,i.e. Spam/Not Spam email. The remaining variables contains derived variables, frequency counts. These are essentials tallies of references to money, currency and exclamation marks (oddly named `bang`). The dataset presents a classification problem. We start by scaling the numeric variables.

```{r Data_Preprocessing}
#| label: Scale Numeric Variables
#| include: true
#| echo: true

Emails[,-grep("yesno",names(Emails))] <-  sapply(Emails[,sapply(Emails,is.numeric)],
       function(x){
         scale(x,center = TRUE,scale = TRUE) 
       }) # <1>
```

1.  Use `<-` as your separator between the right-hand-side and the left-hand-side of the code. On the left-hand-side, we select all variables except the target variable except the outcome variable. On the right-hand-side, we use a nested `sapply` function to subset only for predictor variables. Thereafter, we subset columns that are of type numeric. Finally, we call an anonymous function via `function(x)` and pass each variable through then scale function.

It appears convoluted. However, it completes a set of sub-setting and applies functions simultaneously. It is better practice to first define a function and sapply.

## DATA SPLITTING

Part of the data splitting involves some decisions about whether to stratify the outcome variable. Especially with an imbalanced dataset, it is important to have sufficient representation of the minority cases without leaking the outcomes in the training process. Next, we can do some data splitting into a training and testing set, stratified over the outcome variable. The `rsample` package serves a set of convenient function for the task. The majority of emails (60.56%) are not spam.

```{r Data_Prep}
#| label: Data Splitting

Data_Split <- initial_split(Emails,strata=yesno)
Data_Train <- training(Data_Split)
Data_Test <- testing(Data_Split)

100/nrow(Data_Train)*table(Data_Train$yesno)
```

## MODEL FITTING

To

```{r GLMNET}
X_Train <- model.matrix(yesno ~.,data =Data_Train)[,-1]
Y_Train <- as.numeric(Data_Train$yesno=="y")


Ranger_Model <- ranger(x=X_Train,
       y = Y_Train,
       verbose = TRUE,
       importance = "impurity",
       splitrule = "gini",
       seed = 2023,
       classification = TRUE)

Ranger_Model$confusion.matrix 
```

```{r Elastic_Model_Fitting}
Elastic_Net <- cv.glmnet(x=X_Train,
                      y=Y_Train,
                      alpha =0,
                      family = "binomial",
                      nfolds = 10,
                      type.measure = "class")
```

```{r Train_Performance}
Training_Performance <- assess.glmnet(Elastic_Net,
              newx=X_Train,
              newy=Y_Train)

Final_Model <- glmnet(x=X_Train,
                      y = Y_Train,
                      lambda = min(Elastic_Net$lambda),
                      alpha = 0,
                      family = "binomial",
                      standardize = FALSE)


Training_Performance <- data.frame(lapply(Training_Performance,unlist))

rownames(Training_Performance) <- NULL

Training_Performance |> 
  gt() |> 
  tab_header(title = "2023 Initial ElasticNet Model",
             subtitle = "Training Model Performance") |> 
  gt_theme_espn()
```

# REBALANCING OUTCOME

```{r New_Recipes}
Data_Clean <- recipe(yesno ~.,data = Data_Train) |> 
  themis::step_bsmote(yesno,
                      over_ratio=0.8) |> 
  prep() |> 
  bake(new_data = NULL) 

x_train <- model.matrix(yesno ~.,data = Data_Clean)[,-1]
y_train <- Data_Clean$yesno

Elastic_Upsampled <- cv.glmnet(x=x_train,
          y=y_train,
          alpha = 0,
          family="binomial",
          standardize = FALSE,
          nfolds=10)


Trained_Performance_2 <- assess.glmnet(Elastic_Upsampled,
              newx = x_train,
              newy = y_train,
              family = "binomial",
              alpha = 0,
              standardize = FALSE)
```

```{r New_Model}
Finalised_Model <- glmnet(x=x_train,
       y=y_train,
       family = "binomial",
       alpha = 0,
       standardize = FALSE,
       lambda = Elastic_Upsampled$lambda.min)
```

```{r Compare_Performance}
X_Test <- model.matrix(yesno ~.,data =Data_Test)[,-1]
Y_Test <- as.numeric(Data_Test$yesno=="y")


Final_Prediction <- predict(Final_Model,as.matrix(Data_Test[,-grep("\\byesno\\b",
                           names(Data_Test))]),
        type = "class") |> 
  as.data.frame() |> 
  mutate(.pred_class = ifelse(s0 == "0","y","n")) |> 
  select(-s0) |> 
  mutate(across(everything(),
                .fns=\(x){factor(x,
                                 level = c("n","y"))}))


Final_Prediction_2 <- predict(Finalised_Model,
        as.matrix(Data_Test[,-grep("\\byesno\\b",
                                   names(Data_Test))]),
        type = "class") |> 
  as.data.frame() |> 
  mutate(.pred_class = ifelse(s0 == "0","y","n")) |> 
  select(-s0) |> 
  mutate(across(everything(),
                .fns=\(x){factor(x,
                                 level = c("n","y"))})) 


Final_Prediction$truth <- Data_Test$yesno
Final_Prediction_2$truth <- Data_Test$yesno

Final_Prediction <- Final_Prediction |> 
  mutate(across(everything(),
                .fns=\(x){factor(x,
                                 level = c("n","y"))}))


Final_Prediction_2 <- Final_Prediction_2 |> 
  mutate(across(everything(),
                .fns = \(x){
                  factor(x,
                         level = c("n","y"))
                }))

Final_Prediction$truth |> table();Final_Prediction_2$truth |> table()


Final_Prediction |> 
  conf_mat(truth=truth, 
           estimate = .pred_class) |> 
  autoplot()

Final_Prediction_2 |> 
  conf_mat(truth = truth,
           estimate = .pred_class) |> 
  autoplot()
```
