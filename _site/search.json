[
  {
    "objectID": "posts/2023 US Census Data/index.html",
    "href": "posts/2023 US Census Data/index.html",
    "title": "2023 Spatial Data Analysis",
    "section": "",
    "text": "see code\n#|results: hide\n#|message: false\n#|warning: false\nsource(\"2023_Prep_Data.R\",\n       local = knitr::knit_global(),\n       echo = FALSE,\n       print.eval = FALSE,\n       verbose = FALSE)\n\n\nThe tidycensus packages offers a set of functions to retrieve census and American Community Survey data. Fortunately, the package offers a wide array of options for retrieving census data and American Community Survey via the Census API. We obtain the data through the get_acs function which contains geometry data for the American Community Survey (2015 - 2019) dataset.\n\n\n\n\n\n\nPROGRESS BAR\n\n\n\n\n\nIt may be worthwhile to add an progress_bar = FALSE argument to a get_acs function call, especially, working within a RMarkdown or Quarto document. This way, one can avoid progress bar printing when the document is rendered.\n\n\n\n\n\nWith the spatial data in hand, we can explore the data more in-depth. Here, the segregation package offers a dissimilarity index function (conveniently named dissimilarity). The function returns a total segregation between a group and unit using the Index of Dissimilarity Elbers (2023) . Importantly, the dissimilarity index considers differences between two distinct groups. As the first step, we conduct dissimilarity between Hispanic and White residents in San Francisco–Oakland.\n\n\nsee code\nca_urban_data %&gt;%\n  filter(variable %in% c(\"white\", \"hispanic\"),\n         str_detect(urban_name,\"San Francisco--Oakland\"))%&gt;%\n  dissimilarity(group = \"variable\",\n                unit = \"GEOID\",\n                weight = \"estimate\")\n\n\n     stat       est\n   &lt;char&gt;     &lt;num&gt;\n1:      D 0.5135526\n\n\nTo add context on the dissimilarity index above, we can compare regional. Below, we split the data by urban name and apply the function across those groups and finally combine the outputs. The approach below is slightly different to that contained in the book. The book offers a more tidy and succinct method.\n\n\nsee code\nGroup_Wise &lt;- split(ca_urban_data,ca_urban_data$urban_name)\n\nGroup_Wise &lt;- lapply(Group_Wise,function(x){x |&gt; \n    filter(variable %in% c(\"white\",\"hispanic\"))%&gt;%\n    dissimilarity(group =\"variable\",\n                  unit = \"GEOID\",\n                  weight = \"estimate\")})\n\nGroup_Wise &lt;- do.call(bind_rows,map2(Group_Wise,names(Group_Wise),function(x,y){\n  x |&gt; \n    mutate(urban_name = y)\n}))\n\n\nAcross urban areas, Los Angeles –Long Beach, has the highest dissimilarity index at 0.599. The dissimilarity index ranges from 0 - 1 where 0 represents perfect integration between two groups and 1 represents complete segregation (Walker 2023, 215). The table below provides some context compared to our earlier dissimilarity index value for San Francisco-Oakland.\n\n\nsee code\nlibrary(gt)\nlibrary(gtExtras)\n\nGroup_Wise |&gt; \n  select(c(urban_name,stat,est)) |&gt; \n  arrange(desc(est)) |&gt; \n  gt() |&gt; \n  gt_theme_espn()\n\n\n\n\n\n\n\n\n\nurban_name\nstat\nest\n\n\n\n\nLos Angeles--Long Beach--Anaheim, CA Urbanized Area (2010)\nD\n0.5999229\n\n\nSan Francisco--Oakland, CA Urbanized Area (2010)\nD\n0.5135526\n\n\nSan Jose, CA Urbanized Area (2010)\nD\n0.4935633\n\n\nSan Diego, CA Urbanized Area (2010)\nD\n0.4898184\n\n\nRiverside--San Bernardino, CA Urbanized Area (2010)\nD\n0.4079863\n\n\nSacramento, CA Urbanized Area (2010)\nD\n0.3687927\n\n\n\n\nDissimilarity indices for Hispanic and non-Hispanic white population across California urbanised areas.\n\n\nAmong the urban areas Los Angeles and San Francisco are the most segregated areas among Hispanic and White residents. While, San-Bernardino and Sacramento had the least among of segregation. We can expand on the dissimilarity index by considering more than two groups. Again, we rely on the segregation package’s implementation of the Mutual Information Index and Theil’s Entropy Index. The latter indices measure diversity and segregation across multiple groups (Walker 2023, 217) in California urban areas.\n\n\nsee code\nmutual_within(data = ca_urban_data,\n              group = \"variable\",\n              unit = \"GEOID\",\n              weight = \"estimate\",\n              within = \"urban_name\",\n              wide = TRUE) |&gt; \n  arrange(desc(H)) |&gt; \n  gt() |&gt; \n  cols_label(\n    urban_name = \"URBAN NAME\",\n    M = \"M Index (M)\",\n    H = \"H Index (H)\",\n    p = \"Proportion of the category (p)\",\n    ent_ratio = \"Entropy Ratio\"\n  ) |&gt; \n  gt_theme_espn()\n\n\n\n\n\n\n\n\n\nURBAN NAME\nM Index (M)\nProportion of the category (p)\nH Index (H)\nEntropy Ratio\n\n\n\n\nLos Angeles--Long Beach--Anaheim, CA Urbanized Area (2010)\n0.3391033\n0.50163709\n0.2851662\n0.9693226\n\n\nSan Francisco--Oakland, CA Urbanized Area (2010)\n0.2685992\n0.13945223\n0.2116127\n1.0346590\n\n\nSan Diego, CA Urbanized Area (2010)\n0.2290891\n0.12560720\n0.2025728\n0.9218445\n\n\nSan Jose, CA Urbanized Area (2010)\n0.2147445\n0.07282785\n0.1829190\n0.9569681\n\n\nSacramento, CA Urbanized Area (2010)\n0.1658898\n0.07369482\n0.1426804\n0.9477412\n\n\nRiverside--San Bernardino, CA Urbanized Area (2010)\n0.1497129\n0.08678082\n0.1408461\n0.8664604\n\n\n\n\nSegregation and Integration across several California urban areas and racial categories\n\n\nThe results of the multi-group dissimilarity index are largely similar with Los Angeles remaining the most segregated urban area in California. Los Angeles is large area, hence, it may be worthwhile to extend to local analysis. Local analysis is a more granular approach to understanding the differences.\n\n\nsee code\nla_local_seg &lt;- ca_urban_data %&gt;%\n  filter(str_detect(urban_name,\"Los Angeles\")) %&gt;%\n  mutual_local(\n    group = \"variable\",\n    unit = \"GEOID\",\n    weight = \"estimate\",\n    wide = TRUE\n)\n\nla_tracts_seg &lt;- tracts(\"CA\", cb = TRUE, year = 2019) %&gt;%\n  inner_join(la_local_seg, by = \"GEOID\") \n\ntmap_mode(\"view\")\ntm_shape(la_tracts_seg) + \n  tm_borders(\"black\",lwd = .5)+\n  tm_polygons(\"ls\",\n              palette = \"viridis\",\n              title = \"Local\\nsegregation index\")\n\n\n\n\n\nCalifornia Area Diversity Gradient"
  },
  {
    "objectID": "posts/2023 US Census Data/index.html#exploratory-analysis-dissimilarity",
    "href": "posts/2023 US Census Data/index.html#exploratory-analysis-dissimilarity",
    "title": "2023 Spatial Data Analysis",
    "section": "",
    "text": "With the spatial data in hand, we can explore the data more in-depth. Here, the segregation package offers a dissimilarity index function (conveniently named dissimilarity). The function returns a total segregation between a group and unit using the Index of Dissimilarity Elbers (2023) . Importantly, the dissimilarity index considers differences between two distinct groups. As the first step, we conduct dissimilarity between Hispanic and White residents in San Francisco–Oakland.\n\n\nsee code\nca_urban_data %&gt;%\n  filter(variable %in% c(\"white\", \"hispanic\"),\n         str_detect(urban_name,\"San Francisco--Oakland\"))%&gt;%\n  dissimilarity(group = \"variable\",\n                unit = \"GEOID\",\n                weight = \"estimate\")\n\n\n     stat       est\n   &lt;char&gt;     &lt;num&gt;\n1:      D 0.5135526\n\n\nTo add context on the dissimilarity index above, we can compare regional. Below, we split the data by urban name and apply the function across those groups and finally combine the outputs. The approach below is slightly different to that contained in the book. The book offers a more tidy and succinct method.\n\n\nsee code\nGroup_Wise &lt;- split(ca_urban_data,ca_urban_data$urban_name)\n\nGroup_Wise &lt;- lapply(Group_Wise,function(x){x |&gt; \n    filter(variable %in% c(\"white\",\"hispanic\"))%&gt;%\n    dissimilarity(group =\"variable\",\n                  unit = \"GEOID\",\n                  weight = \"estimate\")})\n\nGroup_Wise &lt;- do.call(bind_rows,map2(Group_Wise,names(Group_Wise),function(x,y){\n  x |&gt; \n    mutate(urban_name = y)\n}))\n\n\nAcross urban areas, Los Angeles –Long Beach, has the highest dissimilarity index at 0.599. The dissimilarity index ranges from 0 - 1 where 0 represents perfect integration between two groups and 1 represents complete segregation (Walker 2023, 215). The table below provides some context compared to our earlier dissimilarity index value for San Francisco-Oakland.\n\n\nsee code\nlibrary(gt)\nlibrary(gtExtras)\n\nGroup_Wise |&gt; \n  select(c(urban_name,stat,est)) |&gt; \n  arrange(desc(est)) |&gt; \n  gt() |&gt; \n  gt_theme_espn()\n\n\n\n\n\n\n\n\n\nurban_name\nstat\nest\n\n\n\n\nLos Angeles--Long Beach--Anaheim, CA Urbanized Area (2010)\nD\n0.5999229\n\n\nSan Francisco--Oakland, CA Urbanized Area (2010)\nD\n0.5135526\n\n\nSan Jose, CA Urbanized Area (2010)\nD\n0.4935633\n\n\nSan Diego, CA Urbanized Area (2010)\nD\n0.4898184\n\n\nRiverside--San Bernardino, CA Urbanized Area (2010)\nD\n0.4079863\n\n\nSacramento, CA Urbanized Area (2010)\nD\n0.3687927\n\n\n\n\nDissimilarity indices for Hispanic and non-Hispanic white population across California urbanised areas.\n\n\nAmong the urban areas Los Angeles and San Francisco are the most segregated areas among Hispanic and White residents. While, San-Bernardino and Sacramento had the least among of segregation. We can expand on the dissimilarity index by considering more than two groups. Again, we rely on the segregation package’s implementation of the Mutual Information Index and Theil’s Entropy Index. The latter indices measure diversity and segregation across multiple groups (Walker 2023, 217) in California urban areas.\n\n\nsee code\nmutual_within(data = ca_urban_data,\n              group = \"variable\",\n              unit = \"GEOID\",\n              weight = \"estimate\",\n              within = \"urban_name\",\n              wide = TRUE) |&gt; \n  arrange(desc(H)) |&gt; \n  gt() |&gt; \n  cols_label(\n    urban_name = \"URBAN NAME\",\n    M = \"M Index (M)\",\n    H = \"H Index (H)\",\n    p = \"Proportion of the category (p)\",\n    ent_ratio = \"Entropy Ratio\"\n  ) |&gt; \n  gt_theme_espn()\n\n\n\n\n\n\n\n\n\nURBAN NAME\nM Index (M)\nProportion of the category (p)\nH Index (H)\nEntropy Ratio\n\n\n\n\nLos Angeles--Long Beach--Anaheim, CA Urbanized Area (2010)\n0.3391033\n0.50163709\n0.2851662\n0.9693226\n\n\nSan Francisco--Oakland, CA Urbanized Area (2010)\n0.2685992\n0.13945223\n0.2116127\n1.0346590\n\n\nSan Diego, CA Urbanized Area (2010)\n0.2290891\n0.12560720\n0.2025728\n0.9218445\n\n\nSan Jose, CA Urbanized Area (2010)\n0.2147445\n0.07282785\n0.1829190\n0.9569681\n\n\nSacramento, CA Urbanized Area (2010)\n0.1658898\n0.07369482\n0.1426804\n0.9477412\n\n\nRiverside--San Bernardino, CA Urbanized Area (2010)\n0.1497129\n0.08678082\n0.1408461\n0.8664604\n\n\n\n\nSegregation and Integration across several California urban areas and racial categories\n\n\nThe results of the multi-group dissimilarity index are largely similar with Los Angeles remaining the most segregated urban area in California. Los Angeles is large area, hence, it may be worthwhile to extend to local analysis. Local analysis is a more granular approach to understanding the differences.\n\n\nsee code\nla_local_seg &lt;- ca_urban_data %&gt;%\n  filter(str_detect(urban_name,\"Los Angeles\")) %&gt;%\n  mutual_local(\n    group = \"variable\",\n    unit = \"GEOID\",\n    weight = \"estimate\",\n    wide = TRUE\n)\n\nla_tracts_seg &lt;- tracts(\"CA\", cb = TRUE, year = 2019) %&gt;%\n  inner_join(la_local_seg, by = \"GEOID\") \n\ntmap_mode(\"view\")\ntm_shape(la_tracts_seg) + \n  tm_borders(\"black\",lwd = .5)+\n  tm_polygons(\"ls\",\n              palette = \"viridis\",\n              title = \"Local\\nsegregation index\")\n\n\n\n\n\nCalifornia Area Diversity Gradient"
  },
  {
    "objectID": "posts/2023 Spam Email Classification/Index.html",
    "href": "posts/2023 Spam Email Classification/Index.html",
    "title": "Spam Emails",
    "section": "",
    "text": "The TidyTuesday project is a weekly social data project. Each week an interesting dataset is shared with the community for members to clean, model and or visualise data. People are encouraged to share their code and posts through social media. In essence, it serves as good avenue to explore one’s data skills and to learn with others. This week (2023/08/14), the dataset is comprised of spam and non-spam emails originating from UCI Machine Learning Repository.\n\n\n\n\nsee code\nlapply(c(\"tidyverse\",\"janitor\",\"ggthemes\",\n         \"glmnet\",\"tidymodels\",\"vip\",\"ranger\",\n         \"themis\",\"gt\",\"gtExtras\"),\n       require,character.only = TRUE) |&gt; \n  suppressWarnings() |&gt; \n  suppressMessages() |&gt; \n1  invisible()\n\nEmails &lt;- read.csv(file = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-15/spam.csv\") |&gt; \n2  clean_names()\n\n3theme_set(theme_minimal())\nset.seed(2023)\n\n\n\n1\n\nWe load our preferred R packages. This style of loading packages is not standard. It helps to silence some of the messages and conflict warnings when loading meta packages such as tidyverse and tidymodels.\n\n2\n\nWe import data from the tidytuesday github repository. Again, the use of read.csv in place of read_csv or other functions boils down to preference.\n\n3\n\nThe theme_set function lets us select a theme for our visualisations.\n\n\n\n\nWe also import a number of auxilary packages to assist in the analysis. The imported data is relatively small only comprising of 4601 rows and 7 columns. Our outcome variable is yesno,i.e. Spam/Not Spam email. The remaining variables contains derived variables, frequency counts. These are essentials tallies of references to money, currency and exclamation marks (oddly named bang). The dataset presents a classification problem. We start by scaling the numeric variables.\n\n\nsee code\nEmails[,-grep(\"yesno\",names(Emails))] &lt;-  sapply(Emails[,sapply(Emails,is.numeric)],\n       function(x){\n         scale(x,center = TRUE,scale = TRUE) \n1       })\n\n\n\n1\n\nUse &lt;- as your separator between the right-hand-side and the left-hand-side of the code. On the left-hand-side, we select all variables except the target variable except the outcome variable. On the right-hand-side, we use a nested sapply function to subset only for predictor variables. Thereafter, we subset columns that are of type numeric. Finally, we call an anonymous function via function(x) and pass each variable through then scale function.\n\n\n\n\nIt appears convoluted. However, it completes a set of sub-setting and applies functions simultaneously. It is better practice to first define a function and sapply.\n\n\n\nPart of the data splitting involves some decisions about whether to stratify the outcome variable. Especially with an imbalanced dataset, it is important to have sufficient representation of the minority cases without leaking the outcomes in the training process. Next, we can do some data splitting into a training and testing set, stratified over the outcome variable. The rsample package serves a set of convenient function for the task. The majority of emails (60.56%) are not spam.\n\n\nsee code\nData_Split &lt;- initial_split(Emails,strata=yesno)\nData_Train &lt;- training(Data_Split)\nData_Test &lt;- testing(Data_Split)\n\n100/nrow(Data_Train)*table(Data_Train$yesno)\n\n\n\n      n       y \n60.6087 39.3913 \n\n\n\n\n\nTo\n\n\nsee code\nX_Train &lt;- model.matrix(yesno ~.,data =Data_Train)[,-1]\nY_Train &lt;- as.numeric(Data_Train$yesno==\"y\")\n\n\nRanger_Model &lt;- ranger(x=X_Train,\n       y = Y_Train,\n       verbose = TRUE,\n       importance = \"impurity\",\n       splitrule = \"gini\",\n       seed = 2023,\n       classification = TRUE)\n\nRanger_Model$confusion.matrix \n\n\n    predicted\ntrue    0    1\n   0 1974  117\n   1  296 1063\n\n\n\n\nsee code\nElastic_Net &lt;- cv.glmnet(x=X_Train,\n                      y=Y_Train,\n                      alpha =0,\n                      family = \"binomial\",\n                      nfolds = 10,\n                      type.measure = \"class\")\n\n\n\n\nsee code\nTraining_Performance &lt;- assess.glmnet(Elastic_Net,\n              newx=X_Train,\n              newy=Y_Train)\n\nFinal_Model &lt;- glmnet(x=X_Train,\n                      y = Y_Train,\n                      lambda = min(Elastic_Net$lambda),\n                      alpha = 0,\n                      family = \"binomial\",\n                      standardize = FALSE)\n\n\nTraining_Performance &lt;- data.frame(lapply(Training_Performance,unlist))\n\nrownames(Training_Performance) &lt;- NULL\n\nTraining_Performance |&gt; \n  gt() |&gt; \n  tab_header(title = \"2023 Initial ElasticNet Model\",\n             subtitle = \"Training Model Performance\") |&gt; \n  gt_theme_espn()\n\n\n\n\n\n\n\n\n2023 Initial ElasticNet Model\n\n\nTraining Model Performance\n\n\ndeviance\nclass\nauc\nmse\nmae\n\n\n\n\n0.905737\n0.1950725\n0.8945032\n0.2811664\n0.6265235"
  },
  {
    "objectID": "posts/2023 Spam Email Classification/Index.html#import-data",
    "href": "posts/2023 Spam Email Classification/Index.html#import-data",
    "title": "Spam Emails",
    "section": "",
    "text": "see code\nlapply(c(\"tidyverse\",\"janitor\",\"ggthemes\",\n         \"glmnet\",\"tidymodels\",\"vip\",\"ranger\",\n         \"themis\",\"gt\",\"gtExtras\"),\n       require,character.only = TRUE) |&gt; \n  suppressWarnings() |&gt; \n  suppressMessages() |&gt; \n1  invisible()\n\nEmails &lt;- read.csv(file = \"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-15/spam.csv\") |&gt; \n2  clean_names()\n\n3theme_set(theme_minimal())\nset.seed(2023)\n\n\n\n1\n\nWe load our preferred R packages. This style of loading packages is not standard. It helps to silence some of the messages and conflict warnings when loading meta packages such as tidyverse and tidymodels.\n\n2\n\nWe import data from the tidytuesday github repository. Again, the use of read.csv in place of read_csv or other functions boils down to preference.\n\n3\n\nThe theme_set function lets us select a theme for our visualisations.\n\n\n\n\nWe also import a number of auxilary packages to assist in the analysis. The imported data is relatively small only comprising of 4601 rows and 7 columns. Our outcome variable is yesno,i.e. Spam/Not Spam email. The remaining variables contains derived variables, frequency counts. These are essentials tallies of references to money, currency and exclamation marks (oddly named bang). The dataset presents a classification problem. We start by scaling the numeric variables.\n\n\nsee code\nEmails[,-grep(\"yesno\",names(Emails))] &lt;-  sapply(Emails[,sapply(Emails,is.numeric)],\n       function(x){\n         scale(x,center = TRUE,scale = TRUE) \n1       })\n\n\n\n1\n\nUse &lt;- as your separator between the right-hand-side and the left-hand-side of the code. On the left-hand-side, we select all variables except the target variable except the outcome variable. On the right-hand-side, we use a nested sapply function to subset only for predictor variables. Thereafter, we subset columns that are of type numeric. Finally, we call an anonymous function via function(x) and pass each variable through then scale function.\n\n\n\n\nIt appears convoluted. However, it completes a set of sub-setting and applies functions simultaneously. It is better practice to first define a function and sapply."
  },
  {
    "objectID": "posts/2023 Spam Email Classification/Index.html#data-splitting",
    "href": "posts/2023 Spam Email Classification/Index.html#data-splitting",
    "title": "Spam Emails",
    "section": "",
    "text": "Part of the data splitting involves some decisions about whether to stratify the outcome variable. Especially with an imbalanced dataset, it is important to have sufficient representation of the minority cases without leaking the outcomes in the training process. Next, we can do some data splitting into a training and testing set, stratified over the outcome variable. The rsample package serves a set of convenient function for the task. The majority of emails (60.56%) are not spam.\n\n\nsee code\nData_Split &lt;- initial_split(Emails,strata=yesno)\nData_Train &lt;- training(Data_Split)\nData_Test &lt;- testing(Data_Split)\n\n100/nrow(Data_Train)*table(Data_Train$yesno)\n\n\n\n      n       y \n60.6087 39.3913"
  },
  {
    "objectID": "posts/2023 Spam Email Classification/Index.html#model-fitting",
    "href": "posts/2023 Spam Email Classification/Index.html#model-fitting",
    "title": "Spam Emails",
    "section": "",
    "text": "To\n\n\nsee code\nX_Train &lt;- model.matrix(yesno ~.,data =Data_Train)[,-1]\nY_Train &lt;- as.numeric(Data_Train$yesno==\"y\")\n\n\nRanger_Model &lt;- ranger(x=X_Train,\n       y = Y_Train,\n       verbose = TRUE,\n       importance = \"impurity\",\n       splitrule = \"gini\",\n       seed = 2023,\n       classification = TRUE)\n\nRanger_Model$confusion.matrix \n\n\n    predicted\ntrue    0    1\n   0 1974  117\n   1  296 1063\n\n\n\n\nsee code\nElastic_Net &lt;- cv.glmnet(x=X_Train,\n                      y=Y_Train,\n                      alpha =0,\n                      family = \"binomial\",\n                      nfolds = 10,\n                      type.measure = \"class\")\n\n\n\n\nsee code\nTraining_Performance &lt;- assess.glmnet(Elastic_Net,\n              newx=X_Train,\n              newy=Y_Train)\n\nFinal_Model &lt;- glmnet(x=X_Train,\n                      y = Y_Train,\n                      lambda = min(Elastic_Net$lambda),\n                      alpha = 0,\n                      family = \"binomial\",\n                      standardize = FALSE)\n\n\nTraining_Performance &lt;- data.frame(lapply(Training_Performance,unlist))\n\nrownames(Training_Performance) &lt;- NULL\n\nTraining_Performance |&gt; \n  gt() |&gt; \n  tab_header(title = \"2023 Initial ElasticNet Model\",\n             subtitle = \"Training Model Performance\") |&gt; \n  gt_theme_espn()\n\n\n\n\n\n\n\n\n2023 Initial ElasticNet Model\n\n\nTraining Model Performance\n\n\ndeviance\nclass\nauc\nmse\nmae\n\n\n\n\n0.905737\n0.1950725\n0.8945032\n0.2811664\n0.6265235"
  },
  {
    "objectID": "posts/2022 State Capture Report 1/index.html",
    "href": "posts/2022 State Capture Report 1/index.html",
    "title": "State of Capture Commission Report Part 1: Notes",
    "section": "",
    "text": "On 14 October 2016, the previous Public Protector, Adv Thuli Mandonsela, published the State of Capture Report. The famed public sector watchdog had a reputation for holding public officials accountable. The State of Capture report was no different.\nIt documented the pervasiveness of State Capture in the Jacob Zuma administrations. The report provided prima facie evidence of State Capture, including many public officials burning desire to visit the home of the notorious Gupta Brothers.\nThe report also lent credence to the assertion of several whistleblowers that Guptas were surreptitiously influencing key public-sector decisions. Most importantly, the report led to the Commission of Inquiry into State Capture.\nIn the years since, a flurry of litigation in the peripheral of State Capture, some directly related to the topic, ensued; Jacob Zuma resigned, the Adv Thuli Mandonsela completed her term as the Public Protector and moved on to Stellenbosch University, and the Commission commenced its work.\nOn 04 January 2022, the Commission published Volume 1 of 3 of its report. The 04 January 2022 report is a continuation of the initial report from the previous Public Protector. The Commission’s report provides comprehensive detail on the allegations of State Capture, investigating claims and issuing several findings against several parties.\n\n\nThe 04 January 2022 report is the culmination of 430 hearings, 778 videos and 170 666 Affidavits and Statements, 3 171 summons issued to witness and 1 380 Requests For Information (State Capture.org.za 2022). Reading the report’s contents is important to understand the depth and breadth of the State Capture project. Beyond this, it is also important to read through the information to defend against disinformation and misinformation campaigns that may arise on social media especially considering the Bell Pottinger scandal.\n\n\n\nThis post attempts to summarise the report’s contents into layman’s language. It is also an attempt to find salient points throughout the report and ultimately to gain an in-depth understanding of the report.\nThe report opens with background information on the establishment of the Commission. It provides descriptive statistics on the work of the Commission and recounts the Commission’s mandate. The Commission heard evidence related to the following State-Owned Enterprises and Private Enterprises:\n\nSouth African Airways (SAA) and Subsidiaries\nBOSASA\nDenel\nEskom\nEstina Dairy Farm\nPRASA\nSABC\nSARS\nSSA\nTransnet.\n\nChapter 1 of the report focuses on SAA and its subsidiaries. Chapters 2, 3, and 4 focus on The New Age and its dealings with government departments and State-Owned Entities, South African Revenue Service and Public Procurement in South Africa, respectively. This post will focus on the first 140 pages of the report, with the remaining pages covered in subsequent posts.\n\n\n\nThe report is unambiguous about the entity’s state while Ms Dudu Myeni and Ms Kwinana served as board members. In short, the report asserts that SAA experienced a steady decline in quality and effectiveness. This decline is largely attributed to the tenures of Ms Myeni and Ms Kwinana. Throughout their terms, corruption and fraud were rampant at the institution. Those that opposed illegal conduct were victimised and eventually removed from their positions. The Commission also highlights failures by SAA auditors to detect fraud and corruption. The collapse also extends to SAA’s internal audit function. There was also a wholesale failure in governance within the SAA and its subsidiaries (see paragraphs 11 – 20 of the report).\nThe Commission is particularly scathing on the conduct of Ms Myeni, arguing that she created the hostile environment described above through “a mixture of negligence, incompetence and deliberate corrupt intent” to further the project of dismantling governance at the entity (see Paragraph 13 of the report).\nThe Commission also implicates several other stakeholders as enablers of Myeni’s conduct. These stakeholders include former President Jacob Zuma (see paragraph 14), former Ministers Gigaba and Brown (see paragraph 18). Finally, the Cabinet, the Executive of South Africa, is also implicated for yielding to the preferences of the President rather than the interests of State-Owned Enterprises. Ms Carolous (previous SAA Board Chair) detailed several instances where then Minister of Public Enterprises, Mr Malusi Gigaba, took steps to undermine the authority of the Board and affect the strategic outcomes of the entity. These actions include:\n\nExcluding the Board Chair from Communication\nPublicly denouncing the Board, calling them unpatriotic and incompetent\nDelaying submission of the Request for a Guarantee to Treasury\nMisleading the Board Chair about the timeline of the proposal to Treasury Pressuring SAA to close the commercially viable Mumbai route.\nAppointing Ms Dudu Myeni as Board Chair despite her poor attendance record at SAA Board Meetings. (see Paragraphs 39 – 68)\n\nThe report also reveals that Mr Siyabonga Mahlangu, then adviser to the Minister of Public Enterprises, had an unquenchable thirst to visit the Gupta household. Mr Mahlangu’s affections for the Saxonwold compound also included inviting others to the address.\nOne such invitee was then Acting Chief Executive Officer, Mr Kona. Mr Kona alleges that Mr Tony Gupta offered him a large amount of money, which he refused. At the same meeting, Mr Kona informed Mr Tony Gupta about allocating a tender to Lufthansa Consultancy. In addition, Mr Kona alleged that Mr Tony Gupta was livid about the tender allocation.\nAfter the visit, Mr Kona received a call from the Director-General of Public Enterprises, Mr Tshediso Matona. The Director-General expressed his displeasure on the tender allocation to Lufthansa Consultancy. The grievances of the Director-General were to the extent that the Department of Public Enterprises deemed it necessary to investigate the tender. The investigation found no irregularities associated with the tender. Despite the findings of the investigation, the Department of Public Enterprises refused the continuance of the tender."
  },
  {
    "objectID": "posts/2022 State Capture Report 1/index.html#reading-the-report",
    "href": "posts/2022 State Capture Report 1/index.html#reading-the-report",
    "title": "State of Capture Commission Report Part 1: Notes",
    "section": "",
    "text": "The 04 January 2022 report is the culmination of 430 hearings, 778 videos and 170 666 Affidavits and Statements, 3 171 summons issued to witness and 1 380 Requests For Information (State Capture.org.za 2022). Reading the report’s contents is important to understand the depth and breadth of the State Capture project. Beyond this, it is also important to read through the information to defend against disinformation and misinformation campaigns that may arise on social media especially considering the Bell Pottinger scandal."
  },
  {
    "objectID": "posts/2022 State Capture Report 1/index.html#notes",
    "href": "posts/2022 State Capture Report 1/index.html#notes",
    "title": "State of Capture Commission Report Part 1: Notes",
    "section": "",
    "text": "This post attempts to summarise the report’s contents into layman’s language. It is also an attempt to find salient points throughout the report and ultimately to gain an in-depth understanding of the report.\nThe report opens with background information on the establishment of the Commission. It provides descriptive statistics on the work of the Commission and recounts the Commission’s mandate. The Commission heard evidence related to the following State-Owned Enterprises and Private Enterprises:\n\nSouth African Airways (SAA) and Subsidiaries\nBOSASA\nDenel\nEskom\nEstina Dairy Farm\nPRASA\nSABC\nSARS\nSSA\nTransnet.\n\nChapter 1 of the report focuses on SAA and its subsidiaries. Chapters 2, 3, and 4 focus on The New Age and its dealings with government departments and State-Owned Entities, South African Revenue Service and Public Procurement in South Africa, respectively. This post will focus on the first 140 pages of the report, with the remaining pages covered in subsequent posts."
  },
  {
    "objectID": "posts/2022 State Capture Report 1/index.html#south-african-airways",
    "href": "posts/2022 State Capture Report 1/index.html#south-african-airways",
    "title": "State of Capture Commission Report Part 1: Notes",
    "section": "",
    "text": "The report is unambiguous about the entity’s state while Ms Dudu Myeni and Ms Kwinana served as board members. In short, the report asserts that SAA experienced a steady decline in quality and effectiveness. This decline is largely attributed to the tenures of Ms Myeni and Ms Kwinana. Throughout their terms, corruption and fraud were rampant at the institution. Those that opposed illegal conduct were victimised and eventually removed from their positions. The Commission also highlights failures by SAA auditors to detect fraud and corruption. The collapse also extends to SAA’s internal audit function. There was also a wholesale failure in governance within the SAA and its subsidiaries (see paragraphs 11 – 20 of the report).\nThe Commission is particularly scathing on the conduct of Ms Myeni, arguing that she created the hostile environment described above through “a mixture of negligence, incompetence and deliberate corrupt intent” to further the project of dismantling governance at the entity (see Paragraph 13 of the report).\nThe Commission also implicates several other stakeholders as enablers of Myeni’s conduct. These stakeholders include former President Jacob Zuma (see paragraph 14), former Ministers Gigaba and Brown (see paragraph 18). Finally, the Cabinet, the Executive of South Africa, is also implicated for yielding to the preferences of the President rather than the interests of State-Owned Enterprises. Ms Carolous (previous SAA Board Chair) detailed several instances where then Minister of Public Enterprises, Mr Malusi Gigaba, took steps to undermine the authority of the Board and affect the strategic outcomes of the entity. These actions include:\n\nExcluding the Board Chair from Communication\nPublicly denouncing the Board, calling them unpatriotic and incompetent\nDelaying submission of the Request for a Guarantee to Treasury\nMisleading the Board Chair about the timeline of the proposal to Treasury Pressuring SAA to close the commercially viable Mumbai route.\nAppointing Ms Dudu Myeni as Board Chair despite her poor attendance record at SAA Board Meetings. (see Paragraphs 39 – 68)\n\nThe report also reveals that Mr Siyabonga Mahlangu, then adviser to the Minister of Public Enterprises, had an unquenchable thirst to visit the Gupta household. Mr Mahlangu’s affections for the Saxonwold compound also included inviting others to the address.\nOne such invitee was then Acting Chief Executive Officer, Mr Kona. Mr Kona alleges that Mr Tony Gupta offered him a large amount of money, which he refused. At the same meeting, Mr Kona informed Mr Tony Gupta about allocating a tender to Lufthansa Consultancy. In addition, Mr Kona alleged that Mr Tony Gupta was livid about the tender allocation.\nAfter the visit, Mr Kona received a call from the Director-General of Public Enterprises, Mr Tshediso Matona. The Director-General expressed his displeasure on the tender allocation to Lufthansa Consultancy. The grievances of the Director-General were to the extent that the Department of Public Enterprises deemed it necessary to investigate the tender. The investigation found no irregularities associated with the tender. Despite the findings of the investigation, the Department of Public Enterprises refused the continuance of the tender."
  },
  {
    "objectID": "posts/2021 Second-Hand Cars in South Africa/Index.html",
    "href": "posts/2021 Second-Hand Cars in South Africa/Index.html",
    "title": "South African Car Prices",
    "section": "",
    "text": "South Africa has a plethora of online vehicle marketplaces. Often, their pool of vehicles for sale are usually &gt; 50 000 on a daily basis. The vehicle listings offer a vast amount of car related data. Naturally, web-scraping the data provides an opportunity to fit a Machine-Learning model and endless exploration for petrol-heads (such as myself). Nearly all the online vehicle marketplaces have restrictive Terms and Conditions deterring the use of their data for commercial purposes and bombarding of their servers through web scrapping among other restrictions. Unfortunately, this means web scraping script cannot be shared in this post as it may reveal where the data were obtained, methodology of scraping the data etc. In addition, the website of the online vehicle marketplace will not be revealed."
  },
  {
    "objectID": "posts/2021 Second-Hand Cars in South Africa/Index.html#importing-the-data",
    "href": "posts/2021 Second-Hand Cars in South Africa/Index.html#importing-the-data",
    "title": "South African Car Prices",
    "section": "IMPORTING THE DATA",
    "text": "IMPORTING THE DATA\nBelow, we import the data and use dplyr::glimpse function to see the number of columns and values. The dataset contains a few important variables including the car_name and vehicle manufacturer. It is worth noting that the car_name variable appears to a free text field where the person listing the vehicle can modify the car name to include marketing terms such as: “excellent condition”,“reduce price” etc.\n\n\nsee code\nCar_Data &lt;- read_csv(file =\"./2021-09-03_MANY_VEHICLES_Clean_Db.csv\") %&gt;% \n  clean_names()\n\nglimpse(Car_Data)\n\n\nRows: 62,196\nColumns: 10\n$ car_name             &lt;chr&gt; \"9-3 Sport 2.0 Linear Lpt\", \"S40 2.0T\", \"V40 2.0\"…\n$ vehicle_manufacturer &lt;chr&gt; \"Saab\", \"Volvo\", \"Volvo\", \"Hyundai\", \"Volvo\", \"Ho…\n$ year                 &lt;dbl&gt; 2007, 1999, 2001, 2000, 2000, 1998, 1996, 1996, 2…\n$ mileage              &lt;dbl&gt; 200000, 285000, 271000, 125000, 190000, 267000, 1…\n$ price                &lt;dbl&gt; 13700, 18900, 18900, 20000, 20900, 21900, 21900, …\n$ fuel_type            &lt;chr&gt; \"Petrol\", \"Petrol\", \"Petrol\", \"Petrol\", \"Petrol\",…\n$ transmission         &lt;chr&gt; \"Manual\", \"Manual\", \"Manual\", \"Manual\", \"Automati…\n$ dealership           &lt;chr&gt; \"Mahala Motors\", \"WeBuyCars Midstream\", \"WeBuyCar…\n$ city_town            &lt;chr&gt; \"Klerksdorp\", \"Centurion\", \"Cape Town\", \"Johannes…\n$ province             &lt;chr&gt; \"North West Province\", \"Gauteng\", \"Western Cape\",…\n\n\nSimilarly, the free text field, also means that vehicle naming conventions deviate from the vehicle manufacturer specifications. Other text variables also contain these anomalous changes in text. The code below demonstrates an example of idiosyncrasies.\n\n\nsee code\nCar_Data %&gt;% \n  filter(str_detect(car_name,\"condition\"))\n\n\n# A tibble: 4 × 10\n  car_name      vehicle_manufacturer  year mileage  price fuel_type transmission\n  &lt;chr&gt;         &lt;chr&gt;                &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       \n1 Focus Excell… Ford                  2008  305000  69950 Petrol    Manual      \n2 Utility 1.4 … Chevrolet             2015  198000 114900 Petrol    Manual      \n3 Clio Excelle… Renault               2019   55000 160000 Petrol    Manual      \n4 Ranger Excel… Ford                  2017  107000 299900 Diesel    Automatic   \n# ℹ 3 more variables: dealership &lt;chr&gt;, city_town &lt;chr&gt;, province &lt;chr&gt;"
  },
  {
    "objectID": "posts/2021 Second-Hand Cars in South Africa/Index.html#data-preprocessing",
    "href": "posts/2021 Second-Hand Cars in South Africa/Index.html#data-preprocessing",
    "title": "South African Car Prices",
    "section": "DATA PREPROCESSING",
    "text": "DATA PREPROCESSING\nWe would like to fit a model to better understand the determinants of vehicle prices. Here, pre-processing is important is especially important. Tidymodels and the textrecipes offer a range of functions to handle the whole modelling workflow. Below, are a number of pre-processing steps, firstly we use the unnest_tokens function from the tidytext package to process the the car_name variable. Thereafter, we handle the numerical values by applying a logarithm to outcome variable and standardising mileage. Finally, we use step_tokenize, step_tokenfilter and step_tf to tokenise, filter the those tokens and ultimately convert the tokens to a term frequency variables.\n\n\nsee code\nUseful_Car_Names &lt;- Car_Data %&gt;% \n  unnest_tokens(car_name,\n                output=\"car_name\") %&gt;% \n  group_by(vehicle_manufacturer,car_name) %&gt;% \n  summarise(n(),.groups = \"drop\") %&gt;% \n  arrange(desc(`n()`)) %&gt;% \n  anti_join(stop_words %&gt;% \n              rename(car_name=word)) %&gt;% \n  filter(!str_detect(car_name,\"\\\\d{1,}\"))\n\nCar_Data &lt;- Car_Data %&gt;% \n  unnest_tokens(car_name,output = \"car_name\") %&gt;% \n  semi_join(Useful_Car_Names %&gt;% \n              select(car_name,vehicle_manufacturer)) %&gt;%\n  group_by(across(-car_name)) %&gt;% \n  summarise(car_name = as.character(list(c(car_name))),\n            .groups = \"drop\") %&gt;% \n  mutate(car_name = str_replace(car_name,\n                                'c[[:punct:]]{2,}',\"\"),\n         car_name = str_replace_all(car_name,\n                                    '\\\\\"',\"\"),\n         car_name = str_replace_all(car_name,\n                                    '[[:punct:]]{1,}$',\"\"),\n         age = 2021-year)\nCar_Data &lt;- Car_Data %&gt;% \n  mutate(across(c(car_name,dealership,city_town),\n                .fns = as_factor))\n\nNew_Car_Data &lt;- recipe(price ~ .,data = Car_Data) %&gt;% \n  step_log(all_outcomes()) %&gt;%\n  step_normalize(mileage) %&gt;% \n  step_tokenize(c(dealership,city_town,car_name)) %&gt;%\n  step_tokenfilter(c(dealership,city_town,car_name)) %&gt;%\n  step_tf(c(dealership,city_town,car_name)) %&gt;% \n  step_dummy(c(vehicle_manufacturer,province,\n               fuel_type,transmission)) %&gt;% \n  step_nzv(all_predictors()) %&gt;% \n  prep() %&gt;% \n  bake(Car_Data)"
  },
  {
    "objectID": "posts/2021 Second-Hand Cars in South Africa/Index.html#lasso-it-once-lasso-it-until-you-can-also-no-more",
    "href": "posts/2021 Second-Hand Cars in South Africa/Index.html#lasso-it-once-lasso-it-until-you-can-also-no-more",
    "title": "South African Car Prices",
    "section": "LASSO IT ONCE, LASSO IT UNTIL YOU CAN ALSO NO MORE",
    "text": "LASSO IT ONCE, LASSO IT UNTIL YOU CAN ALSO NO MORE\nThe resulting dataset contains 59417 rows across 27 variables. Given the dimension above, it prudent to do some additional feature select. LASSO regression helps with variable selection. In turn, we use the LASSO regression results to filter for the appropriate variables. The final variable set yields 24 predictor variables. The code below contains all details the LASSO implementation and subsequent filtering.\n\n\nsee code\nNew_Car_Data &lt;- New_Car_Data %&gt;%\n  select(-year)\n\nCar_split &lt;- initial_split(New_Car_Data)\nCar_Training &lt;- training(Car_split)\nCar_Test &lt;- testing(Car_split)\n\nX &lt;- model.matrix(price~.,Car_Training)[,-1]\nY &lt;- Car_Training$price\nlasso_model &lt;- glmnet(x = X,y=Y,\n       alpha=1)\n\nvariable_extractor &lt;- function(a_list){\n  min_lambda &lt;- data.frame(best_lambda =a_list[[\"lambda\"]]==min(a_list[[\"lambda\"]]))\n  min_lambda &lt;- cbind.data.frame(data.frame(index = rownames(min_lambda)),\n                                 min_lambda)\n  min_lambda &lt;- min_lambda %&gt;% \n    filter(best_lambda == TRUE)\n  min_lambda &lt;- as.double(unique(min_lambda$index))\n  lasso_variables &lt;-\n    as.matrix(coef(a_list))|&gt;data.frame()\n  \n  lasso_variables &lt;- cbind.data.frame(variables = rownames(lasso_variables),\n                                      lasso_variables)\n  \n  lasso_variables &lt;- tibble(lasso_variables)\n  lasso_variables &lt;- lasso_variables[,c(1,min_lambda+1)]\n  names(lasso_variables) &lt;- c(\"variable\",\"importance\")\n  lasso_variables &lt;- lasso_variables %&gt;% \n    filter(variable != \"(Intercept)\",\n           importance != 0.00000000) %&gt;% \n    arrange(desc(importance))\n\n  return(lasso_variables)\n}\n\nVariables &lt;- variable_extractor(lasso_model)\nCar_Training &lt;- Car_Training[,c(\"price\",Variables$variable)]\nCar_Test &lt;- Car_Test[,c(\"price\",Variables$variable)]"
  },
  {
    "objectID": "posts/2021 Second-Hand Cars in South Africa/Index.html#cross-validation",
    "href": "posts/2021 Second-Hand Cars in South Africa/Index.html#cross-validation",
    "title": "South African Car Prices",
    "section": "CROSS VALIDATION",
    "text": "CROSS VALIDATION\nBefore fitting to the test dataset, it worth investigating whether our model performs well against “shuffled” dataset of our training data. Fortunately, tidymodels and parsnip contain several functions to assist with the exercise.\nHere, we use the vfold_cv function to split our training data into random splits of equal size. Next, we use workflow to fit a linear model on the random splits. Subsequently, we plot the r-squares across all the folds.\nUltimately, cross validation helps us understand the performance of our model set of datasets by iterating through the training and test sample of each fold. The code below illustrates an implementation of cross validation.\n\n\nsee code\nCar_Training_cv &lt;- vfold_cv(Car_Training)\n\nlinear_model &lt;- linear_reg() %&gt;% \n  set_engine(\"lm\")\n\ncv_outcomes &lt;- workflow() %&gt;% \n  add_model(linear_model) %&gt;% \n  add_formula(price ~.) %&gt;% \n  fit_resamples(Car_Training_cv) %&gt;% \n  select(id,.metrics) %&gt;% \n  unnest(.metrics) %&gt;% \n  filter(.metric == \"rsq\") %&gt;% \n  select(id,.metric,.estimator,.estimate)\n\ncv_plot &lt;- cv_outcomes %&gt;%  \n  ggplot(aes(id,.estimate,group=1,fill=id))+\n  geom_col(show.legend = FALSE,alpha=0.8)+\n  geom_text(aes(label=round(.estimate,2)))+\n  coord_flip()+\n  labs(title = \"Cross Validation Results\",\n       subtitle = \"Car Prices Linear Model: R-Square across 10 folds\",\n       x=NULL,\n       y = \"R-Square\")+\n  theme(plot.title = element_text(family = \"Arial Narrow\",\n                                  hjust = 0.5),\n        plot.subtitle = element_text(family = \"Arial Narrow\",\n                                     hjust = 0.5,face = \"italic\"))"
  },
  {
    "objectID": "posts/2021 Ask A Manager Salary Survey/index.html",
    "href": "posts/2021 Ask A Manager Salary Survey/index.html",
    "title": "Ask A Manager Survey",
    "section": "",
    "text": "In early 2021, the Ask A Manager blogsite ran their annual salary survey. The survey responses are stored on googlesheets, making the data accessible to all interested. In a previous post, we discussed data pre-processing and feature selection method. This post focuses two aspects,namely, 1) Reproducibility and 2) Out-of-Sample Testing.\n\n\nIn the previous post, we detailed the feature selection method by regularised regreesion, specifically, LASSO regression. In this post, we will attempt to reproduce the feature selection method.\n\n\n\nIn this post, we will also follow the traditional machine learning workflow including, splitting the data into a training and testing samples, fitting a model, cross-validation and finally fitting the model on the out-of-sample dataset(testing dataset). This approach can inform us about the model’s parsimony. In other words, can the model perform well on an unknown sample."
  },
  {
    "objectID": "posts/2021 Ask A Manager Salary Survey/index.html#reproducibility",
    "href": "posts/2021 Ask A Manager Salary Survey/index.html#reproducibility",
    "title": "Ask A Manager Survey",
    "section": "",
    "text": "In the previous post, we detailed the feature selection method by regularised regreesion, specifically, LASSO regression. In this post, we will attempt to reproduce the feature selection method."
  },
  {
    "objectID": "posts/2021 Ask A Manager Salary Survey/index.html#out-of-sample-testing",
    "href": "posts/2021 Ask A Manager Salary Survey/index.html#out-of-sample-testing",
    "title": "Ask A Manager Survey",
    "section": "",
    "text": "In this post, we will also follow the traditional machine learning workflow including, splitting the data into a training and testing samples, fitting a model, cross-validation and finally fitting the model on the out-of-sample dataset(testing dataset). This approach can inform us about the model’s parsimony. In other words, can the model perform well on an unknown sample."
  },
  {
    "objectID": "posts/2021 Ask A Manager Salary Survey/index.html#important-variable-extraction",
    "href": "posts/2021 Ask A Manager Salary Survey/index.html#important-variable-extraction",
    "title": "Ask A Manager Survey",
    "section": "IMPORTANT VARIABLE EXTRACTION",
    "text": "IMPORTANT VARIABLE EXTRACTION\nThe resulting object is a list of class “glmnet”. Essentially, the results contain all the iterations through alpha and to find the minimum lambda. As such, there are several results in the object. We are primarily interested in extracting the remaining variables at minimum lambda along with their coeffiecients. The vip package can automate the plotting of the results. However, we want to extract the variables names in order to fit them on our training test. There is probably a package to assist with this step somewhere in the wild, however, we haven’t found it yet. Luckily in R, we can write custom functions. The code below details the variable_extractor function.\n\n\nsee code\nvariable_extractor &lt;- function(a_list){\n  min_lambda &lt;- data.frame(best_lambda =a_list[[\"lambda\"]]==min(a_list[[\"lambda\"]]))\n  min_lambda &lt;- cbind.data.frame(data.frame(index = rownames(min_lambda)),\n                                 min_lambda)\n  min_lambda &lt;- min_lambda %&gt;% \n    filter(best_lambda == TRUE)\n  min_lambda &lt;- as.double(unique(min_lambda$index))\n  lasso_variables &lt;- as.matrix(coef(a_list))|&gt;data.frame()\n  lasso_variables &lt;- cbind.data.frame(variables = rownames(lasso_variables),\n                                      lasso_variables)\n  lasso_variables &lt;- tibble(lasso_variables)\n  lasso_variables &lt;- lasso_variables[,c(1,min_lambda+1)]\n  names(lasso_variables) &lt;- c(\"variable\",\"importance\")\n  lasso_variables &lt;- lasso_variables %&gt;% \n    filter(variable != \"(Intercept)\",\n           importance != 0.00000000) %&gt;% \n    arrange(desc(importance))\n\n  return(lasso_variables)\n}\n\nlasso_variable &lt;- variable_extractor(lasso)\n\n\nThe function takes a list of attribute “glmnet”. Thereafter, we find the smallest lambda. In addition, we extract all the coefficients from the object and store them as a wide dataframe. The dataframe is subset to only contain the variable name along with the coefficients of the smallest lambda value. We discard the intercept and variable with coefficients that are equal to 0.0000000. The final output is identical to the variables extracted by the vip package. Finally, we subset both the training dataset and the testing dataset to only contain the selected independent variables. Since the outcome variable is expressed in USD terms, we log the outcome variable."
  },
  {
    "objectID": "posts/2021 Ask A Manager Salary Survey/index.html#tidymodels-a-clean-interface-for-maching-learning",
    "href": "posts/2021 Ask A Manager Salary Survey/index.html#tidymodels-a-clean-interface-for-maching-learning",
    "title": "Ask A Manager Survey",
    "section": "TIDYMODELS: A CLEAN INTERFACE FOR MACHING LEARNING",
    "text": "TIDYMODELS: A CLEAN INTERFACE FOR MACHING LEARNING\nThe R programming language doesn’t not lack methods for running machine learning algorithms, it is after all, a statistical programming language. The tidymodels metapackage aims to provide a standard interface for modelling and machine learning using tidyverse principles. Below, we use the package to complete a number of steps including, crossfold_validation, model specification, fitting on the resamples and finally fitting the model on the training dataset.\n\n\nsee code\nSalary_Folds &lt;- vfold_cv(Salary_Train)\n\nlm_spec &lt;- linear_reg(engine = \"lm\")\n\nlm_recipe &lt;- recipe(new_annual_salary ~.,Salary_Train) %&gt;% \n  step_nzv(all_predictors())\n\nlm_wf &lt;- workflow(lm_recipe,lm_spec)\n\ndoParallel::registerDoParallel(cores = 10)\nctrl_preds &lt;- control_resamples(save_pred = TRUE)\ncv_results &lt;- fit_resamples(lm_wf,Salary_Folds,control = ctrl_preds)\n\nlm_wf &lt;- fit(lm_wf,Salary_Train)\n\ncollect_metrics(cv_results,summarize = FALSE) %&gt;% \n  filter(.metric == \"rsq\") %&gt;% \n  summarise(avg_estimate = mean(.estimate),\n            .groups = \"drop\")\n\n\n# A tibble: 1 × 1\n  avg_estimate\n         &lt;dbl&gt;\n1        0.268\n\n\nAcross all 10 validation folds, the linear regression model’s adjusted R-square averaged 0.272. It is possible to tune the parameters and use battery of other machine learning models to improve performance. In the previous post, we utilised random forest to try an improve the model. Despite, requiring additional computational power, the increases in peformance were marginal to neglible.\nAt this point, we have completed our first objective. We are able to reproduce the LASSO regresison results in the previous post. The next objective is to determine the parsimony of the model. Here, we fit model on the test data."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Sivuyile Nzimeni is a Data Analyst in the Faculty of Economic and Management Sciences, University of the Free State."
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About",
    "section": "Experience",
    "text": "Experience\nAugust 2022 - Present | Data Analyst| Office of the Dean: Faculty of Economic and Management Sciences| University of the Free State\nNov 2020 - July 2022| Data Analyst; Teaching and Learning Coordinator | Centre for Teaching and Learning & Faculty of Economic and Management Sciences| University of the Free State\nJan 2018 - Nov 2020| Teaching and Learning Coordinator: Economic and Management Sciences | Centre for Teaching and Learning | University of the Free State\nJan 2017 - Dec 2017| Research Assistant | Department of Business Management | University of the Free State\nJul 2017 - Nov 2017| Part-Time Lecturer |Department of Business Management| University of the Free State\nNov 2015 - Nov 2016| Intern | Office of the Dean: Economic and Management Sciences |University of the Free State"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "Education",
    "text": "Education\n2016| University of the Free State |B.Com Honours with specialisation in Entrepreneurial Management\n2015| University of the Free State |B.A with majors in Business Management and Philosophy"
  },
  {
    "objectID": "about.html#interests",
    "href": "about.html#interests",
    "title": "About",
    "section": "Interests",
    "text": "Interests\n\nR Programming\nData Analysis in Higher Education\nManagement Studies\nEconomics\nSocial Media Analysis\nNatural Language Processing"
  },
  {
    "objectID": "about.html#publications",
    "href": "about.html#publications",
    "title": "About",
    "section": "Publications",
    "text": "Publications\nVan Zyl, H. Nzimeni, S. 2023. ‘An exploration of human capital investment and senior student academic performance at a South African university’.Southern African Accounting Association Biennial International Conference Proceedings 28-30 June 2023. ISBN Number: 978-0-6397-7486-2\nNzimeni, S. Mofokeng, M. 2022. ‘Automating tutorial attendance register capturing, preliminary results from a pilot project’. Siyaphumelela 2022: A Saide Project. Online, 25 - 27 June 2022.\nMuller, A. Nzimeni, S. Janse van Vuuren, Corlia. 2021. ‘Curriculum enhancement: reflections on the use of data, holistic student support and disciplinary skills development on a decade-long transformative journey’. 2021 University of the Free State Annual Teaching and Learning Conference.\nNzimeni, S. 2019. ‘Enrolment versus attendance: A preliminary investigation into the cost of tutorials’. Siyaphumelela 2019: A Saide Project. Johannesburg, 25 - 27 June 2019.\nNzimeni, S. Smit, AVA. 2018. ‘Is the quality of education impacting the global competitiveness of the South African business environment?’ 30th Annual Conference of the South African Institute of Management Scientists: Conference Proceedings, Stellenbosch University, Stellebosch, 16 - 19 September 2018."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nSpam Emails\n\n\n\n\n\n\ndata modelling\n\n\ndata cleaning\n\n\nvisualisation\n\n\n\nThis post is about building a classification model for spam email detection. We explore a solution for handling an imbalanced dataset.\n\n\n\n\n\nAug 18, 2023\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\n2023 South African Macroeconomic Database\n\n\n\n\n\n\napi\n\n\ndata cleaning\n\n\nvisualisation\n\n\n\nThis post walks-through accessing South African Macroeconomic Data in South Africa through the SAMADB package\n\n\n\n\n\nJun 21, 2023\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\n2023 Spatial Data Analysis\n\n\n\n\n\n\nspatial data\n\n\ndata cleaning\n\n\nvisualisation\n\n\n\nChapter 8 of Analysing US Census Data Methods, Maps and Models in R. In this post, we work through the code contained in the above-mentioned book. This chapter is important as includes sections on spatial feature engineering, modelling and visualisation.\n\n\n\n\n\nApr 14, 2023\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\n2023 TidyTuesday Week 1\n\n\n\n\n\n\nspatial data\n\n\ndata cleaning\n\n\nvisualisation\n\n\n\nVisualising Spatial Data in R using data from the IEC and Municipal Dermacation Board in South Africa.\n\n\n\n\n\nJan 6, 2023\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\n2022 Ask A Manager Salary Survey\n\n\n\n\n\n\nData Modelling\n\n\nData Cleaning\n\n\n\nAnalysing the 2022 Ask A Manager Salary Survey. In this post, we detail the data preprocessing procedure, feature-selection and modelling process to estimate salaries among respondents.\n\n\n\n\n\nDec 18, 2022\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\nSouth African Car Prices\n\n\n\n\n\n\nweb-scraping\n\n\ndata analysis\n\n\ndata modelling\n\n\n\nThis post details the data scraping process for obtaining data from a South African online vehicle marketplate. In addition, the post shares the results of a linear regression model to estimate determinants of vehicle prices.\n\n\n\n\n\nFeb 28, 2022\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\nState of Capture Commission Report Part 1: Notes\n\n\n\n\n\n\nnews\n\n\npolitics\n\n\nlegal\n\n\n\nThis posts is the first installment of notes from reading the State of Capture Commission’s Report Part 1. This post post focuses on the first few pages of the report.\n\n\n\n\n\nJan 5, 2022\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\nDepartment of Basic Education: Schools Database\n\n\n\n\n\n\nweb-scraping\n\n\ndata cleaning\n\n\n\nThis post details the data scraping process for obtaining the schools database of from the Department of Basic Education in South Africa.\n\n\n\n\n\nDec 30, 2021\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\n\n\n\n\n\n\nAsk A Manager Survey\n\n\n\n\n\n\ndata analysis\n\n\ndata modelling\n\n\n\nThis post is about the 2021 Ask A Manager Survey analysis. It provides an overview of the data analysis process attempting to fit a linear regression model to explain variances in reported salaries among the respondents\n\n\n\n\n\nDec 25, 2021\n\n\nSivuyile Nzimeni\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021 Department of Basic Education Scraping/index.html",
    "href": "posts/2021 Department of Basic Education Scraping/index.html",
    "title": "Department of Basic Education: Schools Database",
    "section": "",
    "text": "A few years ago, I was a student pursuing Masters of Commerce degree. The topic had something to do with the relationship between Education, Labour and Business outcomes. My pursuit of the qualification is defunct. However, there are several artefacts worth writting up. In this post, we will discuss the South African Schools Database. The Department of Basic Education regularly publishes versions of the School Database including a number of notable variables such as the school’s location, contact information, number of learners and teachers etc. The data is published in a non-standardised matter. This makes it an interesting data wrangling task.\n\n\nThe first hurdle is the volume of files publised on the DBE website. It is possible to download all 200 files by hand and save them to a directory of your choosing. However, such a process would be tedious and error prone(speaking from experience, ofcourse). The R-Programming language is a perfect companion for this task. To download the files, we can use two important packages, rvest and xml2.\nFirstly, we specify the url on the read_html function. Thereafter, we use the html_elements function to point to the html tag of interest. In this case, we are interest in the “a” tag, specifically, the href (or link) attribute.\nWe store the result in a data.frame object and use a regular expression to filter for values that start with a punctuation followed by “Link” and values that contain the term “forcedownload”. Finally, we append the path to file (our base url). The resulting data.frame contains all 200 downloadable files.\n\n\n\nWith the links in hand, we can tackle the next hurdle, downloading the files. Usually, we could use the commandline to download the files. For example, the single command below.\n\n\nsee code\nwget -i some_text_file.txt\n\n\nHowever, the DBE datasets are saved as either xlsx or xls format with a prompt on click to download the file. There are probably ways around this issue. Luckily, xml2 has a convenient function to handle this issue. In the code below, we use a for-loop to download each file in our dataset and save them in a specified sub folder. To avoid a break in the for-loop when an error occurs, we add the try function. As an add-on, we print a statement after each download. Depending on your internet connection speed and the website’s response time, this script can take five minutes to download all the files.\n\n\nsee code\nfor(i in seq_along(1:nrow(Data_Sets))){\n  try(download_xml(url = Data_Sets$dataset_links[[i]],\n               file = paste0(\"./Schools_Db/\",\"file_\",i,\".xlsx\")))\n  print(paste0(\"File \",i, \" downloaded \",\"proceeding to file \",i+1,\".\"))\n}\n\n\n\n\n\nAnother set of tasks to address is reading and cleaning the excel files. Using other software such as Excel or SPSS, these tasks would be cumbersome. Yet with R, Python or other programming languages, it possible handle more than one file at a time. Below, we use the readxl and purrr R packages to iteratively read and clean the files.\n\n\nsee code\n# All_Excel_Reader --------------------------------------------------------\nall_excel &lt;- function(path){\n  collect_sheets &lt;- excel_sheets(path)\n  number_of_sheets &lt;- 1:length(collect_sheets)\n  per_sheet &lt;- list()\n  for(i in seq_along(number_of_sheets)){\n    per_sheet[[i]] &lt;- read_xlsx(path = path,\n                                sheet = collect_sheets[i])\n  }\n  return(per_sheet)}\n# All_Masterlist ----------------------------------------------------------\nEDU_Dbs &lt;- data.frame(master_list = list.files(path = \"./Schools_Db\",\n           full.names=TRUE,\n           pattern = \".xlsx\")) %&gt;% \n  mutate(schools_db = map(master_list,all_excel))\n\nEDU_Dbs &lt;- EDU_Dbs %&gt;% \n  unnest(schools_db)\n\nEDU_Dbs$schools_db &lt;- lapply(EDU_Dbs$schools_db,sapply,as.character)\n\nEDU_Dbs$schools_db &lt;- lapply(EDU_Dbs$schools_db,as.data.frame)\n\nEDU_Dbs &lt;- EDU_Dbs %&gt;% \n  unnest(schools_db)\n\nEDU_Dbs &lt;- EDU_Dbs %&gt;% \n  clean_names()\n\n\nThe resulting data.frame contains hundreds of thousands of rows and nearly 60 columns. Interestingly, most of these variable are effectively differing naming conventions such as emisno = natemis = oldnatemis = newnatemis. The insistent naming conventions extend to other variables such as gps coordinates and centre details. The spectacularly unoptimised script is availablehere. The scraper script,cleaning script and downloaded xlsx files are all available on the this github report."
  },
  {
    "objectID": "posts/2021 Department of Basic Education Scraping/index.html#data-scraping",
    "href": "posts/2021 Department of Basic Education Scraping/index.html#data-scraping",
    "title": "Department of Basic Education: Schools Database",
    "section": "",
    "text": "The first hurdle is the volume of files publised on the DBE website. It is possible to download all 200 files by hand and save them to a directory of your choosing. However, such a process would be tedious and error prone(speaking from experience, ofcourse). The R-Programming language is a perfect companion for this task. To download the files, we can use two important packages, rvest and xml2.\nFirstly, we specify the url on the read_html function. Thereafter, we use the html_elements function to point to the html tag of interest. In this case, we are interest in the “a” tag, specifically, the href (or link) attribute.\nWe store the result in a data.frame object and use a regular expression to filter for values that start with a punctuation followed by “Link” and values that contain the term “forcedownload”. Finally, we append the path to file (our base url). The resulting data.frame contains all 200 downloadable files."
  },
  {
    "objectID": "posts/2021 Department of Basic Education Scraping/index.html#downloads-so-many-downloads.",
    "href": "posts/2021 Department of Basic Education Scraping/index.html#downloads-so-many-downloads.",
    "title": "Department of Basic Education: Schools Database",
    "section": "",
    "text": "With the links in hand, we can tackle the next hurdle, downloading the files. Usually, we could use the commandline to download the files. For example, the single command below.\n\n\nsee code\nwget -i some_text_file.txt\n\n\nHowever, the DBE datasets are saved as either xlsx or xls format with a prompt on click to download the file. There are probably ways around this issue. Luckily, xml2 has a convenient function to handle this issue. In the code below, we use a for-loop to download each file in our dataset and save them in a specified sub folder. To avoid a break in the for-loop when an error occurs, we add the try function. As an add-on, we print a statement after each download. Depending on your internet connection speed and the website’s response time, this script can take five minutes to download all the files.\n\n\nsee code\nfor(i in seq_along(1:nrow(Data_Sets))){\n  try(download_xml(url = Data_Sets$dataset_links[[i]],\n               file = paste0(\"./Schools_Db/\",\"file_\",i,\".xlsx\")))\n  print(paste0(\"File \",i, \" downloaded \",\"proceeding to file \",i+1,\".\"))\n}"
  },
  {
    "objectID": "posts/2021 Department of Basic Education Scraping/index.html#bring-your-brooms-cause-its-a-mess",
    "href": "posts/2021 Department of Basic Education Scraping/index.html#bring-your-brooms-cause-its-a-mess",
    "title": "Department of Basic Education: Schools Database",
    "section": "",
    "text": "Another set of tasks to address is reading and cleaning the excel files. Using other software such as Excel or SPSS, these tasks would be cumbersome. Yet with R, Python or other programming languages, it possible handle more than one file at a time. Below, we use the readxl and purrr R packages to iteratively read and clean the files.\n\n\nsee code\n# All_Excel_Reader --------------------------------------------------------\nall_excel &lt;- function(path){\n  collect_sheets &lt;- excel_sheets(path)\n  number_of_sheets &lt;- 1:length(collect_sheets)\n  per_sheet &lt;- list()\n  for(i in seq_along(number_of_sheets)){\n    per_sheet[[i]] &lt;- read_xlsx(path = path,\n                                sheet = collect_sheets[i])\n  }\n  return(per_sheet)}\n# All_Masterlist ----------------------------------------------------------\nEDU_Dbs &lt;- data.frame(master_list = list.files(path = \"./Schools_Db\",\n           full.names=TRUE,\n           pattern = \".xlsx\")) %&gt;% \n  mutate(schools_db = map(master_list,all_excel))\n\nEDU_Dbs &lt;- EDU_Dbs %&gt;% \n  unnest(schools_db)\n\nEDU_Dbs$schools_db &lt;- lapply(EDU_Dbs$schools_db,sapply,as.character)\n\nEDU_Dbs$schools_db &lt;- lapply(EDU_Dbs$schools_db,as.data.frame)\n\nEDU_Dbs &lt;- EDU_Dbs %&gt;% \n  unnest(schools_db)\n\nEDU_Dbs &lt;- EDU_Dbs %&gt;% \n  clean_names()\n\n\nThe resulting data.frame contains hundreds of thousands of rows and nearly 60 columns. Interestingly, most of these variable are effectively differing naming conventions such as emisno = natemis = oldnatemis = newnatemis. The insistent naming conventions extend to other variables such as gps coordinates and centre details. The spectacularly unoptimised script is availablehere. The scraper script,cleaning script and downloaded xlsx files are all available on the this github report."
  },
  {
    "objectID": "posts/2022 Ask A Manager Salary Survey/index.html",
    "href": "posts/2022 Ask A Manager Salary Survey/index.html",
    "title": "2022 Ask A Manager Salary Survey",
    "section": "",
    "text": "Last year, we analysed the 2021 Ask A Manager Salary Survey. The dataset is interesting for many reasons including,most beneficially, the dataset is open and available for all interested parties. It is also offers an opportunity to move beyond old and boring datasets such as mtcars and iris. The results of the survey offer an opportunity to clean open-text fields, currency data and feature engineering for data modelling.\nFortunately, there is a 2022 Ask A Manager Salary Survey that is also freely available. Notably, there were only 15 465 respondents compared to 27 919 responds in the previous survey. It is difficult to estimate the reasons for the reduction in responses. Nonetheless,there are sufficient responses to model upon. The second batch of responses offers an opportunity to refine the data preprocessing and modelling process.\n\n\nUnlike in the previous post, the data preprocessing step is contained in a stand-alone script ./Scripts/2022_Data_Cleaner.R. This helps with two main aspects; i) practising modular scripts and ii) reducing the size of the analysis. The data cleaning script has several components in it. The table below summarises the aforementioned components.\n\n\nsee code\nlibrary(gt)\nlibrary(gtExtras)\n\ndata.frame(section = c(\"Importing Libraries\",\"Importing Data\",\"Open Text Cleaning\",\n                       \"List to Vec\",\"Completeness Check\"),\n           script_sample =c('lapply(as.list(c(\"tidyverse\",\"janitor\",\"arrow\",\n                 \"ggthemes\",\"tidytext\",\"tidymodels\",\n                 \"textrecipes\",\"glmnet\")),\n       require,character.only=TRUE) |&gt;\n  suppressWarnings() |&gt; \n  suppressMessages() |&gt; \n  invisible()','read_csv(file = \"./Data/Ask A Manager Salary Survey 2022_Responses.csv\") |&gt; \n  clean_names() |&gt; \n  mutate(timestamp = mdy_hms(timestamp)) |&gt; \n  filter(!is.na(job_title)) |&gt; \n  mutate(additional_compensation = ifelse(is.na(additional_compensation),\n                                          0,additional_compensation),\n         full_compensation = salary+additional_compensation) |&gt; \n  filter(!currency %in% c(\"Other\",\"HKD\")) |&gt; \n  rownames_to_column(\"respondent\")','text_cleaner &lt;- function(a_vec){\n  tokens &lt;- str_split(a_vec,pattern=\"\\\\s{1,}\") |&gt; \n    unlist()\n  tokens &lt;- tokens[!grepl(\"\\\\s{1,}|[[:punct:]]|\\\\d{1,}\",tokens)] |&gt; str_to_lower()\n  tokens &lt;- unique(tokens) \n  tokens &lt;- tokens[!tokens %in% c(stopwords::data_stopwords_nltk[[\"en\"]])]\n  return(tokens)}','list_to_vec &lt;- function(a_vec){\n  new_vec &lt;- a_vec |&gt; \n    as.character()\nnew_vec &lt;- gsub(\"(^c+[[:punct:]])|[[:punct:]]\",\n                replacement = \"\",\n                new_vec)\n  return(new_vec)}\n','completeness &lt;- function(a_vec){\n  incomplete &lt;- round(100/length(a_vec)*a_vec[is.na(a_vec)] |&gt; length(),2)\nreturn(incomplete)}\n'),\n           reasoning = c(\"importing libraries required for preprocessing\",\n                         \"import data, convert date column to date type, remove unviable cases and create total compensation columns\",\n                         \"split open-text fields into tokens, remove punctuation, spaces and stopwords. The function returns a list of words per case\",\n                         \"Convert the list of words per case to a vector.\",\n                         \"Check the level of missing values in each column.\")) |&gt; \n  gt() |&gt; \n  gt_theme_nytimes() |&gt; \n  tab_header(title = \"2022 Data Clean Script Overview\",\n                 subtitle = \"An overview of sections in the data cleaning script\") |&gt; \n  opt_align_table_header(align = \"center\") |&gt; \n  tab_style(style = list(\n    cell_fill(color= \"#490E6F\",alpha=0.8),\n    cell_text(color = \"white\",font=google_font(\"Fira Code\"),\n              align = \"center\",style = \"normal\",\n              weight= \"lighter\",whitespace = \"pre-line\")\n  ),\n  locations= cells_body(\n    columns = script_sample\n  ))\n\n\n\n\n\n\n\n\n2022 Data Clean Script Overview\n\n\nAn overview of sections in the data cleaning script\n\n\nsection\nscript_sample\nreasoning\n\n\n\n\nImporting Libraries\nlapply(as.list(c(\"tidyverse\",\"janitor\",\"arrow\", \"ggthemes\",\"tidytext\",\"tidymodels\", \"textrecipes\",\"glmnet\")), require,character.only=TRUE) |&gt; suppressWarnings() |&gt; suppressMessages() |&gt; invisible()\nimporting libraries required for preprocessing\n\n\nImporting Data\nread_csv(file = \"./Data/Ask A Manager Salary Survey 2022_Responses.csv\") |&gt; clean_names() |&gt; mutate(timestamp = mdy_hms(timestamp)) |&gt; filter(!is.na(job_title)) |&gt; mutate(additional_compensation = ifelse(is.na(additional_compensation), 0,additional_compensation), full_compensation = salary+additional_compensation) |&gt; filter(!currency %in% c(\"Other\",\"HKD\")) |&gt; rownames_to_column(\"respondent\")\nimport data, convert date column to date type, remove unviable cases and create total compensation columns\n\n\nOpen Text Cleaning\ntext_cleaner &lt;- function(a_vec){ tokens &lt;- str_split(a_vec,pattern=\"\\s{1,}\") |&gt; unlist() tokens &lt;- tokens[!grepl(\"\\s{1,}|[[:punct:]]|\\d{1,}\",tokens)] |&gt; str_to_lower() tokens &lt;- unique(tokens) tokens &lt;- tokens[!tokens %in% c(stopwords::data_stopwords_nltk[[\"en\"]])] return(tokens)}\nsplit open-text fields into tokens, remove punctuation, spaces and stopwords. The function returns a list of words per case\n\n\nList to Vec\nlist_to_vec &lt;- function(a_vec){ new_vec &lt;- a_vec |&gt; as.character() new_vec &lt;- gsub(\"(^c+[[:punct:]])|[[:punct:]]\", replacement = \"\", new_vec) return(new_vec)}\nConvert the list of words per case to a vector.\n\n\nCompleteness Check\ncompleteness &lt;- function(a_vec){ incomplete &lt;- round(100/length(a_vec)*a_vec[is.na(a_vec)] |&gt; length(),2) return(incomplete)}\nCheck the level of missing values in each column.\n\n\n\n\n\nA table containing 2022 Data Cleaner sections\n\n\nThe table above contains a few convenience functions used throughout the script. Importing of libraries is completed through lapply followed by suppressWarnings, suppressMessages and invisible functions. The last three functions calls are probably bad practise as warnings may be helpful down the line. A crucial function is the importing data followed by some basic cleaning functions from lubridate and Wickham (2022) . A more exotic function is text_cleaner, the main idea is to remove stopwords, punctuation and white spaces. Ultimately, the function returns a list of terms per case. This practise is not tidy yet. Another convenience function list_to_vec,an imitation of concatenating text values in pivot tables in excel. Finally, the completeness function checks the percentage of missing values within a column. The function is intended to aid in checking the viability of a column in the dataset. Here, columns with missing value percentage &gt; 5% are excluded from the dataset.\nThese functions are applied through purrr::map a tidyverse equivalent to base::lapply, along with dplyr::mutate and dplyr::across to implement the functions consistently.\nAnother important task of the cleaning the data is the conversion of currencies to USD for non-USD salary values. This way, we can get closer to comparing apples with apples. The International Monetary Fund’s Exchange Rate Report Wizard which allows users to exchange rates for multiple time ranges. Importantly, the Hong Kong Dollar is not listed in the report. As such, salaries reported in that currency are not included in the analysis.\nThe final preprocessing step relies on the tidymodels and Hvitfeldt (2022) packages to specify a recipe to tokenize the values derived from list_to_vec,extract their TFIDF (Term Frequency-Inverse Document Frequency) of the tokens, log the salary values and remove near-zero variance variables.\nFinally, the resulting data.frame is used in LASSO regression, which serves as our feature selection step.\n\n\nsee code\nsource(\"./Scripts/2022_Data_Cleaner.R\",\n       local = knitr::knit_global())\n\n\n\n\nAn image containing a Lasso Regression plot indicating coeffiecients\n\n\n\n\n\nUltimately, we extract the variables of interest from the lasso model through the function below. The function is an improvement on the previous post, as it does rely on converting each matrix into a data.frame. In this instance, the function subsets the last model and minimum lambda value from the matrices which are in turn converted to a data.frame. The function is similar to Stata17’s lassocoef or SPSS29’s Best option in Linear Lasso Regression: Option. The script outputs training and testing outputs for further analysis. In this way, the preprocessing section is isolated to a single script and negates the need to read-in data.\n\n\nsee code\nvariable_extractor &lt;- function(a_list){\n  min_lambda &lt;- a_list$lambda |&gt; min()\n  last_model &lt;- length(a_list$lambda)\n  lasso_variables &lt;- as.matrix(coef(a_list))[,last_model] |&gt; \n    data.frame()\n  lasso_variables$variable &lt;- rownames(lasso_variables)\n  names(lasso_variables) &lt;- c(\"coef\",\"variable\")\n  lasso_variables &lt;- lasso_variables[,c(\"variable\",\"coef\")]\n  lasso_variables &lt;- lasso_variables[!grepl(pattern = \"[[:punct:]]Intercept[[:punct:]]\",\n                                            lasso_variables$variable),]\nreturn(lasso_variables)}\n\nSalary_Modelling &lt;- cbind(Salary_Modelling[,grep(\"full_comp_usd\",names(Salary_Modelling))],\nSalary_Modelling[,names(Salary_Modelling) %in% variable_extractor(Lasso_Model)$variable])"
  },
  {
    "objectID": "posts/2022 Ask A Manager Salary Survey/index.html#data-preprocessing",
    "href": "posts/2022 Ask A Manager Salary Survey/index.html#data-preprocessing",
    "title": "2022 Ask A Manager Salary Survey",
    "section": "",
    "text": "Unlike in the previous post, the data preprocessing step is contained in a stand-alone script ./Scripts/2022_Data_Cleaner.R. This helps with two main aspects; i) practising modular scripts and ii) reducing the size of the analysis. The data cleaning script has several components in it. The table below summarises the aforementioned components.\n\n\nsee code\nlibrary(gt)\nlibrary(gtExtras)\n\ndata.frame(section = c(\"Importing Libraries\",\"Importing Data\",\"Open Text Cleaning\",\n                       \"List to Vec\",\"Completeness Check\"),\n           script_sample =c('lapply(as.list(c(\"tidyverse\",\"janitor\",\"arrow\",\n                 \"ggthemes\",\"tidytext\",\"tidymodels\",\n                 \"textrecipes\",\"glmnet\")),\n       require,character.only=TRUE) |&gt;\n  suppressWarnings() |&gt; \n  suppressMessages() |&gt; \n  invisible()','read_csv(file = \"./Data/Ask A Manager Salary Survey 2022_Responses.csv\") |&gt; \n  clean_names() |&gt; \n  mutate(timestamp = mdy_hms(timestamp)) |&gt; \n  filter(!is.na(job_title)) |&gt; \n  mutate(additional_compensation = ifelse(is.na(additional_compensation),\n                                          0,additional_compensation),\n         full_compensation = salary+additional_compensation) |&gt; \n  filter(!currency %in% c(\"Other\",\"HKD\")) |&gt; \n  rownames_to_column(\"respondent\")','text_cleaner &lt;- function(a_vec){\n  tokens &lt;- str_split(a_vec,pattern=\"\\\\s{1,}\") |&gt; \n    unlist()\n  tokens &lt;- tokens[!grepl(\"\\\\s{1,}|[[:punct:]]|\\\\d{1,}\",tokens)] |&gt; str_to_lower()\n  tokens &lt;- unique(tokens) \n  tokens &lt;- tokens[!tokens %in% c(stopwords::data_stopwords_nltk[[\"en\"]])]\n  return(tokens)}','list_to_vec &lt;- function(a_vec){\n  new_vec &lt;- a_vec |&gt; \n    as.character()\nnew_vec &lt;- gsub(\"(^c+[[:punct:]])|[[:punct:]]\",\n                replacement = \"\",\n                new_vec)\n  return(new_vec)}\n','completeness &lt;- function(a_vec){\n  incomplete &lt;- round(100/length(a_vec)*a_vec[is.na(a_vec)] |&gt; length(),2)\nreturn(incomplete)}\n'),\n           reasoning = c(\"importing libraries required for preprocessing\",\n                         \"import data, convert date column to date type, remove unviable cases and create total compensation columns\",\n                         \"split open-text fields into tokens, remove punctuation, spaces and stopwords. The function returns a list of words per case\",\n                         \"Convert the list of words per case to a vector.\",\n                         \"Check the level of missing values in each column.\")) |&gt; \n  gt() |&gt; \n  gt_theme_nytimes() |&gt; \n  tab_header(title = \"2022 Data Clean Script Overview\",\n                 subtitle = \"An overview of sections in the data cleaning script\") |&gt; \n  opt_align_table_header(align = \"center\") |&gt; \n  tab_style(style = list(\n    cell_fill(color= \"#490E6F\",alpha=0.8),\n    cell_text(color = \"white\",font=google_font(\"Fira Code\"),\n              align = \"center\",style = \"normal\",\n              weight= \"lighter\",whitespace = \"pre-line\")\n  ),\n  locations= cells_body(\n    columns = script_sample\n  ))\n\n\n\n\n\n\n\n\n2022 Data Clean Script Overview\n\n\nAn overview of sections in the data cleaning script\n\n\nsection\nscript_sample\nreasoning\n\n\n\n\nImporting Libraries\nlapply(as.list(c(\"tidyverse\",\"janitor\",\"arrow\", \"ggthemes\",\"tidytext\",\"tidymodels\", \"textrecipes\",\"glmnet\")), require,character.only=TRUE) |&gt; suppressWarnings() |&gt; suppressMessages() |&gt; invisible()\nimporting libraries required for preprocessing\n\n\nImporting Data\nread_csv(file = \"./Data/Ask A Manager Salary Survey 2022_Responses.csv\") |&gt; clean_names() |&gt; mutate(timestamp = mdy_hms(timestamp)) |&gt; filter(!is.na(job_title)) |&gt; mutate(additional_compensation = ifelse(is.na(additional_compensation), 0,additional_compensation), full_compensation = salary+additional_compensation) |&gt; filter(!currency %in% c(\"Other\",\"HKD\")) |&gt; rownames_to_column(\"respondent\")\nimport data, convert date column to date type, remove unviable cases and create total compensation columns\n\n\nOpen Text Cleaning\ntext_cleaner &lt;- function(a_vec){ tokens &lt;- str_split(a_vec,pattern=\"\\s{1,}\") |&gt; unlist() tokens &lt;- tokens[!grepl(\"\\s{1,}|[[:punct:]]|\\d{1,}\",tokens)] |&gt; str_to_lower() tokens &lt;- unique(tokens) tokens &lt;- tokens[!tokens %in% c(stopwords::data_stopwords_nltk[[\"en\"]])] return(tokens)}\nsplit open-text fields into tokens, remove punctuation, spaces and stopwords. The function returns a list of words per case\n\n\nList to Vec\nlist_to_vec &lt;- function(a_vec){ new_vec &lt;- a_vec |&gt; as.character() new_vec &lt;- gsub(\"(^c+[[:punct:]])|[[:punct:]]\", replacement = \"\", new_vec) return(new_vec)}\nConvert the list of words per case to a vector.\n\n\nCompleteness Check\ncompleteness &lt;- function(a_vec){ incomplete &lt;- round(100/length(a_vec)*a_vec[is.na(a_vec)] |&gt; length(),2) return(incomplete)}\nCheck the level of missing values in each column.\n\n\n\n\n\nA table containing 2022 Data Cleaner sections\n\n\nThe table above contains a few convenience functions used throughout the script. Importing of libraries is completed through lapply followed by suppressWarnings, suppressMessages and invisible functions. The last three functions calls are probably bad practise as warnings may be helpful down the line. A crucial function is the importing data followed by some basic cleaning functions from lubridate and Wickham (2022) . A more exotic function is text_cleaner, the main idea is to remove stopwords, punctuation and white spaces. Ultimately, the function returns a list of terms per case. This practise is not tidy yet. Another convenience function list_to_vec,an imitation of concatenating text values in pivot tables in excel. Finally, the completeness function checks the percentage of missing values within a column. The function is intended to aid in checking the viability of a column in the dataset. Here, columns with missing value percentage &gt; 5% are excluded from the dataset.\nThese functions are applied through purrr::map a tidyverse equivalent to base::lapply, along with dplyr::mutate and dplyr::across to implement the functions consistently.\nAnother important task of the cleaning the data is the conversion of currencies to USD for non-USD salary values. This way, we can get closer to comparing apples with apples. The International Monetary Fund’s Exchange Rate Report Wizard which allows users to exchange rates for multiple time ranges. Importantly, the Hong Kong Dollar is not listed in the report. As such, salaries reported in that currency are not included in the analysis.\nThe final preprocessing step relies on the tidymodels and Hvitfeldt (2022) packages to specify a recipe to tokenize the values derived from list_to_vec,extract their TFIDF (Term Frequency-Inverse Document Frequency) of the tokens, log the salary values and remove near-zero variance variables.\nFinally, the resulting data.frame is used in LASSO regression, which serves as our feature selection step.\n\n\nsee code\nsource(\"./Scripts/2022_Data_Cleaner.R\",\n       local = knitr::knit_global())\n\n\n\n\nAn image containing a Lasso Regression plot indicating coeffiecients\n\n\n\n\n\nUltimately, we extract the variables of interest from the lasso model through the function below. The function is an improvement on the previous post, as it does rely on converting each matrix into a data.frame. In this instance, the function subsets the last model and minimum lambda value from the matrices which are in turn converted to a data.frame. The function is similar to Stata17’s lassocoef or SPSS29’s Best option in Linear Lasso Regression: Option. The script outputs training and testing outputs for further analysis. In this way, the preprocessing section is isolated to a single script and negates the need to read-in data.\n\n\nsee code\nvariable_extractor &lt;- function(a_list){\n  min_lambda &lt;- a_list$lambda |&gt; min()\n  last_model &lt;- length(a_list$lambda)\n  lasso_variables &lt;- as.matrix(coef(a_list))[,last_model] |&gt; \n    data.frame()\n  lasso_variables$variable &lt;- rownames(lasso_variables)\n  names(lasso_variables) &lt;- c(\"coef\",\"variable\")\n  lasso_variables &lt;- lasso_variables[,c(\"variable\",\"coef\")]\n  lasso_variables &lt;- lasso_variables[!grepl(pattern = \"[[:punct:]]Intercept[[:punct:]]\",\n                                            lasso_variables$variable),]\nreturn(lasso_variables)}\n\nSalary_Modelling &lt;- cbind(Salary_Modelling[,grep(\"full_comp_usd\",names(Salary_Modelling))],\nSalary_Modelling[,names(Salary_Modelling) %in% variable_extractor(Lasso_Model)$variable])"
  },
  {
    "objectID": "posts/2022 Ask A Manager Salary Survey/index.html#ols-model-swiss-knife-approach",
    "href": "posts/2022 Ask A Manager Salary Survey/index.html#ols-model-swiss-knife-approach",
    "title": "2022 Ask A Manager Salary Survey",
    "section": "2.1 OLS MODEL: SWISS KNIFE APPROACH",
    "text": "2.1 OLS MODEL: SWISS KNIFE APPROACH\n\n\nsee code\nols_model &lt;- lm(full_comp_usd ~.,data = Training_Salary)\nlibrary(gtsummary)\n\ntbl_regression(ols_model,\n               add_estimate_to_reference_rows = TRUE,\n               exponentiate = FALSE) |&gt; \n  add_glance_source_note(label = list(\n    r.squared ~ \"R2\",\n    adj.r.squared ~ \"Adj R2\",\n    p.value ~ \"p-value\",\n    statistic ~ \"F-Statistic\",\n    df ~ \"Degrees of Freedom\",\n    df.residual ~ \"Residual df\"),\n    include = c(r.squared,adj.r.squared,p.value,df,statistic,\n                df.residual)\n    ) |&gt; \n  italicize_labels() \n\n\n\n\n\n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    tfidf_employers_industry_administration\n0.17\n-0.07, 0.42\n0.2\n    tfidf_employers_industry_banking\n0.07\n-0.32, 0.45\n0.7\n    tfidf_employers_industry_care\n-0.20\n-0.46, 0.07\n0.15\n    tfidf_employers_industry_computing\n0.16\n-0.20, 0.51\n0.4\n    tfidf_employers_industry_education\n-0.12\n-0.14, -0.10\n&lt;0.001\n    tfidf_employers_industry_engineering\n0.11\n0.03, 0.19\n0.009\n    tfidf_employers_industry_finance\n-0.01\n-0.39, 0.37\n&gt;0.9\n    tfidf_employers_industry_government\n0.13\n-0.08, 0.33\n0.2\n    tfidf_employers_industry_health\n0.19\n-0.07, 0.46\n0.2\n    tfidf_employers_industry_manufacturing\n-0.02\n-0.09, 0.06\n0.7\n    tfidf_employers_industry_nonprofits\n-0.09\n-0.10, -0.07\n&lt;0.001\n    tfidf_employers_industry_public\n-0.33\n-0.47, -0.19\n&lt;0.001\n    tfidf_employers_industry_tech\n0.12\n-0.23, 0.48\n0.5\n    tfidf_functional_area_of_job_advertising\n0.31\n-0.49, 1.1\n0.4\n    tfidf_functional_area_of_job_banking\n-0.43\n-0.97, 0.11\n0.12\n    tfidf_functional_area_of_job_computing\n0.71\n-0.25, 1.7\n0.15\n    tfidf_functional_area_of_job_education\n-0.03\n-0.05, -0.01\n0.009\n    tfidf_functional_area_of_job_finance\n0.39\n-0.15, 0.93\n0.2\n    tfidf_functional_area_of_job_pr\n-0.30\n-1.1, 0.51\n0.5\n    tfidf_functional_area_of_job_tech\n-0.52\n-1.5, 0.44\n0.3\n    tfidf_job_title_manager\n0.08\n0.05, 0.11\n&lt;0.001\n    tfidf_job_title_senior\n0.23\n0.19, 0.27\n&lt;0.001\n    tfidf_country_canada\n0.17\n0.15, 0.19\n&lt;0.001\n    tfidf_country_states\n-0.50\n-1.2, 0.19\n0.2\n    tfidf_country_united\n1.2\n0.56, 1.9\n&lt;0.001\n    tfidf_race_white\n-0.09\n-0.14, -0.04\n&lt;0.001\n  \n  \n    \n      R2 = 0.155; Adj R2 = 0.153; p-value = &lt;0.001; Degrees of Freedom = 26; F-Statistic = 79.2; Residual df = 11,237\n    \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\nOLS Regression Results illustrating an adjusted r-square of 0.15 on 11237 cases and global p value of &lt; 0.001\n\n\nFitting a linear regression model is rather straight forward. The model above yields an Adjusted R Square of 0.153. In other words, the model explains 15% of the variance in salaries. The beta, confidence interval and p-values of the variables considered are listed on the table. One way to report the aforementioned results would be to utilise the report package which can aid in reporting models in standard manner including beta values, standard error, confidence intervals etc. for the respective variables considered in the model."
  },
  {
    "objectID": "posts/2022 Ask A Manager Salary Survey/index.html#mars-model-splines-and-lines",
    "href": "posts/2022 Ask A Manager Salary Survey/index.html#mars-model-splines-and-lines",
    "title": "2022 Ask A Manager Salary Survey",
    "section": "2.2 MARS MODEL: SPLINES AND LINES",
    "text": "2.2 MARS MODEL: SPLINES AND LINES\nBelow, we build a MARS model and iterate through 10 cross-validation folds. The resulting models, does not out perform the OLS model. The R-Square average R-Square for the MARS model is 0.15.\n\n\nsee code\nlibrary(earth)\n\nMARS_Model &lt;- earth(full_comp_usd ~.,Training_Salary,\n      degree = 2,\n      glm = list(family = \"gaussian\"),\n      pmethod = \"exhaustive\",\n      nfold = 10,\n      ncross= 10,\n      varmod.method = \"earth\")\n\nFold_Rsquares &lt;- lapply(MARS_Model$cv.list,\\(x){x[\"rsq\"]})\n\nFold_Rsquares &lt;- lapply(Fold_Rsquares,data.frame)\n\ntheme_set(ggthemes::theme_solarized_2())\n\nmap2(Fold_Rsquares,names(Fold_Rsquares),function(x,y){\n  x |&gt; \n    mutate(fold_source =y)\n})%&gt;%\n  do.call(bind_rows,.) |&gt; \n  mutate(iteration = str_extract(fold_source,\"\\\\d{1,2}$\") |&gt; as.integer(),\n         fold_source = str_remove(fold_source,\"[[:punct:]]\\\\d{1,}\") |&gt; as.factor(),\n         fold_source = fct_reorder(fold_source,iteration)) |&gt; \n  ggplot(aes(iteration,rsq,group=fold_source))+\n  geom_line(aes(colour = fold_source),show.legend = FALSE)+\n  scale_colour_manual(values = c(\"fold1\" = \"#0F204B\",\n                                 \"fold2\"= \"#A71930\",\n                                 \"fold3\" = \"#000000\",\n                                 \"fold4\" = \"#9E83B7\",\n                                 \"fold5\"=\"#00B140\",\n                                 \"fold6\" = \"#BB133E\",\n                                 \"fold7\"= \"#490E6F\",\n                                 \"fold8\"= \"#0039A7\",\n                                 \"fold9\"= \"#00675A\",\n                                 \"fold10\"= \"#EA8400\"))+\n  scale_x_continuous(breaks = c(1:10))+\n  facet_wrap(~fold_source,\n             ncol = 2,\n             nrow=5, \n             scales = \"free\")\n\n\n\n\nMARS Model Results indicating a selected model with an R-Square of 0.15\n\n\n\n\n\nThere are several ways to improve the model. Such as including factor variables in place of dummy variables, utilising polynomial regression in place of the gaussian family among others. For a more detailed account on how to work with enhance MARS models, see Milborrow (n.d.) .\n\n\nsee code\nplotmo(MARS_Model)\n\n\n plotmo grid:    tfidf_employers_industry_administration\n                                                       0\n tfidf_employers_industry_banking tfidf_employers_industry_care\n                                0                             0\n tfidf_employers_industry_computing tfidf_employers_industry_education\n                                  0                                  0\n tfidf_employers_industry_engineering tfidf_employers_industry_finance\n                                    0                                0\n tfidf_employers_industry_government tfidf_employers_industry_health\n                                   0                               0\n tfidf_employers_industry_manufacturing tfidf_employers_industry_nonprofits\n                                      0                                   0\n tfidf_employers_industry_public tfidf_employers_industry_tech\n                               0                             0\n tfidf_functional_area_of_job_advertising tfidf_functional_area_of_job_banking\n                                        0                                    0\n tfidf_functional_area_of_job_computing tfidf_functional_area_of_job_education\n                                      0                                      0\n tfidf_functional_area_of_job_finance tfidf_functional_area_of_job_pr\n                                    0                               0\n tfidf_functional_area_of_job_tech tfidf_job_title_manager\n                                 0                       0\n tfidf_job_title_senior tfidf_country_canada tfidf_country_states\n                      0                    0            0.3854429\n tfidf_country_united tfidf_race_white\n            0.3849207        0.7425228\n\n\n\n\nMARS Model Results Visualisation containing variables and their relationships retrieved through the plotmo package."
  },
  {
    "objectID": "posts/2022 Ask A Manager Salary Survey/index.html#keras-gun-to-a-knife-fight",
    "href": "posts/2022 Ask A Manager Salary Survey/index.html#keras-gun-to-a-knife-fight",
    "title": "2022 Ask A Manager Salary Survey",
    "section": "2.3 KERAS: GUN TO A KNIFE FIGHT",
    "text": "2.3 KERAS: GUN TO A KNIFE FIGHT\nWe haven’t had a significant difference between the OLS model and MARS model. Below, we use build a Allaire and Chollet (2022) regression model. It is mostly likely a computationally inefficient approach but worth exploring nonetheless. Fortunately, with a few changes to Chollet, Kalinowski, and Allaire (2022) code , we can fit a regression model through Keras in R. Below, we change the data to matrix format suitable for the type of model we build. Thereafter, we fit it through 500 epochs and visualise the Mean Absolute Error and Loss (Mean Squared Error) of the model.\n\n\nsee code\n#|fig-cap: Specifying a Keras model for regression\nlibrary(keras)\ntrain_data &lt;- model.matrix(full_comp_usd ~.,Training_Salary)[,-1]\ntrain_targets &lt;- Training_Salary$full_comp_usd\nbuild_model &lt;- function() {\nmodel &lt;- keras_model_sequential() %&gt;%\nlayer_dense(64, activation = \"relu\") %&gt;%\nlayer_dense(64, activation = \"relu\") %&gt;%\nlayer_dense(1)\nmodel %&gt;% compile(optimizer = \"rmsprop\",\nloss = \"mse\",\nmetrics = \"mae\")\nmodel\n}\n\n\n\n\nsee code\n#|echo: true\n#|fig-cap: Fitting a regression Keras model \n#|include: false\n#|message: false\n#|warning: false\n#|code-summary: Keras Model Fitting\n\n\nk &lt;- 4\nfold_id &lt;- sample(rep(1:k, length.out = nrow(train_data)))\nnum_epochs &lt;- 100\nall_scores &lt;- numeric()\nfor (i in 1:k) {\ncat(\"Processing fold #\", i, \"\\n\")\nval_indices &lt;- which(fold_id == i)\nval_data &lt;- train_data[val_indices, ]\nval_targets &lt;- train_targets[val_indices]\npartial_train_data &lt;- train_data[-val_indices, ]\npartial_train_targets &lt;- train_targets[-val_indices]\nmodel &lt;- build_model()\nmodel %&gt;% fit(\npartial_train_data,\npartial_train_targets,\nepochs = num_epochs,\nbatch_size = 16,\nverbose = 1\n)\nresults &lt;- model %&gt;% evaluate(val_data,\nval_targets, verbose = 0)\nall_scores[[i]] &lt;- results[['mae']]\n}\n\n\nProcessing fold # 1 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 126.0574 - mae: 11.2182\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 61.1302 - mae: 7.1237  \n147/528 [=======&gt;......................] - ETA: 0s - loss: 33.1162 - mae: 4.4617\n216/528 [===========&gt;..................] - ETA: 0s - loss: 23.1112 - mae: 3.3563\n291/528 [===============&gt;..............] - ETA: 0s - loss: 17.4401 - mae: 2.6785\n339/528 [==================&gt;...........] - ETA: 0s - loss: 15.0775 - mae: 2.3909\n418/528 [======================&gt;.......] - ETA: 0s - loss: 12.3692 - mae: 2.0475\n496/528 [===========================&gt;..] - ETA: 0s - loss: 10.5061 - mae: 1.8057\n528/528 [==============================] - 0s 713us/step - loss: 9.8964 - mae: 1.7256\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2770 - mae: 0.4014\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4705 - mae: 0.4672\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.4262 - mae: 0.4574\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.4067 - mae: 0.4550\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3998 - mae: 0.4482\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.4001 - mae: 0.4465\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3905 - mae: 0.4422\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3819 - mae: 0.4393\n528/528 [==============================] - 0s 723us/step - loss: 0.3791 - mae: 0.4386\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4633 - mae: 0.3749\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3202 - mae: 0.4176\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3408 - mae: 0.4259\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3214 - mae: 0.4186\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3406 - mae: 0.4225\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3509 - mae: 0.4262\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.3579 - mae: 0.4247\n528/528 [==============================] - 0s 657us/step - loss: 0.3526 - mae: 0.4233\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1418 - mae: 0.3218\n 66/528 [==&gt;...........................] - ETA: 0s - loss: 0.4135 - mae: 0.4302\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3970 - mae: 0.4293\n216/528 [===========&gt;..................] - ETA: 0s - loss: 0.3665 - mae: 0.4267\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3594 - mae: 0.4251\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3571 - mae: 0.4235\n443/528 [========================&gt;.....] - ETA: 0s - loss: 0.3459 - mae: 0.4211\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3494 - mae: 0.4223\n528/528 [==============================] - 0s 686us/step - loss: 0.3472 - mae: 0.4215\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0796 - mae: 0.2054\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3582 - mae: 0.4054\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3544 - mae: 0.4160\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3373 - mae: 0.4150\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3338 - mae: 0.4129\n385/528 [====================&gt;.........] - ETA: 0s - loss: 0.3488 - mae: 0.4182\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3498 - mae: 0.4189\n528/528 [==============================] - 0s 656us/step - loss: 0.3451 - mae: 0.4185\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2167 - mae: 0.3394\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3580 - mae: 0.4300\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3170 - mae: 0.4108\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3186 - mae: 0.4110\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3232 - mae: 0.4081\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3396 - mae: 0.4124\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3418 - mae: 0.4132\n528/528 [==============================] - 0s 629us/step - loss: 0.3386 - mae: 0.4137\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3205 - mae: 0.4736\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3182 - mae: 0.4078\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3577 - mae: 0.4137\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3402 - mae: 0.4121\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3293 - mae: 0.4091\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3416 - mae: 0.4140\n450/528 [========================&gt;.....] - ETA: 0s - loss: 0.3430 - mae: 0.4160\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3363 - mae: 0.4120\n528/528 [==============================] - 0s 677us/step - loss: 0.3360 - mae: 0.4121\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2535 - mae: 0.3797\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.3579 - mae: 0.4137\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3413 - mae: 0.4131\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.3256 - mae: 0.4104\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3311 - mae: 0.4082\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3483 - mae: 0.4136\n464/528 [=========================&gt;....] - ETA: 0s - loss: 0.3453 - mae: 0.4143\n528/528 [==============================] - 0s 655us/step - loss: 0.3365 - mae: 0.4119\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5731 - mae: 0.5989\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3136 - mae: 0.4049\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3118 - mae: 0.4055\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3185 - mae: 0.4100\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3105 - mae: 0.4095\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3222 - mae: 0.4101\n464/528 [=========================&gt;....] - ETA: 0s - loss: 0.3329 - mae: 0.4090\n528/528 [==============================] - 0s 656us/step - loss: 0.3368 - mae: 0.4108\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1535 - mae: 0.3112\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.4469 - mae: 0.4162\n140/528 [======&gt;.......................] - ETA: 0s - loss: 0.3774 - mae: 0.4084\n215/528 [===========&gt;..................] - ETA: 0s - loss: 0.3703 - mae: 0.4105\n276/528 [==============&gt;...............] - ETA: 0s - loss: 0.3537 - mae: 0.4077\n342/528 [==================&gt;...........] - ETA: 0s - loss: 0.3573 - mae: 0.4126\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3448 - mae: 0.4099\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3327 - mae: 0.4081\n528/528 [==============================] - 0s 702us/step - loss: 0.3334 - mae: 0.4097\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1353 - mae: 0.2563\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.3135 - mae: 0.4017\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3022 - mae: 0.4008\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3043 - mae: 0.4041\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3348 - mae: 0.4092\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3238 - mae: 0.4073\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3235 - mae: 0.4076\n528/528 [==============================] - 0s 649us/step - loss: 0.3338 - mae: 0.4096\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2844 - mae: 0.4436\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3139 - mae: 0.4190\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3393 - mae: 0.4168\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3346 - mae: 0.4163\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3474 - mae: 0.4145\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3427 - mae: 0.4151\n459/528 [=========================&gt;....] - ETA: 0s - loss: 0.3391 - mae: 0.4132\n528/528 [==============================] - 0s 665us/step - loss: 0.3334 - mae: 0.4114\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1464 - mae: 0.2955\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3683 - mae: 0.4137\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3640 - mae: 0.4097\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3713 - mae: 0.4188\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3480 - mae: 0.4120\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3491 - mae: 0.4120\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3386 - mae: 0.4118\n517/528 [============================&gt;.] - ETA: 0s - loss: 0.3309 - mae: 0.4097\n528/528 [==============================] - 0s 695us/step - loss: 0.3300 - mae: 0.4098\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1447 - mae: 0.2936\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.3571 - mae: 0.4052\n148/528 [=======&gt;......................] - ETA: 0s - loss: 0.3443 - mae: 0.4112\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3394 - mae: 0.4105\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3289 - mae: 0.4075\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3374 - mae: 0.4117\n448/528 [========================&gt;.....] - ETA: 0s - loss: 0.3277 - mae: 0.4092\n522/528 [============================&gt;.] - ETA: 0s - loss: 0.3294 - mae: 0.4084\n528/528 [==============================] - 0s 683us/step - loss: 0.3312 - mae: 0.4093\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1748 - mae: 0.3400\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3459 - mae: 0.4127\n139/528 [======&gt;.......................] - ETA: 0s - loss: 0.3158 - mae: 0.4067\n205/528 [==========&gt;...................] - ETA: 0s - loss: 0.3221 - mae: 0.4100\n257/528 [=============&gt;................] - ETA: 0s - loss: 0.3198 - mae: 0.4093\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3296 - mae: 0.4095\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3488 - mae: 0.4110\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3357 - mae: 0.4085\n528/528 [==============================] - 0s 745us/step - loss: 0.3324 - mae: 0.4086\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2509 - mae: 0.4055\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.2680 - mae: 0.3852\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3171 - mae: 0.3986\n204/528 [==========&gt;...................] - ETA: 0s - loss: 0.3141 - mae: 0.4003\n272/528 [==============&gt;...............] - ETA: 0s - loss: 0.3403 - mae: 0.4039\n348/528 [==================&gt;...........] - ETA: 0s - loss: 0.3303 - mae: 0.4045\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3245 - mae: 0.4039\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3260 - mae: 0.4038\n528/528 [==============================] - 0s 753us/step - loss: 0.3306 - mae: 0.4051\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.3039 - mae: 0.6222\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3300 - mae: 0.4224\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3093 - mae: 0.4049\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3201 - mae: 0.4095\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3387 - mae: 0.4126\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3327 - mae: 0.4096\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3231 - mae: 0.4070\n528/528 [==============================] - 0s 638us/step - loss: 0.3321 - mae: 0.4079\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1522 - mae: 0.2967\n 64/528 [==&gt;...........................] - ETA: 0s - loss: 0.3013 - mae: 0.3969\n132/528 [======&gt;.......................] - ETA: 0s - loss: 0.2879 - mae: 0.3957\n209/528 [==========&gt;...................] - ETA: 0s - loss: 0.2921 - mae: 0.3967\n288/528 [===============&gt;..............] - ETA: 0s - loss: 0.3056 - mae: 0.4016\n369/528 [===================&gt;..........] - ETA: 0s - loss: 0.3342 - mae: 0.4041\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3308 - mae: 0.4052\n526/528 [============================&gt;.] - ETA: 0s - loss: 0.3318 - mae: 0.4069\n528/528 [==============================] - 0s 672us/step - loss: 0.3310 - mae: 0.4065\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1544 - mae: 0.3278\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3114 - mae: 0.4074\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.2845 - mae: 0.4016\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3042 - mae: 0.4007\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3205 - mae: 0.4033\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3358 - mae: 0.4075\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3250 - mae: 0.4053\n528/528 [==============================] - 0s 638us/step - loss: 0.3285 - mae: 0.4055\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1910 - mae: 0.3706\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3421 - mae: 0.4113\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3075 - mae: 0.4004\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3063 - mae: 0.4010\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3054 - mae: 0.4013\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.2990 - mae: 0.4001\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3222 - mae: 0.4038\n528/528 [==============================] - 0s 634us/step - loss: 0.3302 - mae: 0.4061\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1678 - mae: 0.3549\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.3509 - mae: 0.4097\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3035 - mae: 0.4007\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3152 - mae: 0.4046\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3190 - mae: 0.4054\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3273 - mae: 0.4046\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3322 - mae: 0.4055\n528/528 [==============================] - 0s 639us/step - loss: 0.3287 - mae: 0.4052\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3238 - mae: 0.3982\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3718 - mae: 0.4115\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3504 - mae: 0.4087\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3574 - mae: 0.4102\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3438 - mae: 0.4059\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3340 - mae: 0.4055\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3271 - mae: 0.4042\n528/528 [==============================] - 0s 639us/step - loss: 0.3281 - mae: 0.4045\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2521 - mae: 0.4246\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3846 - mae: 0.3886\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3595 - mae: 0.4008\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3381 - mae: 0.4008\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3250 - mae: 0.3989\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3265 - mae: 0.4002\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3247 - mae: 0.4002\n528/528 [==============================] - 0s 616us/step - loss: 0.3243 - mae: 0.4009\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2452 - mae: 0.3830\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3572 - mae: 0.4205\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3258 - mae: 0.4106\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3201 - mae: 0.4056\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3269 - mae: 0.4042\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3154 - mae: 0.4011\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3262 - mae: 0.4025\n528/528 [==============================] - 0s 626us/step - loss: 0.3231 - mae: 0.4021\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3170 - mae: 0.4885\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2694 - mae: 0.3926\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3052 - mae: 0.4043\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3175 - mae: 0.4037\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3224 - mae: 0.4051\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3369 - mae: 0.4060\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3334 - mae: 0.4044\n528/528 [==============================] - 0s 631us/step - loss: 0.3276 - mae: 0.4030\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3578 - mae: 0.4897\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2672 - mae: 0.3799\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.2604 - mae: 0.3815\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.2919 - mae: 0.3911\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3162 - mae: 0.3968\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3231 - mae: 0.3977\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3294 - mae: 0.4019\n528/528 [==============================] - 0s 636us/step - loss: 0.3283 - mae: 0.4024\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7110 - mae: 0.5360\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2668 - mae: 0.3805\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2988 - mae: 0.3931\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3010 - mae: 0.3917\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3244 - mae: 0.3976\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3211 - mae: 0.3983\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3178 - mae: 0.4002\n528/528 [==============================] - 0s 631us/step - loss: 0.3255 - mae: 0.4009\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1933 - mae: 0.3276\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2661 - mae: 0.3884\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2997 - mae: 0.3990\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3336 - mae: 0.4019\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3417 - mae: 0.4080\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3295 - mae: 0.4061\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3226 - mae: 0.4041\n528/528 [==============================] - 0s 630us/step - loss: 0.3269 - mae: 0.4021\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1484 - mae: 0.2973\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3379 - mae: 0.4033\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3177 - mae: 0.4007\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.2994 - mae: 0.3956\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3113 - mae: 0.3984\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3223 - mae: 0.3980\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3235 - mae: 0.3980\n528/528 [==============================] - 0s 627us/step - loss: 0.3269 - mae: 0.4008\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1702 - mae: 0.3575\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2504 - mae: 0.3766\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3043 - mae: 0.3952\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3109 - mae: 0.3990\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3148 - mae: 0.3985\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3259 - mae: 0.4008\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3307 - mae: 0.4016\n528/528 [==============================] - 0s 649us/step - loss: 0.3247 - mae: 0.4007\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3574 - mae: 0.4718\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3401 - mae: 0.3945\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3584 - mae: 0.4100\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3510 - mae: 0.4121\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3418 - mae: 0.4076\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3289 - mae: 0.4056\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3332 - mae: 0.4035\n528/528 [==============================] - 0s 643us/step - loss: 0.3244 - mae: 0.4010\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3015 - mae: 0.4800\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2891 - mae: 0.3965\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2797 - mae: 0.3900\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3385 - mae: 0.4078\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3562 - mae: 0.4106\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3457 - mae: 0.4084\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3299 - mae: 0.4040\n528/528 [==============================] - 0s 638us/step - loss: 0.3247 - mae: 0.4017\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2024 - mae: 0.3949\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3309 - mae: 0.4041\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.3088 - mae: 0.3934\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.3038 - mae: 0.3928\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3013 - mae: 0.3935\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3169 - mae: 0.3969\n459/528 [=========================&gt;....] - ETA: 0s - loss: 0.3047 - mae: 0.3954\n528/528 [==============================] - 0s 659us/step - loss: 0.3235 - mae: 0.3996\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2254 - mae: 0.3602\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3581 - mae: 0.4031\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3590 - mae: 0.4109\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3279 - mae: 0.4017\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3330 - mae: 0.4010\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3294 - mae: 0.4008\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3217 - mae: 0.3996\n528/528 [==============================] - 0s 649us/step - loss: 0.3213 - mae: 0.3994\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1306 - mae: 0.2971\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2977 - mae: 0.3876\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3038 - mae: 0.3933\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.2908 - mae: 0.3920\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.2925 - mae: 0.3944\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3130 - mae: 0.3976\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3163 - mae: 0.3982\n528/528 [==============================] - 0s 644us/step - loss: 0.3252 - mae: 0.4003\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2466 - mae: 0.3739\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.2996 - mae: 0.3955\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.2950 - mae: 0.3911\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3105 - mae: 0.3960\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3143 - mae: 0.3984\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3170 - mae: 0.3961\n469/528 [=========================&gt;....] - ETA: 0s - loss: 0.3274 - mae: 0.3987\n528/528 [==============================] - 0s 649us/step - loss: 0.3237 - mae: 0.3990\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2933 - mae: 0.3702\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2949 - mae: 0.3874\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3065 - mae: 0.3999\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.2990 - mae: 0.3969\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.2949 - mae: 0.3961\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3029 - mae: 0.3989\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3275 - mae: 0.4014\n528/528 [==============================] - 0s 638us/step - loss: 0.3237 - mae: 0.3999\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2272 - mae: 0.3897\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2716 - mae: 0.3946\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3014 - mae: 0.3962\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.2904 - mae: 0.3962\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3103 - mae: 0.3961\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3086 - mae: 0.3963\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3093 - mae: 0.3961\n528/528 [==============================] - 0s 633us/step - loss: 0.3204 - mae: 0.3983\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1218 - mae: 0.3196\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2479 - mae: 0.3666\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2966 - mae: 0.3845\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3247 - mae: 0.3965\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3309 - mae: 0.3960\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3215 - mae: 0.3973\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3253 - mae: 0.3995\n528/528 [==============================] - 0s 663us/step - loss: 0.3219 - mae: 0.3997\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.5501 - mae: 0.7567\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4284 - mae: 0.4244\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3928 - mae: 0.4082\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3508 - mae: 0.4037\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3296 - mae: 0.3985\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3357 - mae: 0.4025\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3291 - mae: 0.4005\n528/528 [==============================] - 0s 644us/step - loss: 0.3195 - mae: 0.3973\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2333 - mae: 0.4069\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2774 - mae: 0.3933\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2963 - mae: 0.3955\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.2955 - mae: 0.3929\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3098 - mae: 0.3973\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3228 - mae: 0.3967\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3118 - mae: 0.3959\n528/528 [==============================] - 0s 647us/step - loss: 0.3209 - mae: 0.3957\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1482 - mae: 0.2896\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2809 - mae: 0.3903\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.2897 - mae: 0.3914\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.2751 - mae: 0.3842\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3224 - mae: 0.3951\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3242 - mae: 0.3962\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3154 - mae: 0.3940\n528/528 [==============================] - 0s 637us/step - loss: 0.3207 - mae: 0.3961\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1003 - mae: 0.2170\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2567 - mae: 0.3768\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2742 - mae: 0.3818\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.2804 - mae: 0.3868\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3108 - mae: 0.3930\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3147 - mae: 0.3950\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3209 - mae: 0.3966\n528/528 [==============================] - 0s 626us/step - loss: 0.3224 - mae: 0.3969\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0990 - mae: 0.2693\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3549 - mae: 0.3957\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3226 - mae: 0.3978\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3444 - mae: 0.4018\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3295 - mae: 0.3996\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3240 - mae: 0.3986\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3275 - mae: 0.4015\n528/528 [==============================] - 0s 632us/step - loss: 0.3220 - mae: 0.3992\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2084 - mae: 0.3779\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2822 - mae: 0.3879\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3540 - mae: 0.4071\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3228 - mae: 0.4019\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3084 - mae: 0.3987\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3055 - mae: 0.3952\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3131 - mae: 0.3951\n528/528 [==============================] - 0s 638us/step - loss: 0.3205 - mae: 0.3963\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2825 - mae: 0.4086\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.3158 - mae: 0.3944\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.2937 - mae: 0.3933\n223/528 [===========&gt;..................] - ETA: 0s - loss: 0.3069 - mae: 0.3949\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3226 - mae: 0.3986\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3302 - mae: 0.3970\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3331 - mae: 0.4012\n528/528 [==============================] - 0s 655us/step - loss: 0.3227 - mae: 0.3977\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3528 - mae: 0.4396\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3217 - mae: 0.4022\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3127 - mae: 0.4026\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3267 - mae: 0.4008\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3319 - mae: 0.3984\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3399 - mae: 0.4021\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3290 - mae: 0.3991\n528/528 [==============================] - 0s 633us/step - loss: 0.3221 - mae: 0.3979\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1976 - mae: 0.3511\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2928 - mae: 0.3956\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3102 - mae: 0.3907\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3203 - mae: 0.3943\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3356 - mae: 0.3968\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3268 - mae: 0.3981\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3269 - mae: 0.3986\n528/528 [==============================] - 0s 665us/step - loss: 0.3218 - mae: 0.3976\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1516 - mae: 0.3056\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3833 - mae: 0.4021\n122/528 [=====&gt;........................] - ETA: 0s - loss: 0.3515 - mae: 0.3985\n182/528 [=========&gt;....................] - ETA: 0s - loss: 0.3719 - mae: 0.4056\n260/528 [=============&gt;................] - ETA: 0s - loss: 0.3529 - mae: 0.4025\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3481 - mae: 0.4032\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3360 - mae: 0.4027\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3210 - mae: 0.3978\n528/528 [==============================] - 0s 710us/step - loss: 0.3164 - mae: 0.3960\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3422 - mae: 0.4675\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2912 - mae: 0.3925\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3057 - mae: 0.3978\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3035 - mae: 0.3992\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3039 - mae: 0.3984\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3080 - mae: 0.3999\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3187 - mae: 0.4002\n528/528 [==============================] - 0s 646us/step - loss: 0.3199 - mae: 0.3977\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2269 - mae: 0.3465\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3838 - mae: 0.4032\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3247 - mae: 0.3929\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3067 - mae: 0.3895\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3105 - mae: 0.3934\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3311 - mae: 0.3963\n464/528 [=========================&gt;....] - ETA: 0s - loss: 0.3242 - mae: 0.3970\n514/528 [============================&gt;.] - ETA: 0s - loss: 0.3212 - mae: 0.3974\n528/528 [==============================] - 0s 707us/step - loss: 0.3195 - mae: 0.3969\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6525 - mae: 0.5285\n 59/528 [==&gt;...........................] - ETA: 0s - loss: 0.3157 - mae: 0.3973\n129/528 [======&gt;.......................] - ETA: 0s - loss: 0.2941 - mae: 0.3999\n202/528 [==========&gt;...................] - ETA: 0s - loss: 0.2861 - mae: 0.3957\n284/528 [===============&gt;..............] - ETA: 0s - loss: 0.3124 - mae: 0.3961\n348/528 [==================&gt;...........] - ETA: 0s - loss: 0.3159 - mae: 0.3942\n427/528 [=======================&gt;......] - ETA: 0s - loss: 0.3219 - mae: 0.3969\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3198 - mae: 0.3979\n528/528 [==============================] - 0s 698us/step - loss: 0.3196 - mae: 0.3973\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3587 - mae: 0.5152\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3135 - mae: 0.4066\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2973 - mae: 0.3962\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3460 - mae: 0.3977\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3380 - mae: 0.4000\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3243 - mae: 0.3961\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3175 - mae: 0.3939\n528/528 [==============================] - 0s 638us/step - loss: 0.3203 - mae: 0.3961\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2835 - mae: 0.3947\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3447 - mae: 0.4041\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3265 - mae: 0.3992\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3320 - mae: 0.3963\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3304 - mae: 0.3974\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3296 - mae: 0.3987\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3256 - mae: 0.3995\n528/528 [==============================] - 0s 629us/step - loss: 0.3213 - mae: 0.3980\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1228 - mae: 0.2610\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2501 - mae: 0.3704\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.2898 - mae: 0.3821\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.2893 - mae: 0.3860\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.2894 - mae: 0.3888\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3197 - mae: 0.3947\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3223 - mae: 0.3976\n528/528 [==============================] - 0s 610us/step - loss: 0.3219 - mae: 0.3979\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1257 - mae: 0.2846\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2566 - mae: 0.3815\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3169 - mae: 0.3877\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3086 - mae: 0.3939\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3378 - mae: 0.4015\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3246 - mae: 0.3977\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3239 - mae: 0.3969\n528/528 [==============================] - 0s 633us/step - loss: 0.3205 - mae: 0.3969\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2571 - mae: 0.4048\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2772 - mae: 0.3938\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3247 - mae: 0.3945\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3159 - mae: 0.3944\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3149 - mae: 0.3944\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3346 - mae: 0.3984\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3249 - mae: 0.3970\n528/528 [==============================] - 0s 649us/step - loss: 0.3176 - mae: 0.3940\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2353 - mae: 0.3647\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3607 - mae: 0.3964\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3544 - mae: 0.4065\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3584 - mae: 0.4031\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3396 - mae: 0.3997\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3280 - mae: 0.3983\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3214 - mae: 0.3962\n528/528 [==============================] - 0s 645us/step - loss: 0.3194 - mae: 0.3965\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3315 - mae: 0.4571\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3051 - mae: 0.4016\n147/528 [=======&gt;......................] - ETA: 0s - loss: 0.3160 - mae: 0.4000\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3072 - mae: 0.3946\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3238 - mae: 0.3942\n370/528 [====================&gt;.........] - ETA: 0s - loss: 0.3249 - mae: 0.3977\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3310 - mae: 0.3994\n524/528 [============================&gt;.] - ETA: 0s - loss: 0.3210 - mae: 0.3967\n528/528 [==============================] - 0s 679us/step - loss: 0.3217 - mae: 0.3973\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.9141 - mae: 0.6449\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3077 - mae: 0.3916\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3030 - mae: 0.3903\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.2953 - mae: 0.3876\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.2991 - mae: 0.3911\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3133 - mae: 0.3957\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3191 - mae: 0.3945\n528/528 [==============================] - 0s 647us/step - loss: 0.3190 - mae: 0.3933\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.7307 - mae: 0.7226\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3233 - mae: 0.3999\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3098 - mae: 0.3968\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.2899 - mae: 0.3884\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3086 - mae: 0.3919\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3297 - mae: 0.3945\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3234 - mae: 0.3941\n528/528 [==============================] - 0s 637us/step - loss: 0.3202 - mae: 0.3933\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2079 - mae: 0.3427\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2793 - mae: 0.3846\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2878 - mae: 0.3844\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3185 - mae: 0.3913\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3225 - mae: 0.3964\n366/528 [===================&gt;..........] - ETA: 0s - loss: 0.3153 - mae: 0.3955\n437/528 [=======================&gt;......] - ETA: 0s - loss: 0.3241 - mae: 0.3965\n515/528 [============================&gt;.] - ETA: 0s - loss: 0.3175 - mae: 0.3938\n528/528 [==============================] - 0s 689us/step - loss: 0.3200 - mae: 0.3948\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2223 - mae: 0.3734\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2887 - mae: 0.3907\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2966 - mae: 0.3845\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3068 - mae: 0.3924\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3062 - mae: 0.3900\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3126 - mae: 0.3935\n451/528 [========================&gt;.....] - ETA: 0s - loss: 0.3118 - mae: 0.3945\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3210 - mae: 0.3950\n528/528 [==============================] - 0s 678us/step - loss: 0.3206 - mae: 0.3949\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1687 - mae: 0.2952\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.2723 - mae: 0.3801\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2837 - mae: 0.3865\n202/528 [==========&gt;...................] - ETA: 0s - loss: 0.2911 - mae: 0.3895\n261/528 [=============&gt;................] - ETA: 0s - loss: 0.3044 - mae: 0.3958\n341/528 [==================&gt;...........] - ETA: 0s - loss: 0.2934 - mae: 0.3919\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3005 - mae: 0.3905\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3182 - mae: 0.3942\n528/528 [==============================] - 0s 733us/step - loss: 0.3184 - mae: 0.3947\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0761 - mae: 0.2103\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2612 - mae: 0.3794\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2803 - mae: 0.3907\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.2791 - mae: 0.3876\n271/528 [==============&gt;...............] - ETA: 0s - loss: 0.2994 - mae: 0.3901\n348/528 [==================&gt;...........] - ETA: 0s - loss: 0.3015 - mae: 0.3906\n427/528 [=======================&gt;......] - ETA: 0s - loss: 0.3010 - mae: 0.3891\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3118 - mae: 0.3917\n528/528 [==============================] - 0s 709us/step - loss: 0.3150 - mae: 0.3936\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1518 - mae: 0.3291\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.3045 - mae: 0.3852\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2876 - mae: 0.3830\n220/528 [===========&gt;..................] - ETA: 0s - loss: 0.3183 - mae: 0.3924\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3114 - mae: 0.3912\n369/528 [===================&gt;..........] - ETA: 0s - loss: 0.3287 - mae: 0.3959\n440/528 [========================&gt;.....] - ETA: 0s - loss: 0.3241 - mae: 0.3952\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3141 - mae: 0.3930\n528/528 [==============================] - 0s 701us/step - loss: 0.3190 - mae: 0.3940\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2736 - mae: 0.4402\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3089 - mae: 0.3988\n140/528 [======&gt;.......................] - ETA: 0s - loss: 0.3283 - mae: 0.3972\n214/528 [===========&gt;..................] - ETA: 0s - loss: 0.3264 - mae: 0.3961\n286/528 [===============&gt;..............] - ETA: 0s - loss: 0.3223 - mae: 0.3974\n359/528 [===================&gt;..........] - ETA: 0s - loss: 0.3154 - mae: 0.3958\n430/528 [=======================&gt;......] - ETA: 0s - loss: 0.3173 - mae: 0.3933\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3188 - mae: 0.3941\n528/528 [==============================] - 0s 709us/step - loss: 0.3184 - mae: 0.3934\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2324 - mae: 0.4266\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3471 - mae: 0.3879\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3052 - mae: 0.3861\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3133 - mae: 0.3882\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.2941 - mae: 0.3846\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.2973 - mae: 0.3866\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.2988 - mae: 0.3886\n528/528 [==============================] - 0s 651us/step - loss: 0.3156 - mae: 0.3927\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2175 - mae: 0.3774\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.3011 - mae: 0.4023\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.2916 - mae: 0.3959\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.2969 - mae: 0.3917\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3145 - mae: 0.3930\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3100 - mae: 0.3927\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3139 - mae: 0.3929\n528/528 [==============================] - 0s 645us/step - loss: 0.3179 - mae: 0.3936\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3765 - mae: 0.4813\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3098 - mae: 0.3910\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3140 - mae: 0.3970\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.2956 - mae: 0.3926\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.2934 - mae: 0.3926\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3234 - mae: 0.3977\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3098 - mae: 0.3926\n528/528 [==============================] - 0s 644us/step - loss: 0.3136 - mae: 0.3930\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4284 - mae: 0.5007\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3114 - mae: 0.4045\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3182 - mae: 0.3971\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3135 - mae: 0.3921\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3354 - mae: 0.3931\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3243 - mae: 0.3918\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3238 - mae: 0.3915\n528/528 [==============================] - 0s 660us/step - loss: 0.3211 - mae: 0.3939\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1994 - mae: 0.3185\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2926 - mae: 0.3912\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3327 - mae: 0.3975\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3166 - mae: 0.3935\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3178 - mae: 0.3967\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3110 - mae: 0.3931\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3197 - mae: 0.3938\n528/528 [==============================] - 0s 633us/step - loss: 0.3177 - mae: 0.3932\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2692 - mae: 0.4120\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3244 - mae: 0.4050\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2835 - mae: 0.3887\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3132 - mae: 0.3928\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3259 - mae: 0.3951\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3109 - mae: 0.3925\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3227 - mae: 0.3965\n528/528 [==============================] - 0s 647us/step - loss: 0.3130 - mae: 0.3929\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1247 - mae: 0.2911\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3098 - mae: 0.3817\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.2937 - mae: 0.3878\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3428 - mae: 0.3927\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3337 - mae: 0.3919\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3295 - mae: 0.3944\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3223 - mae: 0.3935\n528/528 [==============================] - 0s 632us/step - loss: 0.3186 - mae: 0.3939\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1673 - mae: 0.3173\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2971 - mae: 0.3923\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2970 - mae: 0.3966\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.2954 - mae: 0.3967\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3273 - mae: 0.3984\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3374 - mae: 0.3983\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3263 - mae: 0.3954\n528/528 [==============================] - 0s 637us/step - loss: 0.3190 - mae: 0.3927\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1948 - mae: 0.3531\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3715 - mae: 0.4055\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3072 - mae: 0.3872\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.2946 - mae: 0.3820\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3091 - mae: 0.3850\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3089 - mae: 0.3890\n469/528 [=========================&gt;....] - ETA: 0s - loss: 0.3033 - mae: 0.3885\n528/528 [==============================] - 0s 647us/step - loss: 0.3185 - mae: 0.3915\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2641 - mae: 0.4369\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3233 - mae: 0.3812\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3035 - mae: 0.3883\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3060 - mae: 0.3934\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3025 - mae: 0.3938\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3234 - mae: 0.3974\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3166 - mae: 0.3943\n528/528 [==============================] - 0s 628us/step - loss: 0.3135 - mae: 0.3932\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1787 - mae: 0.3260\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3094 - mae: 0.3904\n145/528 [=======&gt;......................] - ETA: 0s - loss: 0.3351 - mae: 0.4017\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3374 - mae: 0.3981\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3312 - mae: 0.3957\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3252 - mae: 0.3948\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3253 - mae: 0.3939\n528/528 [==============================] - 0s 647us/step - loss: 0.3181 - mae: 0.3927\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4693 - mae: 0.4357\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2690 - mae: 0.3791\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3211 - mae: 0.3920\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3096 - mae: 0.3905\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3317 - mae: 0.3962\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3222 - mae: 0.3942\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3100 - mae: 0.3900\n528/528 [==============================] - 0s 654us/step - loss: 0.3168 - mae: 0.3927\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1123 - mae: 0.3045\n 62/528 [==&gt;...........................] - ETA: 0s - loss: 0.2455 - mae: 0.3734\n125/528 [======&gt;.......................] - ETA: 0s - loss: 0.2720 - mae: 0.3788\n204/528 [==========&gt;...................] - ETA: 0s - loss: 0.3350 - mae: 0.3894\n282/528 [===============&gt;..............] - ETA: 0s - loss: 0.3224 - mae: 0.3893\n360/528 [===================&gt;..........] - ETA: 0s - loss: 0.3108 - mae: 0.3876\n440/528 [========================&gt;.....] - ETA: 0s - loss: 0.3080 - mae: 0.3888\n515/528 [============================&gt;.] - ETA: 0s - loss: 0.3099 - mae: 0.3904\n528/528 [==============================] - 0s 685us/step - loss: 0.3156 - mae: 0.3928\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1860 - mae: 0.3151\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2670 - mae: 0.3909\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2718 - mae: 0.3861\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.2876 - mae: 0.3860\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.2953 - mae: 0.3917\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3119 - mae: 0.3951\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3207 - mae: 0.3956\n528/528 [==============================] - 0s 641us/step - loss: 0.3162 - mae: 0.3941\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2716 - mae: 0.3972\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3018 - mae: 0.3903\n131/528 [======&gt;.......................] - ETA: 0s - loss: 0.3146 - mae: 0.3887\n188/528 [=========&gt;....................] - ETA: 0s - loss: 0.3090 - mae: 0.3907\n265/528 [==============&gt;...............] - ETA: 0s - loss: 0.3427 - mae: 0.3959\n344/528 [==================&gt;...........] - ETA: 0s - loss: 0.3226 - mae: 0.3917\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3116 - mae: 0.3904\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3184 - mae: 0.3946\n528/528 [==============================] - 0s 699us/step - loss: 0.3159 - mae: 0.3940\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2409 - mae: 0.3391\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3381 - mae: 0.3980\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3167 - mae: 0.3955\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3623 - mae: 0.3980\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3437 - mae: 0.3978\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3329 - mae: 0.3965\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3161 - mae: 0.3921\n528/528 [==============================] - 0s 636us/step - loss: 0.3146 - mae: 0.3913\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3694 - mae: 0.4462\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3085 - mae: 0.3897\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3272 - mae: 0.3979\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3127 - mae: 0.3946\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.2949 - mae: 0.3869\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.2935 - mae: 0.3874\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3047 - mae: 0.3894\n528/528 [==============================] - 0s 655us/step - loss: 0.3159 - mae: 0.3928\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4882 - mae: 0.4575\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3125 - mae: 0.3960\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2914 - mae: 0.3853\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3068 - mae: 0.3904\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3126 - mae: 0.3944\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3306 - mae: 0.3980\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3212 - mae: 0.3948\n528/528 [==============================] - 0s 643us/step - loss: 0.3168 - mae: 0.3939\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2681 - mae: 0.4350\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2355 - mae: 0.3678\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3168 - mae: 0.3761\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3199 - mae: 0.3846\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3062 - mae: 0.3821\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3183 - mae: 0.3871\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3133 - mae: 0.3889\n528/528 [==============================] - 0s 637us/step - loss: 0.3171 - mae: 0.3910\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.5762 - mae: 0.6439\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3457 - mae: 0.3892\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3155 - mae: 0.3847\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3240 - mae: 0.3869\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3025 - mae: 0.3844\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3088 - mae: 0.3862\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3203 - mae: 0.3905\n528/528 [==============================] - 0s 656us/step - loss: 0.3181 - mae: 0.3919\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1876 - mae: 0.3721\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2577 - mae: 0.3719\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3199 - mae: 0.3844\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3062 - mae: 0.3851\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.2981 - mae: 0.3826\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3044 - mae: 0.3885\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3005 - mae: 0.3898\n528/528 [==============================] - 0s 654us/step - loss: 0.3143 - mae: 0.3933\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.0022 - mae: 0.5524\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3504 - mae: 0.3957\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3211 - mae: 0.3895\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3063 - mae: 0.3864\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3171 - mae: 0.3917\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3149 - mae: 0.3926\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3104 - mae: 0.3915\n528/528 [==============================] - 0s 633us/step - loss: 0.3154 - mae: 0.3929\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1757 - mae: 0.3420\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4062 - mae: 0.4123\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3242 - mae: 0.3903\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3122 - mae: 0.3880\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3228 - mae: 0.3917\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3151 - mae: 0.3900\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3193 - mae: 0.3906\n528/528 [==============================] - 0s 631us/step - loss: 0.3154 - mae: 0.3909\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3012 - mae: 0.4167\n 65/528 [==&gt;...........................] - ETA: 0s - loss: 0.2795 - mae: 0.3762\n138/528 [======&gt;.......................] - ETA: 0s - loss: 0.2817 - mae: 0.3840\n211/528 [==========&gt;...................] - ETA: 0s - loss: 0.2829 - mae: 0.3846\n289/528 [===============&gt;..............] - ETA: 0s - loss: 0.2812 - mae: 0.3837\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.2876 - mae: 0.3862\n446/528 [========================&gt;.....] - ETA: 0s - loss: 0.3021 - mae: 0.3883\n526/528 [============================&gt;.] - ETA: 0s - loss: 0.3150 - mae: 0.3909\n528/528 [==============================] - 0s 685us/step - loss: 0.3151 - mae: 0.3909\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4370 - mae: 0.4944\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3306 - mae: 0.3951\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3294 - mae: 0.4007\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3270 - mae: 0.3972\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3089 - mae: 0.3928\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3215 - mae: 0.3927\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3149 - mae: 0.3915\n528/528 [==============================] - 0s 638us/step - loss: 0.3156 - mae: 0.3909\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1181 - mae: 0.2911\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3021 - mae: 0.3956\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3038 - mae: 0.3935\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3044 - mae: 0.3946\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3093 - mae: 0.3944\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3057 - mae: 0.3937\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.2983 - mae: 0.3897\n528/528 [==============================] - 0s 632us/step - loss: 0.3156 - mae: 0.3918\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2597 - mae: 0.3579\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3113 - mae: 0.3913\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2885 - mae: 0.3876\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.2904 - mae: 0.3885\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3086 - mae: 0.3885\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3199 - mae: 0.3901\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3245 - mae: 0.3936\n528/528 [==============================] - 0s 649us/step - loss: 0.3148 - mae: 0.3908\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2079 - mae: 0.4206\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3120 - mae: 0.3823\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3301 - mae: 0.3875\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3163 - mae: 0.3864\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3248 - mae: 0.3886\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3170 - mae: 0.3884\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3090 - mae: 0.3883\n528/528 [==============================] - 0s 615us/step - loss: 0.3159 - mae: 0.3909\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3242 - mae: 0.4108\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2673 - mae: 0.3818\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.2687 - mae: 0.3839\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.2892 - mae: 0.3876\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.2830 - mae: 0.3873\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3014 - mae: 0.3896\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3160 - mae: 0.3922\n528/528 [==============================] - 0s 647us/step - loss: 0.3169 - mae: 0.3932\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.2425 - mae: 0.5937\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2374 - mae: 0.3660\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3410 - mae: 0.3918\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3175 - mae: 0.3906\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3120 - mae: 0.3885\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3130 - mae: 0.3882\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3161 - mae: 0.3920\n528/528 [==============================] - 0s 670us/step - loss: 0.3136 - mae: 0.3921\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1325 - mae: 0.3113\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2740 - mae: 0.3807\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2751 - mae: 0.3745\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.2608 - mae: 0.3759\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.2784 - mae: 0.3841\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.2822 - mae: 0.3877\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.2902 - mae: 0.3901\n528/528 [==============================] - 0s 638us/step - loss: 0.3142 - mae: 0.3940\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1052 - mae: 0.2800\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2595 - mae: 0.3703\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.2774 - mae: 0.3807\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3010 - mae: 0.3857\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3032 - mae: 0.3870\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3149 - mae: 0.3880\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3162 - mae: 0.3892\n528/528 [==============================] - 0s 617us/step - loss: 0.3175 - mae: 0.3897\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3221 - mae: 0.4319\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2614 - mae: 0.3785\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2995 - mae: 0.3838\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3050 - mae: 0.3880\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3249 - mae: 0.3938\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3211 - mae: 0.3936\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3189 - mae: 0.3918\n528/528 [==============================] - 0s 652us/step - loss: 0.3151 - mae: 0.3913\nProcessing fold # 2 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 119.9420 - mae: 10.9225\n 65/528 [==&gt;...........................] - ETA: 0s - loss: 47.1659 - mae: 5.9911  \n144/528 [=======&gt;......................] - ETA: 0s - loss: 23.5625 - mae: 3.5454\n224/528 [===========&gt;..................] - ETA: 0s - loss: 15.6826 - mae: 2.5910\n305/528 [================&gt;.............] - ETA: 0s - loss: 11.8764 - mae: 2.1074\n388/528 [=====================&gt;........] - ETA: 0s - loss: 9.4857 - mae: 1.7852 \n471/528 [=========================&gt;....] - ETA: 0s - loss: 7.9488 - mae: 1.5672\n528/528 [==============================] - 0s 646us/step - loss: 7.1510 - mae: 1.4515\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2294 - mae: 0.3934\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4442 - mae: 0.4575\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3954 - mae: 0.4459\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3694 - mae: 0.4403\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3938 - mae: 0.4437\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3898 - mae: 0.4449\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.4091 - mae: 0.4468\n528/528 [==============================] - 0s 634us/step - loss: 0.4306 - mae: 0.4490\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3350 - mae: 0.4629\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3605 - mae: 0.4297\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3851 - mae: 0.4308\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.4328 - mae: 0.4387\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.4122 - mae: 0.4381\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.4089 - mae: 0.4371\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.4091 - mae: 0.4381\n528/528 [==============================] - 0s 654us/step - loss: 0.3989 - mae: 0.4346\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2060 - mae: 0.3412\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3369 - mae: 0.4136\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3120 - mae: 0.4153\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3253 - mae: 0.4225\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3777 - mae: 0.4274\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3745 - mae: 0.4262\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3765 - mae: 0.4289\n528/528 [==============================] - 0s 628us/step - loss: 0.3924 - mae: 0.4300\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1838 - mae: 0.3133\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2931 - mae: 0.4116\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3070 - mae: 0.4138\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3999 - mae: 0.4277\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3788 - mae: 0.4251\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3588 - mae: 0.4198\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3737 - mae: 0.4224\n528/528 [==============================] - 0s 639us/step - loss: 0.3881 - mae: 0.4256\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2406 - mae: 0.4031\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.2893 - mae: 0.4098\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3767 - mae: 0.4268\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3807 - mae: 0.4286\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3621 - mae: 0.4253\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3674 - mae: 0.4264\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3916 - mae: 0.4283\n528/528 [==============================] - 0s 628us/step - loss: 0.3854 - mae: 0.4273\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6272 - mae: 0.6058\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3672 - mae: 0.4243\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3260 - mae: 0.4153\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3352 - mae: 0.4095\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3674 - mae: 0.4154\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3649 - mae: 0.4203\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3821 - mae: 0.4242\n528/528 [==============================] - 0s 629us/step - loss: 0.3845 - mae: 0.4239\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4332 - mae: 0.5752\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3340 - mae: 0.4125\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3875 - mae: 0.4235\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3842 - mae: 0.4207\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3899 - mae: 0.4196\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3724 - mae: 0.4177\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3737 - mae: 0.4187\n528/528 [==============================] - 0s 635us/step - loss: 0.3803 - mae: 0.4218\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2875 - mae: 0.4315\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4599 - mae: 0.4283\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.4509 - mae: 0.4295\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.4461 - mae: 0.4283\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.4154 - mae: 0.4257\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.4063 - mae: 0.4255\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3892 - mae: 0.4222\n528/528 [==============================] - 0s 676us/step - loss: 0.3802 - mae: 0.4218\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3230 - mae: 0.4557\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2836 - mae: 0.3930\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3619 - mae: 0.4140\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3869 - mae: 0.4183\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3770 - mae: 0.4143\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3847 - mae: 0.4179\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3762 - mae: 0.4191\n528/528 [==============================] - 0s 636us/step - loss: 0.3782 - mae: 0.4184\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3035 - mae: 0.4970\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3409 - mae: 0.4049\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3539 - mae: 0.4106\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3719 - mae: 0.4174\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3868 - mae: 0.4233\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3733 - mae: 0.4185\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3800 - mae: 0.4197\n528/528 [==============================] - 0s 630us/step - loss: 0.3744 - mae: 0.4189\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1777 - mae: 0.3429\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3114 - mae: 0.3802\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3500 - mae: 0.4015\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.4071 - mae: 0.4168\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3855 - mae: 0.4158\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3853 - mae: 0.4168\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3750 - mae: 0.4177\n528/528 [==============================] - 0s 630us/step - loss: 0.3726 - mae: 0.4184\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1763 - mae: 0.3542\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3400 - mae: 0.4055\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3601 - mae: 0.4019\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3474 - mae: 0.4043\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.4015 - mae: 0.4179\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3854 - mae: 0.4174\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3792 - mae: 0.4165\n528/528 [==============================] - 0s 633us/step - loss: 0.3751 - mae: 0.4161\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1506 - mae: 0.3098\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3593 - mae: 0.4089\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3701 - mae: 0.4144\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3808 - mae: 0.4167\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3715 - mae: 0.4147\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3558 - mae: 0.4118\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3730 - mae: 0.4153\n528/528 [==============================] - 0s 637us/step - loss: 0.3740 - mae: 0.4156\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2649 - mae: 0.4296\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4506 - mae: 0.4278\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3919 - mae: 0.4182\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3842 - mae: 0.4124\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3530 - mae: 0.4060\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3761 - mae: 0.4135\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3798 - mae: 0.4148\n528/528 [==============================] - 0s 646us/step - loss: 0.3700 - mae: 0.4146\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1634 - mae: 0.3222\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3742 - mae: 0.4133\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3947 - mae: 0.4121\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3834 - mae: 0.4126\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3788 - mae: 0.4131\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3848 - mae: 0.4141\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3749 - mae: 0.4127\n528/528 [==============================] - 0s 651us/step - loss: 0.3718 - mae: 0.4141\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1480 - mae: 0.3297\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3487 - mae: 0.4062\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3453 - mae: 0.4082\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3739 - mae: 0.4145\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3769 - mae: 0.4131\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3600 - mae: 0.4114\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3491 - mae: 0.4101\n528/528 [==============================] - 0s 662us/step - loss: 0.3697 - mae: 0.4124\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2065 - mae: 0.3317\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4743 - mae: 0.4308\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3810 - mae: 0.4130\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3488 - mae: 0.4064\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3552 - mae: 0.4076\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3429 - mae: 0.4073\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3606 - mae: 0.4109\n528/528 [==============================] - 0s 658us/step - loss: 0.3664 - mae: 0.4111\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3313 - mae: 0.4470\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2993 - mae: 0.4077\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2922 - mae: 0.4004\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3335 - mae: 0.4029\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3502 - mae: 0.4066\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3721 - mae: 0.4121\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3686 - mae: 0.4104\n528/528 [==============================] - 0s 636us/step - loss: 0.3658 - mae: 0.4103\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1553 - mae: 0.3225\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4547 - mae: 0.4311\n148/528 [=======&gt;......................] - ETA: 0s - loss: 0.3972 - mae: 0.4168\n209/528 [==========&gt;...................] - ETA: 0s - loss: 0.3681 - mae: 0.4122\n265/528 [==============&gt;...............] - ETA: 0s - loss: 0.3853 - mae: 0.4168\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3642 - mae: 0.4123\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3788 - mae: 0.4132\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3703 - mae: 0.4132\n528/528 [==============================] - 0s 713us/step - loss: 0.3660 - mae: 0.4132\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4034 - mae: 0.5714\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3786 - mae: 0.4266\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.4206 - mae: 0.4276\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.4124 - mae: 0.4188\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3844 - mae: 0.4154\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3583 - mae: 0.4101\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3719 - mae: 0.4122\n528/528 [==============================] - 0s 662us/step - loss: 0.3644 - mae: 0.4107\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1977 - mae: 0.3498\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3519 - mae: 0.4000\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3694 - mae: 0.4103\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3323 - mae: 0.4036\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3576 - mae: 0.4040\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3501 - mae: 0.4036\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3722 - mae: 0.4095\n521/528 [============================&gt;.] - ETA: 0s - loss: 0.3642 - mae: 0.4099\n528/528 [==============================] - 0s 690us/step - loss: 0.3628 - mae: 0.4097\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2295 - mae: 0.3987\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3179 - mae: 0.4065\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3128 - mae: 0.4048\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.3334 - mae: 0.4046\n284/528 [===============&gt;..............] - ETA: 0s - loss: 0.3360 - mae: 0.4082\n361/528 [===================&gt;..........] - ETA: 0s - loss: 0.3738 - mae: 0.4139\n435/528 [=======================&gt;......] - ETA: 0s - loss: 0.3594 - mae: 0.4111\n511/528 [============================&gt;.] - ETA: 0s - loss: 0.3684 - mae: 0.4109\n528/528 [==============================] - 0s 697us/step - loss: 0.3649 - mae: 0.4104\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 5.3360 - mae: 0.9647\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.4975 - mae: 0.4207\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.4293 - mae: 0.4125\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.4196 - mae: 0.4120\n297/528 [===============&gt;..............] - ETA: 0s - loss: 0.3892 - mae: 0.4110\n372/528 [====================&gt;.........] - ETA: 0s - loss: 0.3736 - mae: 0.4112\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3620 - mae: 0.4088\n524/528 [============================&gt;.] - ETA: 0s - loss: 0.3677 - mae: 0.4104\n528/528 [==============================] - 0s 678us/step - loss: 0.3667 - mae: 0.4102\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3292 - mae: 0.4431\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4036 - mae: 0.3998\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.4403 - mae: 0.4140\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.4303 - mae: 0.4173\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3898 - mae: 0.4100\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3684 - mae: 0.4107\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3762 - mae: 0.4116\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3632 - mae: 0.4092\n528/528 [==============================] - 0s 676us/step - loss: 0.3624 - mae: 0.4090\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 5.8050 - mae: 0.9896\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.4654 - mae: 0.4205\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.4163 - mae: 0.4137\n215/528 [===========&gt;..................] - ETA: 0s - loss: 0.4099 - mae: 0.4147\n272/528 [==============&gt;...............] - ETA: 0s - loss: 0.3985 - mae: 0.4131\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3802 - mae: 0.4108\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3766 - mae: 0.4096\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3740 - mae: 0.4087\n528/528 [==============================] - 0s 733us/step - loss: 0.3643 - mae: 0.4064\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2948 - mae: 0.3924\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.4492 - mae: 0.4209\n139/528 [======&gt;.......................] - ETA: 0s - loss: 0.3824 - mae: 0.4141\n208/528 [==========&gt;...................] - ETA: 0s - loss: 0.3611 - mae: 0.4102\n283/528 [===============&gt;..............] - ETA: 0s - loss: 0.3381 - mae: 0.4065\n354/528 [===================&gt;..........] - ETA: 0s - loss: 0.3426 - mae: 0.4067\n429/528 [=======================&gt;......] - ETA: 0s - loss: 0.3579 - mae: 0.4085\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3634 - mae: 0.4073\n528/528 [==============================] - 0s 698us/step - loss: 0.3623 - mae: 0.4074\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1856 - mae: 0.3571\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4422 - mae: 0.4124\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3900 - mae: 0.4114\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3842 - mae: 0.4111\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3601 - mae: 0.4091\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3633 - mae: 0.4115\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3507 - mae: 0.4102\n528/528 [==============================] - 0s 643us/step - loss: 0.3635 - mae: 0.4103\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1024 - mae: 0.2675\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4207 - mae: 0.4173\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3562 - mae: 0.4094\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3799 - mae: 0.4136\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3723 - mae: 0.4084\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3528 - mae: 0.4065\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3592 - mae: 0.4095\n528/528 [==============================] - 0s 658us/step - loss: 0.3618 - mae: 0.4096\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2038 - mae: 0.4093\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3097 - mae: 0.4038\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3131 - mae: 0.4014\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3240 - mae: 0.4034\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3246 - mae: 0.4008\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3574 - mae: 0.4031\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3515 - mae: 0.4047\n528/528 [==============================] - 0s 630us/step - loss: 0.3581 - mae: 0.4055\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1485 - mae: 0.2929\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4459 - mae: 0.4170\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3740 - mae: 0.4033\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.4071 - mae: 0.4147\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3724 - mae: 0.4078\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3667 - mae: 0.4080\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3564 - mae: 0.4051\n528/528 [==============================] - 0s 639us/step - loss: 0.3604 - mae: 0.4061\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3465 - mae: 0.4279\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3821 - mae: 0.4057\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3818 - mae: 0.4018\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3396 - mae: 0.3941\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3478 - mae: 0.3980\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3569 - mae: 0.4021\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3644 - mae: 0.4059\n528/528 [==============================] - 0s 632us/step - loss: 0.3584 - mae: 0.4048\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2196 - mae: 0.3956\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2688 - mae: 0.3821\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.2863 - mae: 0.3899\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3674 - mae: 0.3996\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3749 - mae: 0.4007\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3733 - mae: 0.4032\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3687 - mae: 0.4056\n528/528 [==============================] - 0s 639us/step - loss: 0.3611 - mae: 0.4046\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1896 - mae: 0.3009\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4086 - mae: 0.4118\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.4122 - mae: 0.4116\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3899 - mae: 0.4067\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3775 - mae: 0.4069\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3669 - mae: 0.4081\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3542 - mae: 0.4059\n528/528 [==============================] - 0s 637us/step - loss: 0.3582 - mae: 0.4059\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2879 - mae: 0.4506\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2743 - mae: 0.3971\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3797 - mae: 0.4040\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3530 - mae: 0.4021\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3455 - mae: 0.4039\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3313 - mae: 0.3986\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3619 - mae: 0.4040\n528/528 [==============================] - 0s 657us/step - loss: 0.3589 - mae: 0.4048\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1842 - mae: 0.3753\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3749 - mae: 0.4049\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3204 - mae: 0.3950\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3740 - mae: 0.4053\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3828 - mae: 0.4086\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3604 - mae: 0.4055\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3418 - mae: 0.4019\n528/528 [==============================] - 0s 641us/step - loss: 0.3573 - mae: 0.4039\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4273 - mae: 0.4802\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4022 - mae: 0.4044\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3839 - mae: 0.3997\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.4047 - mae: 0.4070\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3949 - mae: 0.4071\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3693 - mae: 0.4027\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3626 - mae: 0.4023\n528/528 [==============================] - 0s 634us/step - loss: 0.3561 - mae: 0.4016\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3115 - mae: 0.4385\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2752 - mae: 0.3932\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3349 - mae: 0.4108\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3418 - mae: 0.4033\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3584 - mae: 0.4044\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3449 - mae: 0.4019\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3675 - mae: 0.4029\n528/528 [==============================] - 0s 652us/step - loss: 0.3587 - mae: 0.4009\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2716 - mae: 0.4362\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3833 - mae: 0.4101\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3086 - mae: 0.3921\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3180 - mae: 0.3897\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3269 - mae: 0.3951\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3318 - mae: 0.3991\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3582 - mae: 0.4031\n528/528 [==============================] - 0s 638us/step - loss: 0.3591 - mae: 0.4051\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1569 - mae: 0.3501\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3169 - mae: 0.4070\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3600 - mae: 0.4084\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3605 - mae: 0.4067\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3646 - mae: 0.4102\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3678 - mae: 0.4063\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3615 - mae: 0.4039\n528/528 [==============================] - 0s 636us/step - loss: 0.3562 - mae: 0.4043\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2219 - mae: 0.3649\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3673 - mae: 0.4128\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3573 - mae: 0.4098\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3340 - mae: 0.4073\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3536 - mae: 0.4073\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3514 - mae: 0.4052\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3520 - mae: 0.4039\n528/528 [==============================] - 0s 635us/step - loss: 0.3583 - mae: 0.4040\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1491 - mae: 0.2973\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3233 - mae: 0.4012\n138/528 [======&gt;.......................] - ETA: 0s - loss: 0.3748 - mae: 0.4018\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.3330 - mae: 0.3944\n299/528 [===============&gt;..............] - ETA: 0s - loss: 0.3292 - mae: 0.3979\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3386 - mae: 0.4008\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3533 - mae: 0.4032\n528/528 [==============================] - 0s 655us/step - loss: 0.3572 - mae: 0.4028\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2805 - mae: 0.3588\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3292 - mae: 0.4119\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3193 - mae: 0.3986\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3283 - mae: 0.4004\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3275 - mae: 0.3991\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3643 - mae: 0.4055\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3622 - mae: 0.4042\n528/528 [==============================] - 0s 627us/step - loss: 0.3549 - mae: 0.4040\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4581 - mae: 0.5146\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4009 - mae: 0.4192\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3449 - mae: 0.4007\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3641 - mae: 0.4056\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3565 - mae: 0.4032\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3641 - mae: 0.4024\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3520 - mae: 0.4011\n528/528 [==============================] - 0s 634us/step - loss: 0.3555 - mae: 0.4013\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1294 - mae: 0.3207\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3739 - mae: 0.3835\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3340 - mae: 0.3883\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3505 - mae: 0.3926\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3714 - mae: 0.4024\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3630 - mae: 0.4047\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3496 - mae: 0.4031\n528/528 [==============================] - 0s 631us/step - loss: 0.3539 - mae: 0.4032\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5222 - mae: 0.5532\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3308 - mae: 0.3951\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3202 - mae: 0.3973\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3149 - mae: 0.3968\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3521 - mae: 0.4028\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3322 - mae: 0.3992\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3504 - mae: 0.4018\n528/528 [==============================] - 0s 638us/step - loss: 0.3550 - mae: 0.4028\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4195 - mae: 0.4103\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2983 - mae: 0.3990\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3259 - mae: 0.4075\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3264 - mae: 0.4043\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3466 - mae: 0.4075\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3377 - mae: 0.4023\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3324 - mae: 0.4001\n528/528 [==============================] - 0s 636us/step - loss: 0.3546 - mae: 0.4021\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1880 - mae: 0.3479\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2984 - mae: 0.4008\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.2723 - mae: 0.3871\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.2898 - mae: 0.3917\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3237 - mae: 0.3976\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3267 - mae: 0.3942\n449/528 [========================&gt;.....] - ETA: 0s - loss: 0.3470 - mae: 0.3976\n526/528 [============================&gt;.] - ETA: 0s - loss: 0.3556 - mae: 0.3995\n528/528 [==============================] - 0s 679us/step - loss: 0.3555 - mae: 0.3997\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1609 - mae: 0.3217\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3465 - mae: 0.3867\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3893 - mae: 0.4010\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3637 - mae: 0.4019\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3652 - mae: 0.4069\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3457 - mae: 0.4021\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3616 - mae: 0.4047\n528/528 [==============================] - 0s 638us/step - loss: 0.3514 - mae: 0.4026\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2153 - mae: 0.3233\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3294 - mae: 0.3858\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3396 - mae: 0.3831\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3595 - mae: 0.3934\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3370 - mae: 0.3932\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3514 - mae: 0.3969\n436/528 [=======================&gt;......] - ETA: 0s - loss: 0.3436 - mae: 0.3963\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3492 - mae: 0.3995\n528/528 [==============================] - 0s 715us/step - loss: 0.3557 - mae: 0.4004\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1768 - mae: 0.3516\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4038 - mae: 0.3956\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.4399 - mae: 0.4170\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.4075 - mae: 0.4072\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3982 - mae: 0.4078\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3799 - mae: 0.4038\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3571 - mae: 0.3997\n528/528 [==============================] - 0s 626us/step - loss: 0.3523 - mae: 0.3992\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1213 - mae: 0.2484\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2795 - mae: 0.3955\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3024 - mae: 0.3975\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3481 - mae: 0.4003\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3465 - mae: 0.4008\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3544 - mae: 0.4016\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3527 - mae: 0.3982\n528/528 [==============================] - 0s 623us/step - loss: 0.3523 - mae: 0.3997\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1626 - mae: 0.3280\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2905 - mae: 0.3932\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.2991 - mae: 0.3975\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3048 - mae: 0.3953\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3308 - mae: 0.3974\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3190 - mae: 0.3949\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3399 - mae: 0.3973\n528/528 [==============================] - 0s 634us/step - loss: 0.3541 - mae: 0.3998\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5679 - mae: 0.5910\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4053 - mae: 0.4061\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3331 - mae: 0.3968\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3131 - mae: 0.3953\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3355 - mae: 0.3992\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3596 - mae: 0.4022\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3454 - mae: 0.3995\n528/528 [==============================] - 0s 612us/step - loss: 0.3490 - mae: 0.3991\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2146 - mae: 0.3874\n 64/528 [==&gt;...........................] - ETA: 0s - loss: 0.2864 - mae: 0.3965\n139/528 [======&gt;.......................] - ETA: 0s - loss: 0.3690 - mae: 0.4035\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3335 - mae: 0.3970\n297/528 [===============&gt;..............] - ETA: 0s - loss: 0.3556 - mae: 0.3957\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.3541 - mae: 0.3954\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3571 - mae: 0.3982\n528/528 [==============================] - 0s 660us/step - loss: 0.3532 - mae: 0.3990\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1699 - mae: 0.3193\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.4100 - mae: 0.4056\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.4185 - mae: 0.4034\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3726 - mae: 0.3963\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3711 - mae: 0.3999\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3491 - mae: 0.3971\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3477 - mae: 0.3982\n528/528 [==============================] - 0s 639us/step - loss: 0.3532 - mae: 0.3981\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2551 - mae: 0.4159\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3564 - mae: 0.4021\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4015 - mae: 0.4078\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3741 - mae: 0.4088\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3531 - mae: 0.4042\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3598 - mae: 0.4019\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3594 - mae: 0.4000\n528/528 [==============================] - 0s 624us/step - loss: 0.3523 - mae: 0.3989\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1459 - mae: 0.2690\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3872 - mae: 0.4023\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3440 - mae: 0.3943\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3519 - mae: 0.4002\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3362 - mae: 0.4004\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3545 - mae: 0.4037\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3600 - mae: 0.4022\n528/528 [==============================] - 0s 620us/step - loss: 0.3544 - mae: 0.4005\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1917 - mae: 0.3731\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3506 - mae: 0.3976\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3062 - mae: 0.3909\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3087 - mae: 0.3941\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3672 - mae: 0.4031\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3749 - mae: 0.4055\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3572 - mae: 0.4007\n528/528 [==============================] - 0s 641us/step - loss: 0.3504 - mae: 0.4003\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1960 - mae: 0.3402\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.5363 - mae: 0.4472\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3907 - mae: 0.4082\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3454 - mae: 0.3992\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3804 - mae: 0.4035\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3578 - mae: 0.4009\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3440 - mae: 0.3982\n528/528 [==============================] - 0s 636us/step - loss: 0.3508 - mae: 0.3986\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1615 - mae: 0.3150\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3379 - mae: 0.3818\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3419 - mae: 0.3942\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3589 - mae: 0.3939\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3582 - mae: 0.3970\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3726 - mae: 0.3985\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3597 - mae: 0.3963\n528/528 [==============================] - 0s 665us/step - loss: 0.3541 - mae: 0.3984\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1646 - mae: 0.3183\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3811 - mae: 0.3979\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3883 - mae: 0.3981\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3974 - mae: 0.3973\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3649 - mae: 0.3957\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3743 - mae: 0.3998\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3591 - mae: 0.3973\n528/528 [==============================] - 0s 654us/step - loss: 0.3497 - mae: 0.3970\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2113 - mae: 0.3772\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4535 - mae: 0.4063\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3698 - mae: 0.3979\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3579 - mae: 0.3962\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3348 - mae: 0.3910\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3519 - mae: 0.3941\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3610 - mae: 0.3971\n528/528 [==============================] - 0s 634us/step - loss: 0.3514 - mae: 0.3954\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4084 - mae: 0.4905\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2528 - mae: 0.3800\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3025 - mae: 0.3927\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3439 - mae: 0.3968\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3291 - mae: 0.3941\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3472 - mae: 0.3950\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3334 - mae: 0.3931\n528/528 [==============================] - 0s 645us/step - loss: 0.3504 - mae: 0.3961\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1794 - mae: 0.3083\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2994 - mae: 0.4011\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3389 - mae: 0.4001\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3748 - mae: 0.4055\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3542 - mae: 0.4022\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3763 - mae: 0.4048\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3602 - mae: 0.4006\n528/528 [==============================] - 0s 650us/step - loss: 0.3490 - mae: 0.3986\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2037 - mae: 0.3626\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4116 - mae: 0.4056\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3464 - mae: 0.3993\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3719 - mae: 0.4012\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3544 - mae: 0.3994\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3471 - mae: 0.3975\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3547 - mae: 0.3985\n528/528 [==============================] - 0s 635us/step - loss: 0.3516 - mae: 0.3980\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2300 - mae: 0.3695\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3579 - mae: 0.4002\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3085 - mae: 0.3919\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3637 - mae: 0.4018\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3432 - mae: 0.3997\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3582 - mae: 0.3987\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3628 - mae: 0.3990\n520/528 [============================&gt;.] - ETA: 0s - loss: 0.3529 - mae: 0.3982\n528/528 [==============================] - 0s 686us/step - loss: 0.3515 - mae: 0.3982\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3162 - mae: 0.4457\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4326 - mae: 0.4134\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3847 - mae: 0.4021\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3865 - mae: 0.4037\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3660 - mae: 0.4001\n354/528 [===================&gt;..........] - ETA: 0s - loss: 0.3619 - mae: 0.4006\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3543 - mae: 0.3992\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3562 - mae: 0.3966\n528/528 [==============================] - 0s 723us/step - loss: 0.3493 - mae: 0.3966\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2562 - mae: 0.3863\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2809 - mae: 0.3974\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3546 - mae: 0.3990\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3542 - mae: 0.3978\n301/528 [================&gt;.............] - ETA: 0s - loss: 0.3595 - mae: 0.3990\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.3609 - mae: 0.3998\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3629 - mae: 0.3996\n528/528 [==============================] - 0s 665us/step - loss: 0.3496 - mae: 0.3956\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2819 - mae: 0.4452\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2845 - mae: 0.3740\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3408 - mae: 0.3808\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3471 - mae: 0.3913\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3458 - mae: 0.3927\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3566 - mae: 0.3935\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3453 - mae: 0.3944\n528/528 [==============================] - 0s 642us/step - loss: 0.3503 - mae: 0.3953\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1149 - mae: 0.2708\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3714 - mae: 0.4175\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3540 - mae: 0.4073\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3480 - mae: 0.4000\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3575 - mae: 0.3997\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3587 - mae: 0.3996\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3417 - mae: 0.3944\n528/528 [==============================] - 0s 668us/step - loss: 0.3493 - mae: 0.3957\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5007 - mae: 0.5053\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3262 - mae: 0.3906\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3649 - mae: 0.3936\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3347 - mae: 0.3914\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3648 - mae: 0.3976\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3469 - mae: 0.3936\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3526 - mae: 0.3950\n528/528 [==============================] - 0s 646us/step - loss: 0.3491 - mae: 0.3950\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2312 - mae: 0.3876\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3952 - mae: 0.3992\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3569 - mae: 0.3987\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3488 - mae: 0.3955\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3344 - mae: 0.3934\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3186 - mae: 0.3899\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3490 - mae: 0.3946\n528/528 [==============================] - 0s 647us/step - loss: 0.3513 - mae: 0.3960\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3389 - mae: 0.4149\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.5087 - mae: 0.4144\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.4871 - mae: 0.4138\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.4160 - mae: 0.4037\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3986 - mae: 0.4033\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3653 - mae: 0.3965\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3516 - mae: 0.3945\n528/528 [==============================] - 0s 664us/step - loss: 0.3474 - mae: 0.3955\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1661 - mae: 0.3317\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4350 - mae: 0.4142\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3635 - mae: 0.4050\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3491 - mae: 0.3956\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3565 - mae: 0.3952\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3375 - mae: 0.3917\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3552 - mae: 0.3964\n528/528 [==============================] - 0s 635us/step - loss: 0.3466 - mae: 0.3962\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2379 - mae: 0.3939\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3187 - mae: 0.3859\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2949 - mae: 0.3812\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.2777 - mae: 0.3797\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.2976 - mae: 0.3885\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3167 - mae: 0.3909\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3520 - mae: 0.3930\n528/528 [==============================] - 0s 648us/step - loss: 0.3469 - mae: 0.3945\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2635 - mae: 0.4174\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3713 - mae: 0.3953\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3280 - mae: 0.3965\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3303 - mae: 0.3960\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3074 - mae: 0.3893\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3298 - mae: 0.3912\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3523 - mae: 0.3960\n528/528 [==============================] - 0s 631us/step - loss: 0.3481 - mae: 0.3959\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0870 - mae: 0.2137\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3921 - mae: 0.3892\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3751 - mae: 0.3896\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3410 - mae: 0.3895\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3393 - mae: 0.3919\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3332 - mae: 0.3932\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3441 - mae: 0.3931\n528/528 [==============================] - 0s 664us/step - loss: 0.3490 - mae: 0.3941\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1625 - mae: 0.2957\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3339 - mae: 0.3949\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.4190 - mae: 0.4013\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3631 - mae: 0.3928\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3665 - mae: 0.3930\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3651 - mae: 0.3944\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3515 - mae: 0.3953\n522/528 [============================&gt;.] - ETA: 0s - loss: 0.3478 - mae: 0.3971\n528/528 [==============================] - 0s 687us/step - loss: 0.3489 - mae: 0.3972\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2239 - mae: 0.3342\n 59/528 [==&gt;...........................] - ETA: 0s - loss: 0.2696 - mae: 0.3846\n134/528 [======&gt;.......................] - ETA: 0s - loss: 0.3227 - mae: 0.3924\n203/528 [==========&gt;...................] - ETA: 0s - loss: 0.3273 - mae: 0.3974\n275/528 [==============&gt;...............] - ETA: 0s - loss: 0.3572 - mae: 0.4014\n355/528 [===================&gt;..........] - ETA: 0s - loss: 0.3466 - mae: 0.3962\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3504 - mae: 0.3954\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3521 - mae: 0.3949\n528/528 [==============================] - 0s 702us/step - loss: 0.3464 - mae: 0.3939\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2634 - mae: 0.4547\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3447 - mae: 0.3790\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3760 - mae: 0.3955\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3897 - mae: 0.4016\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3654 - mae: 0.4005\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3554 - mae: 0.3976\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3442 - mae: 0.3961\n528/528 [==============================] - 0s 648us/step - loss: 0.3460 - mae: 0.3938\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2175 - mae: 0.3498\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2604 - mae: 0.3813\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2982 - mae: 0.3808\n220/528 [===========&gt;..................] - ETA: 0s - loss: 0.3077 - mae: 0.3852\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3009 - mae: 0.3839\n366/528 [===================&gt;..........] - ETA: 0s - loss: 0.3109 - mae: 0.3872\n442/528 [========================&gt;.....] - ETA: 0s - loss: 0.3269 - mae: 0.3897\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3525 - mae: 0.3926\n528/528 [==============================] - 0s 697us/step - loss: 0.3507 - mae: 0.3930\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2526 - mae: 0.3285\n 67/528 [==&gt;...........................] - ETA: 0s - loss: 0.4196 - mae: 0.4047\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3973 - mae: 0.4040\n213/528 [===========&gt;..................] - ETA: 0s - loss: 0.3549 - mae: 0.3944\n289/528 [===============&gt;..............] - ETA: 0s - loss: 0.3669 - mae: 0.3939\n364/528 [===================&gt;..........] - ETA: 0s - loss: 0.3802 - mae: 0.3973\n434/528 [=======================&gt;......] - ETA: 0s - loss: 0.3605 - mae: 0.3950\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3504 - mae: 0.3939\n528/528 [==============================] - 0s 708us/step - loss: 0.3476 - mae: 0.3940\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.0081 - mae: 0.6118\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.4024 - mae: 0.3952\n136/528 [======&gt;.......................] - ETA: 0s - loss: 0.3300 - mae: 0.3887\n212/528 [===========&gt;..................] - ETA: 0s - loss: 0.3307 - mae: 0.3893\n279/528 [==============&gt;...............] - ETA: 0s - loss: 0.3368 - mae: 0.3931\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3479 - mae: 0.3928\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3560 - mae: 0.3940\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3523 - mae: 0.3975\n528/528 [==============================] - 0s 719us/step - loss: 0.3452 - mae: 0.3949\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.6729 - mae: 0.6983\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2924 - mae: 0.3923\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3021 - mae: 0.3957\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3175 - mae: 0.3943\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3310 - mae: 0.3939\n362/528 [===================&gt;..........] - ETA: 0s - loss: 0.3294 - mae: 0.3925\n433/528 [=======================&gt;......] - ETA: 0s - loss: 0.3512 - mae: 0.3944\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3529 - mae: 0.3934\n528/528 [==============================] - 0s 701us/step - loss: 0.3485 - mae: 0.3926\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1846 - mae: 0.3078\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.4902 - mae: 0.4011\n145/528 [=======&gt;......................] - ETA: 0s - loss: 0.3619 - mae: 0.3869\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.3397 - mae: 0.3905\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3384 - mae: 0.3917\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3511 - mae: 0.3943\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3518 - mae: 0.3951\n515/528 [============================&gt;.] - ETA: 0s - loss: 0.3480 - mae: 0.3930\n528/528 [==============================] - 0s 690us/step - loss: 0.3470 - mae: 0.3925\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1102 - mae: 0.2561\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.2881 - mae: 0.3671\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3035 - mae: 0.3824\n216/528 [===========&gt;..................] - ETA: 0s - loss: 0.3939 - mae: 0.3924\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3760 - mae: 0.3921\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3527 - mae: 0.3902\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3522 - mae: 0.3911\n528/528 [==============================] - 0s 658us/step - loss: 0.3468 - mae: 0.3923\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2658 - mae: 0.4304\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2951 - mae: 0.3926\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3535 - mae: 0.4003\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3402 - mae: 0.3934\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3345 - mae: 0.3894\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3315 - mae: 0.3917\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3392 - mae: 0.3928\n528/528 [==============================] - 0s 626us/step - loss: 0.3450 - mae: 0.3942\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5469 - mae: 0.6227\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3020 - mae: 0.3658\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3096 - mae: 0.3794\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3250 - mae: 0.3861\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3221 - mae: 0.3902\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3403 - mae: 0.3932\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3396 - mae: 0.3922\n528/528 [==============================] - 0s 613us/step - loss: 0.3461 - mae: 0.3932\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3192 - mae: 0.3784\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3337 - mae: 0.3929\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3072 - mae: 0.3863\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.2921 - mae: 0.3847\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3089 - mae: 0.3876\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3391 - mae: 0.3922\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3371 - mae: 0.3905\n528/528 [==============================] - 0s 625us/step - loss: 0.3466 - mae: 0.3926\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2445 - mae: 0.3856\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3702 - mae: 0.4016\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3196 - mae: 0.3915\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3385 - mae: 0.3981\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3400 - mae: 0.3959\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3512 - mae: 0.3950\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3361 - mae: 0.3922\n528/528 [==============================] - 0s 619us/step - loss: 0.3451 - mae: 0.3925\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0999 - mae: 0.2355\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3177 - mae: 0.3770\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3285 - mae: 0.3841\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3541 - mae: 0.3892\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3414 - mae: 0.3894\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3362 - mae: 0.3902\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3493 - mae: 0.3923\n528/528 [==============================] - 0s 609us/step - loss: 0.3442 - mae: 0.3914\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.1531 - mae: 0.5922\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3727 - mae: 0.3894\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3302 - mae: 0.3941\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3594 - mae: 0.3964\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3401 - mae: 0.3929\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3432 - mae: 0.3929\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3635 - mae: 0.3966\n528/528 [==============================] - 0s 664us/step - loss: 0.3474 - mae: 0.3927\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1882 - mae: 0.3228\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2973 - mae: 0.3838\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3988 - mae: 0.4022\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3548 - mae: 0.3989\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3639 - mae: 0.3999\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3451 - mae: 0.3950\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3491 - mae: 0.3947\n528/528 [==============================] - 0s 643us/step - loss: 0.3420 - mae: 0.3931\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1545 - mae: 0.3055\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3306 - mae: 0.3832\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3071 - mae: 0.3815\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3211 - mae: 0.3847\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3094 - mae: 0.3863\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3124 - mae: 0.3854\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3129 - mae: 0.3878\n528/528 [==============================] - 0s 647us/step - loss: 0.3466 - mae: 0.3912\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1142 - mae: 0.3026\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3489 - mae: 0.3897\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3402 - mae: 0.3894\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3270 - mae: 0.3869\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3411 - mae: 0.3879\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3453 - mae: 0.3900\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3465 - mae: 0.3910\n528/528 [==============================] - 0s 640us/step - loss: 0.3442 - mae: 0.3908\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2056 - mae: 0.3683\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3279 - mae: 0.3917\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3221 - mae: 0.3844\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.2989 - mae: 0.3787\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3504 - mae: 0.3883\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3400 - mae: 0.3914\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3470 - mae: 0.3904\n528/528 [==============================] - 0s 652us/step - loss: 0.3430 - mae: 0.3910\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2148 - mae: 0.3746\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4173 - mae: 0.4016\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3385 - mae: 0.3902\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3295 - mae: 0.3927\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3345 - mae: 0.3911\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3323 - mae: 0.3914\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3271 - mae: 0.3912\n528/528 [==============================] - 0s 634us/step - loss: 0.3452 - mae: 0.3928\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2291 - mae: 0.3721\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2806 - mae: 0.3796\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.2951 - mae: 0.3827\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3314 - mae: 0.3850\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3284 - mae: 0.3849\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3276 - mae: 0.3850\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3368 - mae: 0.3907\n528/528 [==============================] - 0s 654us/step - loss: 0.3435 - mae: 0.3932\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1463 - mae: 0.3117\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3536 - mae: 0.3861\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.3934 - mae: 0.3999\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3648 - mae: 0.3951\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3324 - mae: 0.3895\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3270 - mae: 0.3901\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3531 - mae: 0.3940\n528/528 [==============================] - 0s 656us/step - loss: 0.3452 - mae: 0.3930\nProcessing fold # 3 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 128.8647 - mae: 11.3388\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 57.6175 - mae: 6.7709  \n141/528 [=======&gt;......................] - ETA: 0s - loss: 32.0038 - mae: 4.3361\n210/528 [==========&gt;...................] - ETA: 0s - loss: 22.1245 - mae: 3.2533\n276/528 [==============&gt;...............] - ETA: 0s - loss: 17.1063 - mae: 2.6553\n350/528 [==================&gt;...........] - ETA: 0s - loss: 13.6970 - mae: 2.2324\n425/528 [=======================&gt;......] - ETA: 0s - loss: 11.3992 - mae: 1.9398\n498/528 [===========================&gt;..] - ETA: 0s - loss: 9.8117 - mae: 1.7316 \n528/528 [==============================] - 0s 717us/step - loss: 9.2912 - mae: 1.6638\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5062 - mae: 0.4767\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3558 - mae: 0.4478\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3897 - mae: 0.4505\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.4118 - mae: 0.4513\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.4181 - mae: 0.4521\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.4279 - mae: 0.4499\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.4308 - mae: 0.4498\n528/528 [==============================] - 0s 670us/step - loss: 0.4179 - mae: 0.4464\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3229 - mae: 0.4549\n 68/528 [==&gt;...........................] - ETA: 0s - loss: 0.4407 - mae: 0.4575\n138/528 [======&gt;.......................] - ETA: 0s - loss: 0.3625 - mae: 0.4339\n211/528 [==========&gt;...................] - ETA: 0s - loss: 0.3528 - mae: 0.4301\n283/528 [===============&gt;..............] - ETA: 0s - loss: 0.3438 - mae: 0.4285\n358/528 [===================&gt;..........] - ETA: 0s - loss: 0.3711 - mae: 0.4303\n431/528 [=======================&gt;......] - ETA: 0s - loss: 0.3882 - mae: 0.4306\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3900 - mae: 0.4312\n528/528 [==============================] - 0s 691us/step - loss: 0.3860 - mae: 0.4300\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1964 - mae: 0.3389\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2932 - mae: 0.4042\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3558 - mae: 0.4207\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.4104 - mae: 0.4279\n299/528 [===============&gt;..............] - ETA: 0s - loss: 0.3833 - mae: 0.4250\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3678 - mae: 0.4212\n452/528 [========================&gt;.....] - ETA: 0s - loss: 0.3728 - mae: 0.4226\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3807 - mae: 0.4244\n528/528 [==============================] - 0s 676us/step - loss: 0.3807 - mae: 0.4247\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2074 - mae: 0.3956\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.5238 - mae: 0.4393\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.4226 - mae: 0.4291\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.4206 - mae: 0.4300\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3849 - mae: 0.4220\n365/528 [===================&gt;..........] - ETA: 0s - loss: 0.4030 - mae: 0.4241\n443/528 [========================&gt;.....] - ETA: 0s - loss: 0.3869 - mae: 0.4235\n520/528 [============================&gt;.] - ETA: 0s - loss: 0.3759 - mae: 0.4221\n528/528 [==============================] - 0s 687us/step - loss: 0.3744 - mae: 0.4222\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3216 - mae: 0.4102\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.3237 - mae: 0.4134\n121/528 [=====&gt;........................] - ETA: 0s - loss: 0.3159 - mae: 0.4122\n186/528 [=========&gt;....................] - ETA: 0s - loss: 0.3253 - mae: 0.4134\n258/528 [=============&gt;................] - ETA: 0s - loss: 0.3595 - mae: 0.4182\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3544 - mae: 0.4182\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3571 - mae: 0.4158\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3718 - mae: 0.4199\n528/528 [==============================] - 0s 746us/step - loss: 0.3683 - mae: 0.4197\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2789 - mae: 0.4543\n 54/528 [==&gt;...........................] - ETA: 0s - loss: 0.4856 - mae: 0.4233\n110/528 [=====&gt;........................] - ETA: 0s - loss: 0.4324 - mae: 0.4188\n176/528 [=========&gt;....................] - ETA: 0s - loss: 0.3893 - mae: 0.4159\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3728 - mae: 0.4149\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3779 - mae: 0.4152\n370/528 [====================&gt;.........] - ETA: 0s - loss: 0.3656 - mae: 0.4147\n441/528 [========================&gt;.....] - ETA: 0s - loss: 0.3594 - mae: 0.4155\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3726 - mae: 0.4179\n528/528 [==============================] - 0s 815us/step - loss: 0.3667 - mae: 0.4170\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4583 - mae: 0.5879\n 57/528 [==&gt;...........................] - ETA: 0s - loss: 0.3113 - mae: 0.4152\n112/528 [=====&gt;........................] - ETA: 0s - loss: 0.3148 - mae: 0.4141\n179/528 [=========&gt;....................] - ETA: 0s - loss: 0.2992 - mae: 0.4049\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3282 - mae: 0.4088\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3556 - mae: 0.4088\n362/528 [===================&gt;..........] - ETA: 0s - loss: 0.3498 - mae: 0.4083\n430/528 [=======================&gt;......] - ETA: 0s - loss: 0.3500 - mae: 0.4096\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3603 - mae: 0.4148\n528/528 [==============================] - 0s 830us/step - loss: 0.3668 - mae: 0.4162\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3654 - mae: 0.4679\n 61/528 [==&gt;...........................] - ETA: 0s - loss: 0.3623 - mae: 0.4157\n117/528 [=====&gt;........................] - ETA: 0s - loss: 0.3210 - mae: 0.4055\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3258 - mae: 0.4091\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3474 - mae: 0.4113\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3687 - mae: 0.4136\n385/528 [====================&gt;.........] - ETA: 0s - loss: 0.3805 - mae: 0.4162\n455/528 [========================&gt;.....] - ETA: 0s - loss: 0.3652 - mae: 0.4136\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3632 - mae: 0.4159\n528/528 [==============================] - 0s 788us/step - loss: 0.3628 - mae: 0.4148\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1707 - mae: 0.3151\n 69/528 [==&gt;...........................] - ETA: 0s - loss: 0.4115 - mae: 0.4354\n121/528 [=====&gt;........................] - ETA: 0s - loss: 0.3457 - mae: 0.4197\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3414 - mae: 0.4195\n207/528 [==========&gt;...................] - ETA: 0s - loss: 0.3452 - mae: 0.4199\n267/528 [==============&gt;...............] - ETA: 0s - loss: 0.3511 - mae: 0.4203\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3388 - mae: 0.4139\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3296 - mae: 0.4114\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3459 - mae: 0.4114\n523/528 [============================&gt;.] - ETA: 0s - loss: 0.3625 - mae: 0.4125\n528/528 [==============================] - 0s 874us/step - loss: 0.3612 - mae: 0.4122\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1993 - mae: 0.3274\n 66/528 [==&gt;...........................] - ETA: 0s - loss: 0.4625 - mae: 0.4169\n120/528 [=====&gt;........................] - ETA: 0s - loss: 0.4622 - mae: 0.4229\n183/528 [=========&gt;....................] - ETA: 0s - loss: 0.3992 - mae: 0.4136\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3602 - mae: 0.4053\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3677 - mae: 0.4077\n351/528 [==================&gt;...........] - ETA: 0s - loss: 0.3711 - mae: 0.4110\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3789 - mae: 0.4136\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3643 - mae: 0.4113\n528/528 [==============================] - 0s 826us/step - loss: 0.3591 - mae: 0.4118\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4757 - mae: 0.4355\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.5068 - mae: 0.4360\n135/528 [======&gt;.......................] - ETA: 0s - loss: 0.4113 - mae: 0.4201\n202/528 [==========&gt;...................] - ETA: 0s - loss: 0.4275 - mae: 0.4203\n258/528 [=============&gt;................] - ETA: 0s - loss: 0.3903 - mae: 0.4142\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3825 - mae: 0.4147\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3643 - mae: 0.4107\n446/528 [========================&gt;.....] - ETA: 0s - loss: 0.3684 - mae: 0.4116\n526/528 [============================&gt;.] - ETA: 0s - loss: 0.3612 - mae: 0.4114\n528/528 [==============================] - 0s 773us/step - loss: 0.3607 - mae: 0.4113\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6484 - mae: 0.4558\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2606 - mae: 0.3831\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3311 - mae: 0.4003\n203/528 [==========&gt;...................] - ETA: 0s - loss: 0.3544 - mae: 0.4044\n267/528 [==============&gt;...............] - ETA: 0s - loss: 0.3493 - mae: 0.4022\n342/528 [==================&gt;...........] - ETA: 0s - loss: 0.3376 - mae: 0.4026\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3430 - mae: 0.4055\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3564 - mae: 0.4088\n528/528 [==============================] - 0s 703us/step - loss: 0.3583 - mae: 0.4098\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1493 - mae: 0.3230\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3586 - mae: 0.4198\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3608 - mae: 0.4152\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3996 - mae: 0.4183\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3797 - mae: 0.4132\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3614 - mae: 0.4094\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3609 - mae: 0.4074\n528/528 [==============================] - 0s 644us/step - loss: 0.3583 - mae: 0.4094\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3543 - mae: 0.4774\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4136 - mae: 0.4178\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3787 - mae: 0.4142\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3486 - mae: 0.4102\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3383 - mae: 0.4089\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3539 - mae: 0.4109\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3500 - mae: 0.4089\n528/528 [==============================] - 0s 648us/step - loss: 0.3557 - mae: 0.4088\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2212 - mae: 0.3517\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3761 - mae: 0.4149\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3229 - mae: 0.4031\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3458 - mae: 0.4073\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3444 - mae: 0.4041\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3339 - mae: 0.4021\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3613 - mae: 0.4081\n528/528 [==============================] - 0s 655us/step - loss: 0.3565 - mae: 0.4077\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1984 - mae: 0.3354\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2855 - mae: 0.3905\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.4121 - mae: 0.4067\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3983 - mae: 0.4098\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3741 - mae: 0.4071\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3558 - mae: 0.4062\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3498 - mae: 0.4077\n528/528 [==============================] - 0s 634us/step - loss: 0.3582 - mae: 0.4085\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2103 - mae: 0.3805\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3414 - mae: 0.4132\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3290 - mae: 0.4098\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.3318 - mae: 0.4132\n299/528 [===============&gt;..............] - ETA: 0s - loss: 0.3548 - mae: 0.4121\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.3562 - mae: 0.4103\n442/528 [========================&gt;.....] - ETA: 0s - loss: 0.3522 - mae: 0.4101\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3613 - mae: 0.4085\n528/528 [==============================] - 0s 689us/step - loss: 0.3575 - mae: 0.4075\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1707 - mae: 0.3219\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4658 - mae: 0.4281\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3599 - mae: 0.4087\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3501 - mae: 0.4111\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3601 - mae: 0.4104\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3581 - mae: 0.4087\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3578 - mae: 0.4069\n528/528 [==============================] - 0s 637us/step - loss: 0.3526 - mae: 0.4074\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1490 - mae: 0.3275\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3428 - mae: 0.3997\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3289 - mae: 0.3971\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3245 - mae: 0.3991\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3608 - mae: 0.4062\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3577 - mae: 0.4060\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3420 - mae: 0.4035\n528/528 [==============================] - 0s 634us/step - loss: 0.3513 - mae: 0.4053\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1037 - mae: 0.2780\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3824 - mae: 0.4148\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3734 - mae: 0.4132\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3631 - mae: 0.4090\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3650 - mae: 0.4077\n360/528 [===================&gt;..........] - ETA: 0s - loss: 0.3476 - mae: 0.4058\n434/528 [=======================&gt;......] - ETA: 0s - loss: 0.3705 - mae: 0.4085\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3542 - mae: 0.4040\n528/528 [==============================] - 0s 696us/step - loss: 0.3504 - mae: 0.4035\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1006 - mae: 0.2577\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3007 - mae: 0.4005\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3277 - mae: 0.4067\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3599 - mae: 0.4113\n290/528 [===============&gt;..............] - ETA: 0s - loss: 0.3893 - mae: 0.4126\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3759 - mae: 0.4111\n366/528 [===================&gt;..........] - ETA: 0s - loss: 0.3769 - mae: 0.4108\n436/528 [=======================&gt;......] - ETA: 0s - loss: 0.3644 - mae: 0.4101\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3520 - mae: 0.4073\n528/528 [==============================] - 0s 794us/step - loss: 0.3504 - mae: 0.4070\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2875 - mae: 0.4235\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2858 - mae: 0.4012\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3045 - mae: 0.4076\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3053 - mae: 0.4054\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3481 - mae: 0.4100\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3469 - mae: 0.4084\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3348 - mae: 0.4053\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3502 - mae: 0.4053\n528/528 [==============================] - 0s 746us/step - loss: 0.3532 - mae: 0.4055\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3377 - mae: 0.4887\n 60/528 [==&gt;...........................] - ETA: 0s - loss: 0.3546 - mae: 0.3975\n128/528 [======&gt;.......................] - ETA: 0s - loss: 0.3329 - mae: 0.4013\n204/528 [==========&gt;...................] - ETA: 0s - loss: 0.3383 - mae: 0.4015\n271/528 [==============&gt;...............] - ETA: 0s - loss: 0.3355 - mae: 0.4013\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3447 - mae: 0.4013\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3452 - mae: 0.4038\n433/528 [=======================&gt;......] - ETA: 0s - loss: 0.3527 - mae: 0.4055\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3581 - mae: 0.4047\n528/528 [==============================] - 0s 800us/step - loss: 0.3511 - mae: 0.4023\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1732 - mae: 0.3405\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2890 - mae: 0.3838\n124/528 [======&gt;.......................] - ETA: 0s - loss: 0.2792 - mae: 0.3841\n181/528 [=========&gt;....................] - ETA: 0s - loss: 0.3057 - mae: 0.3895\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3450 - mae: 0.3976\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3395 - mae: 0.3995\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3422 - mae: 0.3986\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3478 - mae: 0.4008\n528/528 [==============================] - 0s 766us/step - loss: 0.3517 - mae: 0.4028\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1939 - mae: 0.3616\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.5153 - mae: 0.4305\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3916 - mae: 0.4046\n213/528 [===========&gt;..................] - ETA: 0s - loss: 0.3727 - mae: 0.4001\n287/528 [===============&gt;..............] - ETA: 0s - loss: 0.3544 - mae: 0.4027\n352/528 [===================&gt;..........] - ETA: 0s - loss: 0.3499 - mae: 0.4055\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3634 - mae: 0.4057\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3499 - mae: 0.4041\n528/528 [==============================] - 0s 734us/step - loss: 0.3483 - mae: 0.4046\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3460 - mae: 0.4659\n 50/528 [=&gt;............................] - ETA: 0s - loss: 0.2995 - mae: 0.3863\n 94/528 [====&gt;.........................] - ETA: 0s - loss: 0.3305 - mae: 0.3890\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3293 - mae: 0.3989\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.4164 - mae: 0.4115\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3829 - mae: 0.4072\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3605 - mae: 0.4035\n452/528 [========================&gt;.....] - ETA: 0s - loss: 0.3483 - mae: 0.4034\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3476 - mae: 0.4041\n528/528 [==============================] - 0s 771us/step - loss: 0.3474 - mae: 0.4041\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1857 - mae: 0.3175\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.2859 - mae: 0.3947\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3314 - mae: 0.4045\n216/528 [===========&gt;..................] - ETA: 0s - loss: 0.3213 - mae: 0.4005\n283/528 [===============&gt;..............] - ETA: 0s - loss: 0.3273 - mae: 0.4014\n364/528 [===================&gt;..........] - ETA: 0s - loss: 0.3435 - mae: 0.4003\n431/528 [=======================&gt;......] - ETA: 0s - loss: 0.3322 - mae: 0.3991\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3491 - mae: 0.4033\n528/528 [==============================] - 0s 693us/step - loss: 0.3498 - mae: 0.4035\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2380 - mae: 0.4173\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.4303 - mae: 0.4156\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.4075 - mae: 0.4165\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3927 - mae: 0.4156\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3667 - mae: 0.4104\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3735 - mae: 0.4086\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3543 - mae: 0.4053\n528/528 [==============================] - 0s 667us/step - loss: 0.3465 - mae: 0.4029\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2617 - mae: 0.3570\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.5535 - mae: 0.4274\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.4689 - mae: 0.4162\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3969 - mae: 0.4021\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3714 - mae: 0.4000\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3710 - mae: 0.4021\n459/528 [=========================&gt;....] - ETA: 0s - loss: 0.3595 - mae: 0.4024\n528/528 [==============================] - 0s 661us/step - loss: 0.3474 - mae: 0.4018\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2310 - mae: 0.3594\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3131 - mae: 0.4112\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3441 - mae: 0.4067\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3545 - mae: 0.4052\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3272 - mae: 0.3963\n350/528 [==================&gt;...........] - ETA: 0s - loss: 0.3441 - mae: 0.3971\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3338 - mae: 0.3968\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3483 - mae: 0.3995\n528/528 [==============================] - 0s 735us/step - loss: 0.3456 - mae: 0.3996\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1796 - mae: 0.3513\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3895 - mae: 0.3997\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3651 - mae: 0.3962\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3679 - mae: 0.4029\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3397 - mae: 0.3999\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3421 - mae: 0.4022\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3497 - mae: 0.4041\n528/528 [==============================] - 0s 649us/step - loss: 0.3455 - mae: 0.4039\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1797 - mae: 0.3267\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.2662 - mae: 0.3893\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3027 - mae: 0.3873\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3024 - mae: 0.3903\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3128 - mae: 0.3932\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3063 - mae: 0.3949\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3567 - mae: 0.4030\n528/528 [==============================] - 0s 650us/step - loss: 0.3438 - mae: 0.3989\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4267 - mae: 0.5423\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3426 - mae: 0.3974\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3750 - mae: 0.4077\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3719 - mae: 0.4099\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3558 - mae: 0.4058\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3324 - mae: 0.3999\n459/528 [=========================&gt;....] - ETA: 0s - loss: 0.3320 - mae: 0.3977\n528/528 [==============================] - 0s 662us/step - loss: 0.3445 - mae: 0.4007\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1371 - mae: 0.2972\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3227 - mae: 0.3965\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3036 - mae: 0.3921\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3135 - mae: 0.3916\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3102 - mae: 0.3916\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3218 - mae: 0.3952\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3186 - mae: 0.3942\n528/528 [==============================] - 0s 656us/step - loss: 0.3460 - mae: 0.3986\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2808 - mae: 0.3671\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3459 - mae: 0.3890\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3521 - mae: 0.3955\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3327 - mae: 0.3948\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3479 - mae: 0.3992\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3496 - mae: 0.4001\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3473 - mae: 0.3982\n528/528 [==============================] - 0s 655us/step - loss: 0.3460 - mae: 0.4009\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3929 - mae: 0.4403\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2891 - mae: 0.3963\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.2742 - mae: 0.3897\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.2965 - mae: 0.3916\n297/528 [===============&gt;..............] - ETA: 0s - loss: 0.3213 - mae: 0.3924\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3343 - mae: 0.3947\n455/528 [========================&gt;.....] - ETA: 0s - loss: 0.3508 - mae: 0.3979\n528/528 [==============================] - 0s 668us/step - loss: 0.3448 - mae: 0.3987\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5783 - mae: 0.4786\n 68/528 [==&gt;...........................] - ETA: 0s - loss: 0.3130 - mae: 0.3914\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3173 - mae: 0.4000\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3257 - mae: 0.3976\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3282 - mae: 0.3949\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3281 - mae: 0.3960\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3356 - mae: 0.3964\n528/528 [==============================] - 0s 661us/step - loss: 0.3451 - mae: 0.3988\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4180 - mae: 0.4875\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2738 - mae: 0.3910\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3349 - mae: 0.4018\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.3716 - mae: 0.4029\n293/528 [===============&gt;..............] - ETA: 0s - loss: 0.3723 - mae: 0.4017\n369/528 [===================&gt;..........] - ETA: 0s - loss: 0.3619 - mae: 0.4027\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3523 - mae: 0.3987\n520/528 [============================&gt;.] - ETA: 0s - loss: 0.3470 - mae: 0.3992\n528/528 [==============================] - 0s 679us/step - loss: 0.3452 - mae: 0.3988\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1108 - mae: 0.2690\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2813 - mae: 0.3915\n140/528 [======&gt;.......................] - ETA: 0s - loss: 0.2726 - mae: 0.3808\n212/528 [===========&gt;..................] - ETA: 0s - loss: 0.3255 - mae: 0.3930\n292/528 [===============&gt;..............] - ETA: 0s - loss: 0.3286 - mae: 0.3945\n371/528 [====================&gt;.........] - ETA: 0s - loss: 0.3287 - mae: 0.3940\n452/528 [========================&gt;.....] - ETA: 0s - loss: 0.3383 - mae: 0.3964\n528/528 [==============================] - 0s 667us/step - loss: 0.3472 - mae: 0.3993\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4513 - mae: 0.5029\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4386 - mae: 0.4136\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3610 - mae: 0.4030\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3820 - mae: 0.4028\n284/528 [===============&gt;..............] - ETA: 0s - loss: 0.3685 - mae: 0.4014\n344/528 [==================&gt;...........] - ETA: 0s - loss: 0.3681 - mae: 0.4005\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3483 - mae: 0.3982\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3510 - mae: 0.3988\n528/528 [==============================] - 0s 708us/step - loss: 0.3485 - mae: 0.3988\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1797 - mae: 0.3339\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2620 - mae: 0.3886\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2702 - mae: 0.3881\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.2876 - mae: 0.3881\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3233 - mae: 0.3957\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3078 - mae: 0.3912\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3010 - mae: 0.3905\n528/528 [==============================] - 0s 649us/step - loss: 0.3412 - mae: 0.3979\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1699 - mae: 0.3315\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2592 - mae: 0.3812\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3269 - mae: 0.3914\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3335 - mae: 0.3942\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3242 - mae: 0.3940\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3359 - mae: 0.3980\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3429 - mae: 0.3982\n528/528 [==============================] - 0s 650us/step - loss: 0.3447 - mae: 0.3989\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2307 - mae: 0.3846\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2971 - mae: 0.3913\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3105 - mae: 0.3876\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3703 - mae: 0.3978\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3701 - mae: 0.3976\n374/528 [====================&gt;.........] - ETA: 0s - loss: 0.3464 - mae: 0.3943\n448/528 [========================&gt;.....] - ETA: 0s - loss: 0.3454 - mae: 0.3959\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3433 - mae: 0.3970\n528/528 [==============================] - 0s 674us/step - loss: 0.3429 - mae: 0.3970\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1879 - mae: 0.3621\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3231 - mae: 0.3927\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3687 - mae: 0.3981\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3441 - mae: 0.3920\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3184 - mae: 0.3869\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3266 - mae: 0.3931\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3176 - mae: 0.3922\n528/528 [==============================] - 0s 667us/step - loss: 0.3413 - mae: 0.3968\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5070 - mae: 0.4967\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3172 - mae: 0.3771\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3059 - mae: 0.3870\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3108 - mae: 0.3919\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3123 - mae: 0.3932\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3175 - mae: 0.3926\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3315 - mae: 0.3960\n528/528 [==============================] - 0s 649us/step - loss: 0.3390 - mae: 0.3959\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7588 - mae: 0.4968\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3422 - mae: 0.3932\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3439 - mae: 0.3961\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3320 - mae: 0.3949\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3569 - mae: 0.3998\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3539 - mae: 0.3998\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3426 - mae: 0.3985\n528/528 [==============================] - 0s 656us/step - loss: 0.3423 - mae: 0.3966\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2827 - mae: 0.4139\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4061 - mae: 0.4101\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3601 - mae: 0.4115\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3510 - mae: 0.4076\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3265 - mae: 0.3998\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3345 - mae: 0.3986\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.3538 - mae: 0.4014\n528/528 [==============================] - 0s 650us/step - loss: 0.3430 - mae: 0.3988\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2114 - mae: 0.3823\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4503 - mae: 0.4201\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3687 - mae: 0.4051\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3580 - mae: 0.4010\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3443 - mae: 0.4006\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3367 - mae: 0.3980\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3498 - mae: 0.3987\n528/528 [==============================] - 0s 618us/step - loss: 0.3423 - mae: 0.3969\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2159 - mae: 0.3467\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4154 - mae: 0.3932\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3487 - mae: 0.3922\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3648 - mae: 0.3953\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3522 - mae: 0.3966\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3525 - mae: 0.3977\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3511 - mae: 0.3964\n528/528 [==============================] - 0s 659us/step - loss: 0.3430 - mae: 0.3969\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2195 - mae: 0.3233\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2761 - mae: 0.3891\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2990 - mae: 0.3883\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3313 - mae: 0.3929\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3486 - mae: 0.3988\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3298 - mae: 0.3952\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3257 - mae: 0.3939\n528/528 [==============================] - 0s 649us/step - loss: 0.3409 - mae: 0.3975\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2111 - mae: 0.3427\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3277 - mae: 0.3884\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3690 - mae: 0.4037\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3387 - mae: 0.3971\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3192 - mae: 0.3906\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3206 - mae: 0.3930\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3330 - mae: 0.3948\n528/528 [==============================] - 0s 636us/step - loss: 0.3400 - mae: 0.3979\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1212 - mae: 0.2764\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2803 - mae: 0.3858\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3512 - mae: 0.3915\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3426 - mae: 0.3934\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3422 - mae: 0.3967\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3557 - mae: 0.3973\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3468 - mae: 0.3951\n528/528 [==============================] - 0s 652us/step - loss: 0.3389 - mae: 0.3952\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2493 - mae: 0.3988\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3520 - mae: 0.3909\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3683 - mae: 0.3965\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3406 - mae: 0.3943\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3571 - mae: 0.3981\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3611 - mae: 0.3941\n452/528 [========================&gt;.....] - ETA: 0s - loss: 0.3487 - mae: 0.3955\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3402 - mae: 0.3937\n528/528 [==============================] - 0s 672us/step - loss: 0.3398 - mae: 0.3937\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1541 - mae: 0.2865\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3339 - mae: 0.3983\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3139 - mae: 0.3969\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3013 - mae: 0.3921\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3101 - mae: 0.3931\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3331 - mae: 0.3957\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3449 - mae: 0.3948\n528/528 [==============================] - 0s 640us/step - loss: 0.3390 - mae: 0.3945\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1119 - mae: 0.2782\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2468 - mae: 0.3826\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3195 - mae: 0.3978\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3567 - mae: 0.4019\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3492 - mae: 0.3974\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3416 - mae: 0.3935\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3444 - mae: 0.3946\n528/528 [==============================] - 0s 659us/step - loss: 0.3384 - mae: 0.3950\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2495 - mae: 0.4102\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3217 - mae: 0.3993\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3721 - mae: 0.4023\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3917 - mae: 0.4045\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3642 - mae: 0.4007\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3609 - mae: 0.4009\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3492 - mae: 0.3995\n528/528 [==============================] - 0s 652us/step - loss: 0.3401 - mae: 0.3961\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2099 - mae: 0.3999\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2699 - mae: 0.3824\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3781 - mae: 0.3976\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3585 - mae: 0.3989\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3425 - mae: 0.3973\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3396 - mae: 0.3935\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3444 - mae: 0.3943\n528/528 [==============================] - 0s 634us/step - loss: 0.3392 - mae: 0.3927\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2320 - mae: 0.4003\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4091 - mae: 0.3990\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3828 - mae: 0.3996\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3508 - mae: 0.3952\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3437 - mae: 0.3931\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3356 - mae: 0.3931\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3334 - mae: 0.3927\n528/528 [==============================] - 0s 636us/step - loss: 0.3386 - mae: 0.3923\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2365 - mae: 0.3874\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2879 - mae: 0.3911\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2962 - mae: 0.3943\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3107 - mae: 0.3945\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3237 - mae: 0.3951\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3312 - mae: 0.3954\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3364 - mae: 0.3955\n528/528 [==============================] - 0s 641us/step - loss: 0.3379 - mae: 0.3947\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1897 - mae: 0.3052\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3195 - mae: 0.3916\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3314 - mae: 0.3870\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3220 - mae: 0.3838\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3195 - mae: 0.3874\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3288 - mae: 0.3895\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3206 - mae: 0.3887\n528/528 [==============================] - 0s 637us/step - loss: 0.3422 - mae: 0.3931\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1881 - mae: 0.3518\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2778 - mae: 0.3882\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3351 - mae: 0.3925\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3643 - mae: 0.3948\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3400 - mae: 0.3925\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3327 - mae: 0.3942\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3369 - mae: 0.3955\n528/528 [==============================] - 0s 648us/step - loss: 0.3432 - mae: 0.3969\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.3372 - mae: 0.5655\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2852 - mae: 0.3856\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3010 - mae: 0.3821\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.2948 - mae: 0.3835\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3149 - mae: 0.3893\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3263 - mae: 0.3937\n451/528 [========================&gt;.....] - ETA: 0s - loss: 0.3576 - mae: 0.3991\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3412 - mae: 0.3946\n528/528 [==============================] - 0s 673us/step - loss: 0.3407 - mae: 0.3943\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1637 - mae: 0.3184\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2696 - mae: 0.3868\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3112 - mae: 0.3903\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3483 - mae: 0.3948\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3455 - mae: 0.3932\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3534 - mae: 0.3948\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3430 - mae: 0.3947\n528/528 [==============================] - 0s 650us/step - loss: 0.3374 - mae: 0.3939\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1226 - mae: 0.3033\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3452 - mae: 0.3848\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3373 - mae: 0.3908\n213/528 [===========&gt;..................] - ETA: 0s - loss: 0.3183 - mae: 0.3918\n287/528 [===============&gt;..............] - ETA: 0s - loss: 0.3690 - mae: 0.4000\n362/528 [===================&gt;..........] - ETA: 0s - loss: 0.3664 - mae: 0.4001\n439/528 [=======================&gt;......] - ETA: 0s - loss: 0.3564 - mae: 0.3973\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3422 - mae: 0.3947\n528/528 [==============================] - 0s 691us/step - loss: 0.3393 - mae: 0.3941\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1299 - mae: 0.2879\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4747 - mae: 0.4184\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3804 - mae: 0.4024\n216/528 [===========&gt;..................] - ETA: 0s - loss: 0.3394 - mae: 0.3936\n289/528 [===============&gt;..............] - ETA: 0s - loss: 0.3538 - mae: 0.3957\n365/528 [===================&gt;..........] - ETA: 0s - loss: 0.3444 - mae: 0.3971\n442/528 [========================&gt;.....] - ETA: 0s - loss: 0.3446 - mae: 0.3956\n518/528 [============================&gt;.] - ETA: 0s - loss: 0.3361 - mae: 0.3931\n528/528 [==============================] - 0s 685us/step - loss: 0.3365 - mae: 0.3929\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2525 - mae: 0.4230\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3330 - mae: 0.3797\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.2956 - mae: 0.3802\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.2766 - mae: 0.3778\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3077 - mae: 0.3888\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3232 - mae: 0.3914\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3374 - mae: 0.3937\n528/528 [==============================] - 0s 666us/step - loss: 0.3370 - mae: 0.3942\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5679 - mae: 0.4578\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2705 - mae: 0.3761\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3124 - mae: 0.3844\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3521 - mae: 0.3944\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3488 - mae: 0.3923\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3338 - mae: 0.3891\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3289 - mae: 0.3911\n528/528 [==============================] - 0s 643us/step - loss: 0.3366 - mae: 0.3922\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1705 - mae: 0.3353\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3398 - mae: 0.3883\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2880 - mae: 0.3782\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3292 - mae: 0.3886\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3480 - mae: 0.3946\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3467 - mae: 0.3918\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3370 - mae: 0.3920\n528/528 [==============================] - 0s 643us/step - loss: 0.3370 - mae: 0.3921\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3709 - mae: 0.5432\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3554 - mae: 0.3934\n139/528 [======&gt;.......................] - ETA: 0s - loss: 0.3214 - mae: 0.3826\n216/528 [===========&gt;..................] - ETA: 0s - loss: 0.3187 - mae: 0.3867\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3095 - mae: 0.3871\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3093 - mae: 0.3865\n452/528 [========================&gt;.....] - ETA: 0s - loss: 0.3154 - mae: 0.3895\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3386 - mae: 0.3931\n528/528 [==============================] - 0s 674us/step - loss: 0.3384 - mae: 0.3932\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2716 - mae: 0.4094\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2541 - mae: 0.3718\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3004 - mae: 0.3803\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3161 - mae: 0.3844\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3352 - mae: 0.3870\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3545 - mae: 0.3911\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3443 - mae: 0.3912\n528/528 [==============================] - 0s 660us/step - loss: 0.3379 - mae: 0.3924\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1571 - mae: 0.3135\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3233 - mae: 0.3949\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3131 - mae: 0.3910\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3191 - mae: 0.3889\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3158 - mae: 0.3887\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3436 - mae: 0.3924\n435/528 [=======================&gt;......] - ETA: 0s - loss: 0.3342 - mae: 0.3908\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3397 - mae: 0.3924\n528/528 [==============================] - 0s 701us/step - loss: 0.3389 - mae: 0.3927\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2539 - mae: 0.3250\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2897 - mae: 0.3867\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.2846 - mae: 0.3863\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3256 - mae: 0.3907\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3159 - mae: 0.3870\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3366 - mae: 0.3909\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3442 - mae: 0.3928\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3432 - mae: 0.3936\n528/528 [==============================] - 0s 729us/step - loss: 0.3377 - mae: 0.3927\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2227 - mae: 0.3689\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2318 - mae: 0.3614\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.2503 - mae: 0.3722\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.2913 - mae: 0.3805\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.2875 - mae: 0.3812\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3472 - mae: 0.3933\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3353 - mae: 0.3917\n528/528 [==============================] - 0s 660us/step - loss: 0.3374 - mae: 0.3914\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2660 - mae: 0.3598\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2550 - mae: 0.3815\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3402 - mae: 0.3984\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3390 - mae: 0.3944\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3353 - mae: 0.3956\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3366 - mae: 0.3926\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3385 - mae: 0.3914\n528/528 [==============================] - 0s 653us/step - loss: 0.3349 - mae: 0.3907\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2055 - mae: 0.3720\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.2551 - mae: 0.3762\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.2996 - mae: 0.3784\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3087 - mae: 0.3829\n293/528 [===============&gt;..............] - ETA: 0s - loss: 0.3371 - mae: 0.3896\n347/528 [==================&gt;...........] - ETA: 0s - loss: 0.3325 - mae: 0.3904\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3357 - mae: 0.3901\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3429 - mae: 0.3919\n528/528 [==============================] - 0s 726us/step - loss: 0.3350 - mae: 0.3907\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1455 - mae: 0.2870\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4380 - mae: 0.4099\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3848 - mae: 0.3965\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3594 - mae: 0.3928\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3619 - mae: 0.3956\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3493 - mae: 0.3914\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.3379 - mae: 0.3911\n528/528 [==============================] - 0s 652us/step - loss: 0.3331 - mae: 0.3918\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1627 - mae: 0.3386\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3163 - mae: 0.3919\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2912 - mae: 0.3879\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.2810 - mae: 0.3836\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3146 - mae: 0.3867\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3243 - mae: 0.3901\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3410 - mae: 0.3911\n528/528 [==============================] - 0s 644us/step - loss: 0.3344 - mae: 0.3915\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2941 - mae: 0.3981\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3904 - mae: 0.4052\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.3390 - mae: 0.3914\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.3402 - mae: 0.3929\n291/528 [===============&gt;..............] - ETA: 0s - loss: 0.3211 - mae: 0.3887\n363/528 [===================&gt;..........] - ETA: 0s - loss: 0.3255 - mae: 0.3916\n428/528 [=======================&gt;......] - ETA: 0s - loss: 0.3309 - mae: 0.3909\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3367 - mae: 0.3928\n528/528 [==============================] - 0s 700us/step - loss: 0.3347 - mae: 0.3922\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1546 - mae: 0.3244\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.3361 - mae: 0.3866\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.2896 - mae: 0.3802\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.2753 - mae: 0.3785\n283/528 [===============&gt;..............] - ETA: 0s - loss: 0.2979 - mae: 0.3837\n356/528 [===================&gt;..........] - ETA: 0s - loss: 0.3216 - mae: 0.3863\n434/528 [=======================&gt;......] - ETA: 0s - loss: 0.3324 - mae: 0.3905\n514/528 [============================&gt;.] - ETA: 0s - loss: 0.3395 - mae: 0.3916\n528/528 [==============================] - 0s 692us/step - loss: 0.3363 - mae: 0.3910\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0896 - mae: 0.2416\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2917 - mae: 0.3882\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3943 - mae: 0.4065\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.4066 - mae: 0.4032\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3885 - mae: 0.4028\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3732 - mae: 0.4020\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3482 - mae: 0.3957\n528/528 [==============================] - 0s 649us/step - loss: 0.3350 - mae: 0.3923\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2349 - mae: 0.3750\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3025 - mae: 0.3897\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.2892 - mae: 0.3848\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3310 - mae: 0.3920\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3460 - mae: 0.3949\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3320 - mae: 0.3929\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3457 - mae: 0.3940\n528/528 [==============================] - 0s 644us/step - loss: 0.3344 - mae: 0.3904\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4123 - mae: 0.4542\n 64/528 [==&gt;...........................] - ETA: 0s - loss: 0.2359 - mae: 0.3662\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3126 - mae: 0.3828\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.2979 - mae: 0.3837\n297/528 [===============&gt;..............] - ETA: 0s - loss: 0.3147 - mae: 0.3862\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3092 - mae: 0.3864\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3034 - mae: 0.3878\n528/528 [==============================] - 0s 669us/step - loss: 0.3358 - mae: 0.3930\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4830 - mae: 0.5308\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3299 - mae: 0.4007\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3008 - mae: 0.3904\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3347 - mae: 0.3907\n275/528 [==============&gt;...............] - ETA: 0s - loss: 0.3247 - mae: 0.3894\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3448 - mae: 0.3947\n365/528 [===================&gt;..........] - ETA: 0s - loss: 0.3531 - mae: 0.3968\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3368 - mae: 0.3922\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3459 - mae: 0.3946\n528/528 [==============================] - 0s 848us/step - loss: 0.3326 - mae: 0.3907\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2386 - mae: 0.4402\n 67/528 [==&gt;...........................] - ETA: 0s - loss: 0.3986 - mae: 0.3920\n128/528 [======&gt;.......................] - ETA: 0s - loss: 0.3247 - mae: 0.3824\n187/528 [=========&gt;....................] - ETA: 0s - loss: 0.3415 - mae: 0.3916\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3338 - mae: 0.3908\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3179 - mae: 0.3882\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3487 - mae: 0.3925\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3428 - mae: 0.3926\n528/528 [==============================] - ETA: 0s - loss: 0.3365 - mae: 0.3907\n528/528 [==============================] - 0s 769us/step - loss: 0.3365 - mae: 0.3907\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2270 - mae: 0.3788\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.2435 - mae: 0.3637\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3225 - mae: 0.3853\n211/528 [==========&gt;...................] - ETA: 0s - loss: 0.3317 - mae: 0.3872\n290/528 [===============&gt;..............] - ETA: 0s - loss: 0.3147 - mae: 0.3854\n353/528 [===================&gt;..........] - ETA: 0s - loss: 0.3099 - mae: 0.3849\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3095 - mae: 0.3867\n464/528 [=========================&gt;....] - ETA: 0s - loss: 0.3390 - mae: 0.3930\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3369 - mae: 0.3920\n528/528 [==============================] - 0s 773us/step - loss: 0.3367 - mae: 0.3920\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1793 - mae: 0.3620\n 69/528 [==&gt;...........................] - ETA: 0s - loss: 0.3231 - mae: 0.3848\n138/528 [======&gt;.......................] - ETA: 0s - loss: 0.3221 - mae: 0.3900\n213/528 [===========&gt;..................] - ETA: 0s - loss: 0.3458 - mae: 0.3960\n281/528 [==============&gt;...............] - ETA: 0s - loss: 0.3206 - mae: 0.3904\n355/528 [===================&gt;..........] - ETA: 0s - loss: 0.3382 - mae: 0.3904\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3355 - mae: 0.3924\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3408 - mae: 0.3935\n528/528 [==============================] - 0s 712us/step - loss: 0.3370 - mae: 0.3924\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3096 - mae: 0.4269\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3587 - mae: 0.4066\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2986 - mae: 0.3907\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3328 - mae: 0.3919\n286/528 [===============&gt;..............] - ETA: 0s - loss: 0.3442 - mae: 0.3923\n354/528 [===================&gt;..........] - ETA: 0s - loss: 0.3461 - mae: 0.3924\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3475 - mae: 0.3954\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3466 - mae: 0.3949\n528/528 [==============================] - 0s 742us/step - loss: 0.3379 - mae: 0.3926\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1941 - mae: 0.3773\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4016 - mae: 0.4110\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3407 - mae: 0.3991\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3643 - mae: 0.3993\n289/528 [===============&gt;..............] - ETA: 0s - loss: 0.3527 - mae: 0.3975\n365/528 [===================&gt;..........] - ETA: 0s - loss: 0.3317 - mae: 0.3931\n440/528 [========================&gt;.....] - ETA: 0s - loss: 0.3456 - mae: 0.3927\n513/528 [============================&gt;.] - ETA: 0s - loss: 0.3359 - mae: 0.3905\n528/528 [==============================] - 0s 692us/step - loss: 0.3339 - mae: 0.3905\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3820 - mae: 0.4678\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.2439 - mae: 0.3763\n128/528 [======&gt;.......................] - ETA: 0s - loss: 0.2835 - mae: 0.3788\n186/528 [=========&gt;....................] - ETA: 0s - loss: 0.2816 - mae: 0.3814\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3181 - mae: 0.3849\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3265 - mae: 0.3874\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3402 - mae: 0.3900\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3370 - mae: 0.3905\n528/528 [==============================] - 0s 723us/step - loss: 0.3349 - mae: 0.3909\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6257 - mae: 0.5129\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.4563 - mae: 0.4119\n145/528 [=======&gt;......................] - ETA: 0s - loss: 0.3792 - mae: 0.4007\n215/528 [===========&gt;..................] - ETA: 0s - loss: 0.3809 - mae: 0.4020\n291/528 [===============&gt;..............] - ETA: 0s - loss: 0.3580 - mae: 0.3921\n369/528 [===================&gt;..........] - ETA: 0s - loss: 0.3675 - mae: 0.3962\n446/528 [========================&gt;.....] - ETA: 0s - loss: 0.3508 - mae: 0.3923\n523/528 [============================&gt;.] - ETA: 0s - loss: 0.3371 - mae: 0.3909\n528/528 [==============================] - 0s 678us/step - loss: 0.3361 - mae: 0.3904\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1288 - mae: 0.3038\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2734 - mae: 0.3805\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3081 - mae: 0.3878\n196/528 [==========&gt;...................] - ETA: 0s - loss: 0.3272 - mae: 0.3873\n267/528 [==============&gt;...............] - ETA: 0s - loss: 0.3391 - mae: 0.3890\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3282 - mae: 0.3898\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3306 - mae: 0.3884\n436/528 [=======================&gt;......] - ETA: 0s - loss: 0.3263 - mae: 0.3850\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3344 - mae: 0.3882\n528/528 [==============================] - 0s 827us/step - loss: 0.3365 - mae: 0.3905\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2843 - mae: 0.4269\n 69/528 [==&gt;...........................] - ETA: 0s - loss: 0.3168 - mae: 0.3896\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3347 - mae: 0.3899\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3326 - mae: 0.3864\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3513 - mae: 0.3891\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3437 - mae: 0.3891\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3368 - mae: 0.3890\n528/528 [==============================] - 0s 642us/step - loss: 0.3330 - mae: 0.3887\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2391 - mae: 0.3811\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3743 - mae: 0.3930\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3481 - mae: 0.3838\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3428 - mae: 0.3846\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3416 - mae: 0.3887\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3390 - mae: 0.3881\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3374 - mae: 0.3893\n528/528 [==============================] - 0s 623us/step - loss: 0.3343 - mae: 0.3895\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2103 - mae: 0.4051\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2628 - mae: 0.3805\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2957 - mae: 0.3855\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3817 - mae: 0.3948\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3546 - mae: 0.3906\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3424 - mae: 0.3858\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3386 - mae: 0.3887\n528/528 [==============================] - 0s 643us/step - loss: 0.3323 - mae: 0.3880\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1510 - mae: 0.3548\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3258 - mae: 0.3943\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3544 - mae: 0.4044\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3311 - mae: 0.3948\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3266 - mae: 0.3934\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3281 - mae: 0.3922\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3293 - mae: 0.3907\n528/528 [==============================] - 0s 646us/step - loss: 0.3335 - mae: 0.3904\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5988 - mae: 0.5132\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4171 - mae: 0.3985\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3894 - mae: 0.3956\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3609 - mae: 0.3899\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3499 - mae: 0.3924\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3462 - mae: 0.3900\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3395 - mae: 0.3882\n528/528 [==============================] - 0s 610us/step - loss: 0.3363 - mae: 0.3884\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3520 - mae: 0.5079\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2428 - mae: 0.3619\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.2363 - mae: 0.3659\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.2613 - mae: 0.3730\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.2941 - mae: 0.3812\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3121 - mae: 0.3847\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3302 - mae: 0.3908\n528/528 [==============================] - 0s 633us/step - loss: 0.3309 - mae: 0.3906\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3532 - mae: 0.4670\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3680 - mae: 0.3909\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3874 - mae: 0.3966\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3583 - mae: 0.3871\n292/528 [===============&gt;..............] - ETA: 0s - loss: 0.3532 - mae: 0.3854\n370/528 [====================&gt;.........] - ETA: 0s - loss: 0.3399 - mae: 0.3856\n448/528 [========================&gt;.....] - ETA: 0s - loss: 0.3325 - mae: 0.3875\n528/528 [==============================] - 0s 670us/step - loss: 0.3337 - mae: 0.3882\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3508 - mae: 0.4955\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4762 - mae: 0.4114\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3598 - mae: 0.3916\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3597 - mae: 0.3901\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3602 - mae: 0.3908\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3403 - mae: 0.3876\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3347 - mae: 0.3875\n528/528 [==============================] - 0s 604us/step - loss: 0.3324 - mae: 0.3883\nProcessing fold # 4 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 125.0518 - mae: 11.1776\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 45.7584 - mae: 5.7700  \n154/528 [=======&gt;......................] - ETA: 0s - loss: 23.8386 - mae: 3.4764\n238/528 [============&gt;.................] - ETA: 0s - loss: 15.8573 - mae: 2.5148\n323/528 [=================&gt;............] - ETA: 0s - loss: 11.8846 - mae: 2.0121\n405/528 [======================&gt;.......] - ETA: 0s - loss: 9.6013 - mae: 1.7155 \n489/528 [==========================&gt;...] - ETA: 0s - loss: 8.0627 - mae: 1.5097\n528/528 [==============================] - 0s 638us/step - loss: 7.4956 - mae: 1.4327\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3182 - mae: 0.4003\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.4090 - mae: 0.4565\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.4096 - mae: 0.4495\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3974 - mae: 0.4488\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.4261 - mae: 0.4525\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.4265 - mae: 0.4523\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.4112 - mae: 0.4469\n528/528 [==============================] - 0s 603us/step - loss: 0.4086 - mae: 0.4454\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2210 - mae: 0.3410\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.5801 - mae: 0.4701\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4581 - mae: 0.4428\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.4574 - mae: 0.4483\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.4187 - mae: 0.4413\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.4137 - mae: 0.4390\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3941 - mae: 0.4360\n528/528 [==============================] - 0s 605us/step - loss: 0.3872 - mae: 0.4339\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2801 - mae: 0.4014\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3467 - mae: 0.4169\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.4055 - mae: 0.4245\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3971 - mae: 0.4255\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.4017 - mae: 0.4263\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3954 - mae: 0.4269\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3820 - mae: 0.4262\n528/528 [==============================] - 0s 613us/step - loss: 0.3786 - mae: 0.4266\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3535 - mae: 0.5142\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2866 - mae: 0.4068\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.2942 - mae: 0.4129\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3261 - mae: 0.4190\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3653 - mae: 0.4236\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3875 - mae: 0.4273\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3744 - mae: 0.4262\n528/528 [==============================] - 0s 610us/step - loss: 0.3735 - mae: 0.4262\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2856 - mae: 0.4494\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3295 - mae: 0.4179\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3170 - mae: 0.4153\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3321 - mae: 0.4223\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3544 - mae: 0.4192\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3611 - mae: 0.4197\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3627 - mae: 0.4192\n528/528 [==============================] - 0s 617us/step - loss: 0.3691 - mae: 0.4200\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2628 - mae: 0.3442\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3392 - mae: 0.4166\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3454 - mae: 0.4193\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3583 - mae: 0.4216\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3571 - mae: 0.4227\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3762 - mae: 0.4244\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3763 - mae: 0.4229\n528/528 [==============================] - 0s 598us/step - loss: 0.3736 - mae: 0.4230\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1496 - mae: 0.3347\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4453 - mae: 0.4214\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3571 - mae: 0.4076\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3422 - mae: 0.4099\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3520 - mae: 0.4122\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3567 - mae: 0.4134\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3665 - mae: 0.4163\n528/528 [==============================] - 0s 632us/step - loss: 0.3670 - mae: 0.4177\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.2944 - mae: 0.6406\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3886 - mae: 0.4095\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3822 - mae: 0.4232\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3470 - mae: 0.4126\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3740 - mae: 0.4172\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3498 - mae: 0.4113\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3565 - mae: 0.4135\n528/528 [==============================] - 0s 606us/step - loss: 0.3642 - mae: 0.4157\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1923 - mae: 0.3452\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3431 - mae: 0.4057\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3074 - mae: 0.4052\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3205 - mae: 0.4094\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3170 - mae: 0.4086\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3547 - mae: 0.4145\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3572 - mae: 0.4157\n528/528 [==============================] - 0s 598us/step - loss: 0.3614 - mae: 0.4164\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4150 - mae: 0.5271\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3163 - mae: 0.4076\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3388 - mae: 0.4096\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3959 - mae: 0.4216\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3826 - mae: 0.4243\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3867 - mae: 0.4237\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3665 - mae: 0.4202\n528/528 [==============================] - 0s 611us/step - loss: 0.3611 - mae: 0.4191\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3924 - mae: 0.5416\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3075 - mae: 0.4071\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3465 - mae: 0.4093\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3389 - mae: 0.4049\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3543 - mae: 0.4109\n426/528 [=======================&gt;......] - ETA: 0s - loss: 0.3677 - mae: 0.4173\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3588 - mae: 0.4152\n528/528 [==============================] - 0s 596us/step - loss: 0.3652 - mae: 0.4158\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7638 - mae: 0.5697\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.5025 - mae: 0.4480\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4168 - mae: 0.4288\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3712 - mae: 0.4188\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3610 - mae: 0.4195\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3636 - mae: 0.4150\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3627 - mae: 0.4143\n528/528 [==============================] - 0s 609us/step - loss: 0.3586 - mae: 0.4134\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1797 - mae: 0.3900\n 87/528 [===&gt;..........................] - ETA: 0s - loss: 0.4374 - mae: 0.4158\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3648 - mae: 0.4074\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3716 - mae: 0.4133\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3628 - mae: 0.4114\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3529 - mae: 0.4101\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3553 - mae: 0.4107\n528/528 [==============================] - 0s 626us/step - loss: 0.3615 - mae: 0.4121\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1344 - mae: 0.3081\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3275 - mae: 0.4118\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3656 - mae: 0.4108\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3814 - mae: 0.4126\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3619 - mae: 0.4104\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3515 - mae: 0.4109\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3627 - mae: 0.4133\n528/528 [==============================] - 0s 598us/step - loss: 0.3589 - mae: 0.4124\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1504 - mae: 0.3068\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.4275 - mae: 0.4216\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4052 - mae: 0.4178\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3640 - mae: 0.4126\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3654 - mae: 0.4137\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3613 - mae: 0.4143\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3619 - mae: 0.4136\n528/528 [==============================] - 0s 601us/step - loss: 0.3581 - mae: 0.4133\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4310 - mae: 0.5109\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.4265 - mae: 0.4222\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3649 - mae: 0.4121\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3481 - mae: 0.4078\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3517 - mae: 0.4082\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3465 - mae: 0.4090\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3573 - mae: 0.4093\n528/528 [==============================] - 0s 604us/step - loss: 0.3569 - mae: 0.4097\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2045 - mae: 0.3386\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2886 - mae: 0.3901\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3256 - mae: 0.4038\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3125 - mae: 0.4004\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3445 - mae: 0.4083\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3571 - mae: 0.4105\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3585 - mae: 0.4125\n528/528 [==============================] - 0s 603us/step - loss: 0.3558 - mae: 0.4113\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5328 - mae: 0.6084\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3000 - mae: 0.4028\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3451 - mae: 0.4148\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3515 - mae: 0.4144\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3343 - mae: 0.4125\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3513 - mae: 0.4129\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3601 - mae: 0.4130\n528/528 [==============================] - 0s 624us/step - loss: 0.3553 - mae: 0.4103\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1347 - mae: 0.2859\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3623 - mae: 0.4135\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3639 - mae: 0.4075\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3456 - mae: 0.4084\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3807 - mae: 0.4139\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3690 - mae: 0.4109\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3485 - mae: 0.4056\n528/528 [==============================] - 0s 663us/step - loss: 0.3540 - mae: 0.4086\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3984 - mae: 0.4824\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3714 - mae: 0.3977\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3905 - mae: 0.4073\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3883 - mae: 0.4119\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3788 - mae: 0.4098\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3625 - mae: 0.4096\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3581 - mae: 0.4079\n528/528 [==============================] - 0s 620us/step - loss: 0.3529 - mae: 0.4068\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2818 - mae: 0.3830\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3643 - mae: 0.4201\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3175 - mae: 0.4019\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3254 - mae: 0.4012\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3244 - mae: 0.4031\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3172 - mae: 0.4012\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3553 - mae: 0.4084\n528/528 [==============================] - 0s 603us/step - loss: 0.3525 - mae: 0.4078\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2876 - mae: 0.4706\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3761 - mae: 0.4090\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3287 - mae: 0.4041\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3367 - mae: 0.4066\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3371 - mae: 0.4085\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3593 - mae: 0.4116\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3573 - mae: 0.4100\n528/528 [==============================] - 0s 600us/step - loss: 0.3523 - mae: 0.4081\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1368 - mae: 0.3180\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4000 - mae: 0.4185\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3540 - mae: 0.4136\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3418 - mae: 0.4096\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3560 - mae: 0.4086\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3687 - mae: 0.4102\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3605 - mae: 0.4104\n528/528 [==============================] - 0s 612us/step - loss: 0.3557 - mae: 0.4098\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2191 - mae: 0.3848\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3886 - mae: 0.4112\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3891 - mae: 0.4102\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3537 - mae: 0.4053\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3571 - mae: 0.4055\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3457 - mae: 0.4048\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3483 - mae: 0.4056\n525/528 [============================&gt;.] - ETA: 0s - loss: 0.3520 - mae: 0.4057\n528/528 [==============================] - 0s 681us/step - loss: 0.3533 - mae: 0.4062\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.4236 - mae: 0.7191\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.2916 - mae: 0.3927\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3569 - mae: 0.3994\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3489 - mae: 0.4036\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3411 - mae: 0.4047\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.3295 - mae: 0.4028\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3400 - mae: 0.4043\n528/528 [==============================] - 0s 671us/step - loss: 0.3538 - mae: 0.4064\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2159 - mae: 0.3700\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2618 - mae: 0.3875\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3859 - mae: 0.4122\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3711 - mae: 0.4080\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3633 - mae: 0.4063\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3482 - mae: 0.4044\n469/528 [=========================&gt;....] - ETA: 0s - loss: 0.3532 - mae: 0.4072\n528/528 [==============================] - 0s 645us/step - loss: 0.3472 - mae: 0.4054\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2855 - mae: 0.4115\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4023 - mae: 0.4229\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3890 - mae: 0.4166\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3583 - mae: 0.4090\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3734 - mae: 0.4092\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3469 - mae: 0.4033\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3497 - mae: 0.4050\n528/528 [==============================] - 0s 616us/step - loss: 0.3484 - mae: 0.4043\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2865 - mae: 0.4119\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.4258 - mae: 0.4186\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3572 - mae: 0.4037\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3544 - mae: 0.4048\n342/528 [==================&gt;...........] - ETA: 0s - loss: 0.3291 - mae: 0.3993\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3225 - mae: 0.3996\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3376 - mae: 0.4028\n528/528 [==============================] - 0s 597us/step - loss: 0.3490 - mae: 0.4058\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1295 - mae: 0.2791\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3488 - mae: 0.3846\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3754 - mae: 0.4005\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3649 - mae: 0.3998\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3461 - mae: 0.4022\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3347 - mae: 0.4023\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3516 - mae: 0.4039\n528/528 [==============================] - 0s 614us/step - loss: 0.3478 - mae: 0.4025\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0762 - mae: 0.2268\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3169 - mae: 0.3923\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3424 - mae: 0.3986\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3185 - mae: 0.3964\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3347 - mae: 0.3997\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3338 - mae: 0.4002\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3496 - mae: 0.4019\n528/528 [==============================] - 0s 627us/step - loss: 0.3460 - mae: 0.4027\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1945 - mae: 0.3525\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.3628 - mae: 0.4276\n135/528 [======&gt;.......................] - ETA: 0s - loss: 0.3585 - mae: 0.4102\n210/528 [==========&gt;...................] - ETA: 0s - loss: 0.3633 - mae: 0.4098\n290/528 [===============&gt;..............] - ETA: 0s - loss: 0.3790 - mae: 0.4077\n372/528 [====================&gt;.........] - ETA: 0s - loss: 0.3584 - mae: 0.4045\n455/528 [========================&gt;.....] - ETA: 0s - loss: 0.3553 - mae: 0.4029\n528/528 [==============================] - 0s 660us/step - loss: 0.3503 - mae: 0.4026\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.1217 - mae: 0.5966\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3587 - mae: 0.4076\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3513 - mae: 0.4037\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3348 - mae: 0.3981\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3734 - mae: 0.4038\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3554 - mae: 0.4025\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3471 - mae: 0.4012\n528/528 [==============================] - 0s 622us/step - loss: 0.3448 - mae: 0.4002\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1575 - mae: 0.2989\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.3469 - mae: 0.4160\n148/528 [=======&gt;......................] - ETA: 0s - loss: 0.3731 - mae: 0.4135\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3599 - mae: 0.4070\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3432 - mae: 0.4051\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3557 - mae: 0.4037\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3402 - mae: 0.4000\n528/528 [==============================] - 0s 643us/step - loss: 0.3479 - mae: 0.4009\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1937 - mae: 0.3321\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4289 - mae: 0.4247\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3508 - mae: 0.3972\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3647 - mae: 0.3985\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3647 - mae: 0.4017\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3680 - mae: 0.4026\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3517 - mae: 0.4023\n528/528 [==============================] - 0s 612us/step - loss: 0.3489 - mae: 0.4014\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2067 - mae: 0.3561\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4947 - mae: 0.4175\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.4103 - mae: 0.4094\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3691 - mae: 0.4038\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3578 - mae: 0.4035\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3569 - mae: 0.4021\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3513 - mae: 0.4031\n528/528 [==============================] - 0s 611us/step - loss: 0.3486 - mae: 0.4028\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1878 - mae: 0.3119\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.2831 - mae: 0.3841\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3539 - mae: 0.3991\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3230 - mae: 0.3960\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3189 - mae: 0.3961\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3111 - mae: 0.3939\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3311 - mae: 0.3965\n528/528 [==============================] - 0s 617us/step - loss: 0.3441 - mae: 0.3993\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1775 - mae: 0.3400\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2897 - mae: 0.3911\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3403 - mae: 0.3949\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3128 - mae: 0.3921\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3188 - mae: 0.3970\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3083 - mae: 0.3954\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3222 - mae: 0.3980\n528/528 [==============================] - 0s 609us/step - loss: 0.3453 - mae: 0.4018\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1946 - mae: 0.3630\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3281 - mae: 0.4088\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3860 - mae: 0.4112\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.3797 - mae: 0.4051\n267/528 [==============&gt;...............] - ETA: 0s - loss: 0.3592 - mae: 0.3989\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3651 - mae: 0.3999\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3485 - mae: 0.4001\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3450 - mae: 0.3996\n528/528 [==============================] - 0s 727us/step - loss: 0.3452 - mae: 0.4017\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2081 - mae: 0.3606\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3345 - mae: 0.3886\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3092 - mae: 0.3847\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3034 - mae: 0.3883\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.2872 - mae: 0.3818\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3133 - mae: 0.3902\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3367 - mae: 0.3968\n528/528 [==============================] - 0s 645us/step - loss: 0.3448 - mae: 0.3993\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2420 - mae: 0.3956\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3029 - mae: 0.3916\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3243 - mae: 0.3914\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3274 - mae: 0.3950\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3298 - mae: 0.3942\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3267 - mae: 0.3969\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3336 - mae: 0.3969\n528/528 [==============================] - 0s 661us/step - loss: 0.3440 - mae: 0.4015\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1495 - mae: 0.3008\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3486 - mae: 0.3962\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3361 - mae: 0.4028\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3662 - mae: 0.4038\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3413 - mae: 0.3987\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3415 - mae: 0.3986\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3361 - mae: 0.3986\n528/528 [==============================] - 0s 628us/step - loss: 0.3455 - mae: 0.3993\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2651 - mae: 0.3676\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2366 - mae: 0.3811\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3198 - mae: 0.3877\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3176 - mae: 0.3889\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3193 - mae: 0.3940\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3459 - mae: 0.3994\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3518 - mae: 0.4023\n528/528 [==============================] - 0s 668us/step - loss: 0.3451 - mae: 0.4006\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2778 - mae: 0.3612\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2722 - mae: 0.3939\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2928 - mae: 0.3846\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3444 - mae: 0.3998\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3565 - mae: 0.4015\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3650 - mae: 0.4024\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3477 - mae: 0.4006\n528/528 [==============================] - 0s 654us/step - loss: 0.3433 - mae: 0.4002\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 5.1990 - mae: 0.9249\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4252 - mae: 0.3994\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3439 - mae: 0.3941\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3383 - mae: 0.3936\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3337 - mae: 0.3972\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3281 - mae: 0.3967\n442/528 [========================&gt;.....] - ETA: 0s - loss: 0.3374 - mae: 0.3981\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3368 - mae: 0.3993\n528/528 [==============================] - 0s 695us/step - loss: 0.3443 - mae: 0.4001\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1080 - mae: 0.2772\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3712 - mae: 0.3885\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3600 - mae: 0.3994\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3347 - mae: 0.3959\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3538 - mae: 0.4026\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3423 - mae: 0.4016\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3510 - mae: 0.4016\n528/528 [==============================] - 0s 666us/step - loss: 0.3394 - mae: 0.3984\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1576 - mae: 0.2889\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2849 - mae: 0.3937\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2704 - mae: 0.3873\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3359 - mae: 0.4016\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3549 - mae: 0.4016\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3336 - mae: 0.3960\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3388 - mae: 0.3954\n528/528 [==============================] - 0s 645us/step - loss: 0.3395 - mae: 0.3958\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4754 - mae: 0.5891\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3560 - mae: 0.4083\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3214 - mae: 0.3986\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3145 - mae: 0.3985\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3134 - mae: 0.3973\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3082 - mae: 0.3958\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3261 - mae: 0.3976\n528/528 [==============================] - 0s 636us/step - loss: 0.3431 - mae: 0.3998\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5702 - mae: 0.5189\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3422 - mae: 0.3930\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.3557 - mae: 0.3957\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3571 - mae: 0.3922\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3362 - mae: 0.3914\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3345 - mae: 0.3966\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3449 - mae: 0.3970\n528/528 [==============================] - 0s 642us/step - loss: 0.3466 - mae: 0.3981\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4419 - mae: 0.4480\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3574 - mae: 0.3987\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3449 - mae: 0.4001\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3423 - mae: 0.3975\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3359 - mae: 0.3963\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3255 - mae: 0.3949\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3391 - mae: 0.3983\n528/528 [==============================] - 0s 639us/step - loss: 0.3433 - mae: 0.3989\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1733 - mae: 0.3677\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4136 - mae: 0.4049\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3868 - mae: 0.4028\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3907 - mae: 0.4008\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3768 - mae: 0.3999\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3571 - mae: 0.3974\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3464 - mae: 0.3967\n528/528 [==============================] - 0s 631us/step - loss: 0.3386 - mae: 0.3965\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1569 - mae: 0.3254\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3670 - mae: 0.4015\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3880 - mae: 0.4015\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3784 - mae: 0.4021\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3688 - mae: 0.3999\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3554 - mae: 0.3979\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3486 - mae: 0.3988\n528/528 [==============================] - 0s 640us/step - loss: 0.3397 - mae: 0.3969\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3246 - mae: 0.4548\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3278 - mae: 0.3848\n147/528 [=======&gt;......................] - ETA: 0s - loss: 0.3012 - mae: 0.3872\n223/528 [===========&gt;..................] - ETA: 0s - loss: 0.3227 - mae: 0.3933\n301/528 [================&gt;.............] - ETA: 0s - loss: 0.3338 - mae: 0.3925\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3387 - mae: 0.3955\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3484 - mae: 0.3985\n528/528 [==============================] - 0s 657us/step - loss: 0.3411 - mae: 0.3976\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3876 - mae: 0.4227\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4170 - mae: 0.4079\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3669 - mae: 0.3980\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3567 - mae: 0.3944\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3675 - mae: 0.4009\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3543 - mae: 0.3976\n491/528 [==========================&gt;...] - ETA: 0s - loss: 0.3491 - mae: 0.3974\n528/528 [==============================] - 0s 621us/step - loss: 0.3411 - mae: 0.3956\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1452 - mae: 0.3013\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4670 - mae: 0.4143\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.4503 - mae: 0.4113\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3908 - mae: 0.3991\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3698 - mae: 0.3999\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3512 - mae: 0.3987\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3429 - mae: 0.3962\n528/528 [==============================] - 0s 616us/step - loss: 0.3376 - mae: 0.3960\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2073 - mae: 0.3382\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3197 - mae: 0.3980\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3046 - mae: 0.3916\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.2960 - mae: 0.3875\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3487 - mae: 0.3960\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3413 - mae: 0.3935\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3350 - mae: 0.3952\n528/528 [==============================] - 0s 630us/step - loss: 0.3399 - mae: 0.3952\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4294 - mae: 0.5316\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3431 - mae: 0.3988\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3511 - mae: 0.3981\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3370 - mae: 0.3965\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3238 - mae: 0.3935\n352/528 [===================&gt;..........] - ETA: 0s - loss: 0.3259 - mae: 0.3952\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3255 - mae: 0.3927\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3271 - mae: 0.3927\n528/528 [==============================] - 0s 730us/step - loss: 0.3385 - mae: 0.3955\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1718 - mae: 0.3375\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2919 - mae: 0.3936\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3047 - mae: 0.3981\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3066 - mae: 0.3925\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3228 - mae: 0.3927\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3207 - mae: 0.3900\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3406 - mae: 0.3952\n528/528 [==============================] - 0s 629us/step - loss: 0.3394 - mae: 0.3950\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2446 - mae: 0.3473\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3342 - mae: 0.3955\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3130 - mae: 0.3952\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3416 - mae: 0.3948\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3402 - mae: 0.3933\n374/528 [====================&gt;.........] - ETA: 0s - loss: 0.3340 - mae: 0.3928\n446/528 [========================&gt;.....] - ETA: 0s - loss: 0.3304 - mae: 0.3938\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3388 - mae: 0.3952\n528/528 [==============================] - 0s 716us/step - loss: 0.3374 - mae: 0.3955\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1261 - mae: 0.2995\n 62/528 [==&gt;...........................] - ETA: 0s - loss: 0.4097 - mae: 0.4044\n130/528 [======&gt;.......................] - ETA: 0s - loss: 0.3977 - mae: 0.4058\n199/528 [==========&gt;...................] - ETA: 0s - loss: 0.3453 - mae: 0.3951\n276/528 [==============&gt;...............] - ETA: 0s - loss: 0.3192 - mae: 0.3926\n350/528 [==================&gt;...........] - ETA: 0s - loss: 0.3146 - mae: 0.3925\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3301 - mae: 0.3952\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3430 - mae: 0.3979\n528/528 [==============================] - 0s 709us/step - loss: 0.3375 - mae: 0.3971\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1704 - mae: 0.3439\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3438 - mae: 0.4080\n147/528 [=======&gt;......................] - ETA: 0s - loss: 0.3411 - mae: 0.4004\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3238 - mae: 0.3918\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3184 - mae: 0.3905\n372/528 [====================&gt;.........] - ETA: 0s - loss: 0.3216 - mae: 0.3921\n436/528 [=======================&gt;......] - ETA: 0s - loss: 0.3132 - mae: 0.3901\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3283 - mae: 0.3930\n528/528 [==============================] - 0s 715us/step - loss: 0.3368 - mae: 0.3948\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1698 - mae: 0.2993\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3676 - mae: 0.3989\n147/528 [=======&gt;......................] - ETA: 0s - loss: 0.3616 - mae: 0.3962\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3347 - mae: 0.3882\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3442 - mae: 0.3925\n372/528 [====================&gt;.........] - ETA: 0s - loss: 0.3403 - mae: 0.3911\n446/528 [========================&gt;.....] - ETA: 0s - loss: 0.3447 - mae: 0.3922\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3407 - mae: 0.3934\n528/528 [==============================] - 0s 691us/step - loss: 0.3395 - mae: 0.3934\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3159 - mae: 0.4281\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3423 - mae: 0.3796\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.3217 - mae: 0.3866\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3065 - mae: 0.3874\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.3139 - mae: 0.3876\n363/528 [===================&gt;..........] - ETA: 0s - loss: 0.3112 - mae: 0.3880\n436/528 [=======================&gt;......] - ETA: 0s - loss: 0.3118 - mae: 0.3889\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3243 - mae: 0.3915\n528/528 [==============================] - 0s 702us/step - loss: 0.3392 - mae: 0.3943\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3377 - mae: 0.4405\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2944 - mae: 0.3855\n134/528 [======&gt;.......................] - ETA: 0s - loss: 0.3128 - mae: 0.3868\n195/528 [==========&gt;...................] - ETA: 0s - loss: 0.3190 - mae: 0.3903\n257/528 [=============&gt;................] - ETA: 0s - loss: 0.3143 - mae: 0.3918\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3232 - mae: 0.3945\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3133 - mae: 0.3921\n443/528 [========================&gt;.....] - ETA: 0s - loss: 0.3381 - mae: 0.3954\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3375 - mae: 0.3967\n528/528 [==============================] - 0s 845us/step - loss: 0.3380 - mae: 0.3958\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1170 - mae: 0.3006\n 62/528 [==&gt;...........................] - ETA: 0s - loss: 0.3402 - mae: 0.3833\n131/528 [======&gt;.......................] - ETA: 0s - loss: 0.3861 - mae: 0.3921\n201/528 [==========&gt;...................] - ETA: 0s - loss: 0.3666 - mae: 0.3942\n267/528 [==============&gt;...............] - ETA: 0s - loss: 0.3403 - mae: 0.3911\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3475 - mae: 0.3958\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3404 - mae: 0.3927\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3369 - mae: 0.3930\n528/528 [==============================] - 0s 741us/step - loss: 0.3369 - mae: 0.3951\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2169 - mae: 0.3792\n 48/528 [=&gt;............................] - ETA: 0s - loss: 0.3121 - mae: 0.4067\n108/528 [=====&gt;........................] - ETA: 0s - loss: 0.2744 - mae: 0.3848\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3147 - mae: 0.3949\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.3072 - mae: 0.3916\n293/528 [===============&gt;..............] - ETA: 0s - loss: 0.3154 - mae: 0.3898\n359/528 [===================&gt;..........] - ETA: 0s - loss: 0.3391 - mae: 0.3930\n432/528 [=======================&gt;......] - ETA: 0s - loss: 0.3438 - mae: 0.3930\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3365 - mae: 0.3922\n528/528 [==============================] - 0s 799us/step - loss: 0.3375 - mae: 0.3924\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3320 - mae: 0.4017\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2669 - mae: 0.3742\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3308 - mae: 0.3846\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3314 - mae: 0.3835\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3209 - mae: 0.3852\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3290 - mae: 0.3874\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3247 - mae: 0.3897\n528/528 [==============================] - 0s 640us/step - loss: 0.3346 - mae: 0.3916\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2598 - mae: 0.4611\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4093 - mae: 0.4057\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3548 - mae: 0.3960\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3523 - mae: 0.3935\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3672 - mae: 0.3964\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3550 - mae: 0.3957\n462/528 [=========================&gt;....] - ETA: 0s - loss: 0.3454 - mae: 0.3934\n526/528 [============================&gt;.] - ETA: 0s - loss: 0.3379 - mae: 0.3928\n528/528 [==============================] - 0s 681us/step - loss: 0.3378 - mae: 0.3931\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1491 - mae: 0.3078\n 67/528 [==&gt;...........................] - ETA: 0s - loss: 0.3708 - mae: 0.3944\n135/528 [======&gt;.......................] - ETA: 0s - loss: 0.3452 - mae: 0.3935\n205/528 [==========&gt;...................] - ETA: 0s - loss: 0.3216 - mae: 0.3944\n274/528 [==============&gt;...............] - ETA: 0s - loss: 0.3300 - mae: 0.3957\n350/528 [==================&gt;...........] - ETA: 0s - loss: 0.3421 - mae: 0.3958\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3506 - mae: 0.3948\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3399 - mae: 0.3928\n528/528 [==============================] - 0s 708us/step - loss: 0.3386 - mae: 0.3924\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0679 - mae: 0.2209\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3655 - mae: 0.4023\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3881 - mae: 0.4083\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3512 - mae: 0.3995\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3387 - mae: 0.3969\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3463 - mae: 0.3968\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3445 - mae: 0.3953\n528/528 [==============================] - 0s 658us/step - loss: 0.3331 - mae: 0.3932\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1709 - mae: 0.3208\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3688 - mae: 0.4040\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3771 - mae: 0.4032\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3408 - mae: 0.3956\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3395 - mae: 0.3940\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.3345 - mae: 0.3931\n455/528 [========================&gt;.....] - ETA: 0s - loss: 0.3349 - mae: 0.3911\n528/528 [==============================] - 0s 659us/step - loss: 0.3361 - mae: 0.3921\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2014 - mae: 0.3466\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2871 - mae: 0.3820\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3247 - mae: 0.3794\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3179 - mae: 0.3854\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3197 - mae: 0.3880\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3062 - mae: 0.3852\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3098 - mae: 0.3868\n528/528 [==============================] - 0s 650us/step - loss: 0.3356 - mae: 0.3912\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2371 - mae: 0.4013\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2940 - mae: 0.3845\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3246 - mae: 0.3876\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3173 - mae: 0.3890\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3090 - mae: 0.3875\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3138 - mae: 0.3881\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3352 - mae: 0.3915\n528/528 [==============================] - 0s 622us/step - loss: 0.3385 - mae: 0.3922\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4458 - mae: 0.4853\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.2866 - mae: 0.3841\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3214 - mae: 0.3875\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3247 - mae: 0.3926\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3512 - mae: 0.3952\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3317 - mae: 0.3921\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3391 - mae: 0.3925\n528/528 [==============================] - 0s 612us/step - loss: 0.3332 - mae: 0.3919\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1014 - mae: 0.2589\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4794 - mae: 0.4057\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.4118 - mae: 0.3984\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3616 - mae: 0.3938\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3487 - mae: 0.3916\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3319 - mae: 0.3903\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3342 - mae: 0.3921\n528/528 [==============================] - 0s 625us/step - loss: 0.3325 - mae: 0.3911\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1873 - mae: 0.3328\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3057 - mae: 0.4009\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3110 - mae: 0.3940\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3143 - mae: 0.3944\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3047 - mae: 0.3923\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3443 - mae: 0.3941\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3371 - mae: 0.3923\n528/528 [==============================] - 0s 609us/step - loss: 0.3336 - mae: 0.3916\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2360 - mae: 0.2863\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3666 - mae: 0.3950\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3407 - mae: 0.3903\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3508 - mae: 0.3939\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3472 - mae: 0.3914\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3424 - mae: 0.3919\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3372 - mae: 0.3907\n528/528 [==============================] - 0s 615us/step - loss: 0.3340 - mae: 0.3904\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3210 - mae: 0.4399\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4118 - mae: 0.4063\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3933 - mae: 0.4036\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3624 - mae: 0.3989\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3719 - mae: 0.4019\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3584 - mae: 0.3950\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3380 - mae: 0.3908\n528/528 [==============================] - 0s 656us/step - loss: 0.3331 - mae: 0.3904\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2988 - mae: 0.3294\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2945 - mae: 0.3876\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.2944 - mae: 0.3973\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3204 - mae: 0.3959\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3414 - mae: 0.3953\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3402 - mae: 0.3930\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3362 - mae: 0.3911\n528/528 [==============================] - 0s 643us/step - loss: 0.3338 - mae: 0.3907\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4223 - mae: 0.4288\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.2653 - mae: 0.3737\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3395 - mae: 0.3873\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3390 - mae: 0.3849\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3344 - mae: 0.3849\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3349 - mae: 0.3886\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3372 - mae: 0.3890\n528/528 [==============================] - 0s 634us/step - loss: 0.3347 - mae: 0.3890\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 6.5383 - mae: 1.0047\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3942 - mae: 0.3854\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3206 - mae: 0.3763\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3451 - mae: 0.3880\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3277 - mae: 0.3853\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3219 - mae: 0.3844\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3411 - mae: 0.3899\n528/528 [==============================] - 0s 643us/step - loss: 0.3326 - mae: 0.3896\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2807 - mae: 0.4652\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3654 - mae: 0.3974\n145/528 [=======&gt;......................] - ETA: 0s - loss: 0.3718 - mae: 0.3959\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3382 - mae: 0.3910\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3568 - mae: 0.3952\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3478 - mae: 0.3915\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.3314 - mae: 0.3880\n528/528 [==============================] - 0s 649us/step - loss: 0.3352 - mae: 0.3905\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1195 - mae: 0.2932\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3417 - mae: 0.3818\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3743 - mae: 0.3931\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3652 - mae: 0.3905\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3428 - mae: 0.3871\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3347 - mae: 0.3874\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3291 - mae: 0.3885\n528/528 [==============================] - 0s 641us/step - loss: 0.3347 - mae: 0.3888\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4042 - mae: 0.5040\n 53/528 [==&gt;...........................] - ETA: 0s - loss: 0.2645 - mae: 0.3795\n127/528 [======&gt;.......................] - ETA: 0s - loss: 0.3104 - mae: 0.3856\n208/528 [==========&gt;...................] - ETA: 0s - loss: 0.2897 - mae: 0.3833\n284/528 [===============&gt;..............] - ETA: 0s - loss: 0.2881 - mae: 0.3820\n360/528 [===================&gt;..........] - ETA: 0s - loss: 0.3136 - mae: 0.3856\n441/528 [========================&gt;.....] - ETA: 0s - loss: 0.3332 - mae: 0.3883\n521/528 [============================&gt;.] - ETA: 0s - loss: 0.3360 - mae: 0.3897\n528/528 [==============================] - 0s 679us/step - loss: 0.3350 - mae: 0.3897\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0822 - mae: 0.2550\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4626 - mae: 0.4072\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3764 - mae: 0.3943\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3509 - mae: 0.3906\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3451 - mae: 0.3873\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3298 - mae: 0.3866\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3377 - mae: 0.3890\n528/528 [==============================] - 0s 637us/step - loss: 0.3329 - mae: 0.3886\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1419 - mae: 0.3022\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.2623 - mae: 0.3778\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.2810 - mae: 0.3800\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3040 - mae: 0.3859\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3253 - mae: 0.3892\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3521 - mae: 0.3932\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3378 - mae: 0.3917\n528/528 [==============================] - 0s 607us/step - loss: 0.3350 - mae: 0.3913\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0922 - mae: 0.2472\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3392 - mae: 0.3882\n172/528 [========&gt;.....................] - ETA: 0s - loss: 0.3160 - mae: 0.3909\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3449 - mae: 0.3960\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3386 - mae: 0.3927\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3521 - mae: 0.3948\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3398 - mae: 0.3904\n528/528 [==============================] - 0s 608us/step - loss: 0.3348 - mae: 0.3894\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.9525 - mae: 0.6700\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3680 - mae: 0.3986\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3594 - mae: 0.3924\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3242 - mae: 0.3857\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3264 - mae: 0.3865\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3242 - mae: 0.3867\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3349 - mae: 0.3892\n528/528 [==============================] - 0s 611us/step - loss: 0.3341 - mae: 0.3898\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2362 - mae: 0.3973\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.3508 - mae: 0.3844\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3331 - mae: 0.3909\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3415 - mae: 0.3903\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3434 - mae: 0.3890\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3479 - mae: 0.3909\n439/528 [=======================&gt;......] - ETA: 0s - loss: 0.3474 - mae: 0.3907\n514/528 [============================&gt;.] - ETA: 0s - loss: 0.3367 - mae: 0.3909\n528/528 [==============================] - 0s 692us/step - loss: 0.3335 - mae: 0.3901\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2722 - mae: 0.4346\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.2358 - mae: 0.3762\n147/528 [=======&gt;......................] - ETA: 0s - loss: 0.2938 - mae: 0.3882\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3181 - mae: 0.3900\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3218 - mae: 0.3917\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3286 - mae: 0.3899\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.3388 - mae: 0.3906\n528/528 [==============================] - 0s 654us/step - loss: 0.3307 - mae: 0.3890\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2924 - mae: 0.4667\n 54/528 [==&gt;...........................] - ETA: 0s - loss: 0.3138 - mae: 0.3761\n117/528 [=====&gt;........................] - ETA: 0s - loss: 0.2829 - mae: 0.3767\n187/528 [=========&gt;....................] - ETA: 0s - loss: 0.3106 - mae: 0.3816\n261/528 [=============&gt;................] - ETA: 0s - loss: 0.3253 - mae: 0.3844\n342/528 [==================&gt;...........] - ETA: 0s - loss: 0.3269 - mae: 0.3857\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3292 - mae: 0.3878\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3386 - mae: 0.3909\n528/528 [==============================] - 0s 720us/step - loss: 0.3340 - mae: 0.3905\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1957 - mae: 0.3700\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2648 - mae: 0.3690\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2993 - mae: 0.3795\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.2994 - mae: 0.3833\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.2955 - mae: 0.3830\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.2946 - mae: 0.3840\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3158 - mae: 0.3854\n528/528 [==============================] - 0s 639us/step - loss: 0.3325 - mae: 0.3872\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5080 - mae: 0.5489\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3517 - mae: 0.3851\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3638 - mae: 0.3860\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3528 - mae: 0.3864\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3443 - mae: 0.3881\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3363 - mae: 0.3903\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3267 - mae: 0.3881\n528/528 [==============================] - 0s 604us/step - loss: 0.3301 - mae: 0.3891\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2195 - mae: 0.3754\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2624 - mae: 0.3744\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2981 - mae: 0.3824\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3347 - mae: 0.3846\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3182 - mae: 0.3855\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3100 - mae: 0.3871\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3313 - mae: 0.3889\n528/528 [==============================] - 0s 607us/step - loss: 0.3311 - mae: 0.3884\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3192 - mae: 0.4527\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.2601 - mae: 0.3722\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3222 - mae: 0.3818\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3053 - mae: 0.3831\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3095 - mae: 0.3822\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3179 - mae: 0.3847\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3216 - mae: 0.3882\n528/528 [==============================] - 0s 637us/step - loss: 0.3292 - mae: 0.3891\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3830 - mae: 0.4674\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3644 - mae: 0.3955\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3506 - mae: 0.3883\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3441 - mae: 0.3896\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3342 - mae: 0.3867\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3539 - mae: 0.3897\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3396 - mae: 0.3897\n528/528 [==============================] - 0s 652us/step - loss: 0.3324 - mae: 0.3883\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1486 - mae: 0.3190\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3622 - mae: 0.4035\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.3378 - mae: 0.3979\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3681 - mae: 0.3993\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3407 - mae: 0.3945\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3216 - mae: 0.3908\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3372 - mae: 0.3927\n528/528 [==============================] - 0s 626us/step - loss: 0.3299 - mae: 0.3905\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0871 - mae: 0.2297\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2872 - mae: 0.3894\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.2983 - mae: 0.3825\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.2950 - mae: 0.3851\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3049 - mae: 0.3860\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3246 - mae: 0.3903\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3328 - mae: 0.3915\n528/528 [==============================] - 0s 656us/step - loss: 0.3364 - mae: 0.3916\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2467 - mae: 0.4049\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3420 - mae: 0.3858\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3190 - mae: 0.3874\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3223 - mae: 0.3874\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3453 - mae: 0.3919\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3313 - mae: 0.3895\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3343 - mae: 0.3897\n528/528 [==============================] - 0s 618us/step - loss: 0.3335 - mae: 0.3905\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5725 - mae: 0.4443\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3114 - mae: 0.3956\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3018 - mae: 0.3910\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3228 - mae: 0.3914\n301/528 [================&gt;.............] - ETA: 0s - loss: 0.3179 - mae: 0.3888\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3214 - mae: 0.3895\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3295 - mae: 0.3903\n528/528 [==============================] - 0s 653us/step - loss: 0.3315 - mae: 0.3896\n\n\n\n\nsee code\nnum_epochs &lt;- 100\nall_mae_histories &lt;- list()\nfor (i in 1:k) {\ncat(\"Processing fold #\", i, \"\\n\")\nval_indices &lt;- which(fold_id == i)\nval_data &lt;- train_data[val_indices, ]\nval_targets &lt;- train_targets[val_indices]\npartial_train_data &lt;- train_data[-val_indices, ]\npartial_train_targets &lt;- train_targets[-val_indices]\nmodel &lt;- build_model()\nhistory &lt;- model %&gt;% fit(\npartial_train_data, partial_train_targets,\nvalidation_data = list(val_data, val_targets),\nepochs = num_epochs, batch_size = 16, verbose = 1\n)\nmae_history &lt;- history$metrics$val_mae\nall_mae_histories[[i]] &lt;- mae_history\n}\n\n\nProcessing fold # 1 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 125.8926 - mae: 11.2120\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 42.2068 - mae: 5.4807  \n163/528 [========&gt;.....................] - ETA: 0s - loss: 21.9507 - mae: 3.3061\n248/528 [=============&gt;................] - ETA: 0s - loss: 14.9648 - mae: 2.4651\n334/528 [=================&gt;............] - ETA: 0s - loss: 11.3416 - mae: 2.0061\n416/528 [======================&gt;.......] - ETA: 0s - loss: 9.2292 - mae: 1.7261 \n500/528 [===========================&gt;..] - ETA: 0s - loss: 7.7845 - mae: 1.5250\n528/528 [==============================] - 1s 995us/step - loss: 7.3919 - mae: 1.4693 - val_loss: 0.5902 - val_mae: 0.4888\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.9301 - mae: 0.7593\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4606 - mae: 0.4829\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.4203 - mae: 0.4692\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.4323 - mae: 0.4654\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.4343 - mae: 0.4617\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.4186 - mae: 0.4561\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.4039 - mae: 0.4533\n528/528 [==============================] - 0s 873us/step - loss: 0.3962 - mae: 0.4521 - val_loss: 0.4699 - val_mae: 0.4587\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2112 - mae: 0.3773\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3647 - mae: 0.4192\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3290 - mae: 0.4161\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3560 - mae: 0.4269\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3675 - mae: 0.4278\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3707 - mae: 0.4283\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3655 - mae: 0.4303\n528/528 [==============================] - 0s 808us/step - loss: 0.3635 - mae: 0.4308 - val_loss: 0.4191 - val_mae: 0.4127\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3036 - mae: 0.4429\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3158 - mae: 0.4199\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4198 - mae: 0.4369\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3916 - mae: 0.4342\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3685 - mae: 0.4281\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3620 - mae: 0.4265\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3521 - mae: 0.4256\n528/528 [==============================] - 0s 845us/step - loss: 0.3561 - mae: 0.4268 - val_loss: 0.4552 - val_mae: 0.4534\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2623 - mae: 0.4283\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4412 - mae: 0.4220\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.4010 - mae: 0.4239\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3727 - mae: 0.4251\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3515 - mae: 0.4202\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3474 - mae: 0.4229\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3454 - mae: 0.4228\n528/528 [==============================] - 0s 808us/step - loss: 0.3493 - mae: 0.4237 - val_loss: 0.4514 - val_mae: 0.4251\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2663 - mae: 0.3664\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3172 - mae: 0.4207\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3089 - mae: 0.4142\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3155 - mae: 0.4137\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3147 - mae: 0.4144\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3160 - mae: 0.4124\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3409 - mae: 0.4173\n528/528 [==============================] - 0s 798us/step - loss: 0.3471 - mae: 0.4191 - val_loss: 0.4958 - val_mae: 0.4966\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1963 - mae: 0.4082\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3736 - mae: 0.4330\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3481 - mae: 0.4212\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3633 - mae: 0.4205\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3469 - mae: 0.4191\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3392 - mae: 0.4167\n448/528 [========================&gt;.....] - ETA: 0s - loss: 0.3511 - mae: 0.4190\n528/528 [==============================] - 0s 880us/step - loss: 0.3467 - mae: 0.4194 - val_loss: 0.4390 - val_mae: 0.4428\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1241 - mae: 0.2776\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3352 - mae: 0.4202\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3719 - mae: 0.4221\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3456 - mae: 0.4156\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3376 - mae: 0.4158\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3351 - mae: 0.4147\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3285 - mae: 0.4144\n528/528 [==============================] - 0s 820us/step - loss: 0.3460 - mae: 0.4179 - val_loss: 0.4481 - val_mae: 0.4279\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2862 - mae: 0.4238\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4010 - mae: 0.4307\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3646 - mae: 0.4219\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3671 - mae: 0.4264\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3501 - mae: 0.4240\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3576 - mae: 0.4199\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3474 - mae: 0.4178\n528/528 [==============================] - 0s 826us/step - loss: 0.3423 - mae: 0.4152 - val_loss: 0.4184 - val_mae: 0.4084\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3185 - mae: 0.4344\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2970 - mae: 0.4166\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3214 - mae: 0.4182\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3451 - mae: 0.4206\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3530 - mae: 0.4201\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3559 - mae: 0.4213\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3434 - mae: 0.4185\n528/528 [==============================] - 0s 827us/step - loss: 0.3416 - mae: 0.4185 - val_loss: 0.4198 - val_mae: 0.4205\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.4995 - mae: 0.5225\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.3307 - mae: 0.4175\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3307 - mae: 0.4100\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3590 - mae: 0.4155\n289/528 [===============&gt;..............] - ETA: 0s - loss: 0.3453 - mae: 0.4173\n364/528 [===================&gt;..........] - ETA: 0s - loss: 0.3578 - mae: 0.4176\n434/528 [=======================&gt;......] - ETA: 0s - loss: 0.3533 - mae: 0.4176\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3421 - mae: 0.4146\n528/528 [==============================] - 0s 891us/step - loss: 0.3407 - mae: 0.4148 - val_loss: 0.4148 - val_mae: 0.4112\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2767 - mae: 0.4189\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2500 - mae: 0.3773\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2817 - mae: 0.3921\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3072 - mae: 0.4016\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3336 - mae: 0.4097\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3265 - mae: 0.4094\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3393 - mae: 0.4119\n528/528 [==============================] - 0s 864us/step - loss: 0.3354 - mae: 0.4112 - val_loss: 0.4219 - val_mae: 0.4162\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1158 - mae: 0.2605\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2689 - mae: 0.4013\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3522 - mae: 0.4199\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3503 - mae: 0.4177\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3357 - mae: 0.4150\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3505 - mae: 0.4182\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3365 - mae: 0.4131\n528/528 [==============================] - 0s 835us/step - loss: 0.3382 - mae: 0.4122 - val_loss: 0.4080 - val_mae: 0.3971\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0807 - mae: 0.2570\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.4072 - mae: 0.4202\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3424 - mae: 0.4133\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.3307 - mae: 0.4131\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3334 - mae: 0.4106\n373/528 [====================&gt;.........] - ETA: 0s - loss: 0.3360 - mae: 0.4119\n451/528 [========================&gt;.....] - ETA: 0s - loss: 0.3477 - mae: 0.4139\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3367 - mae: 0.4112\n528/528 [==============================] - 0s 873us/step - loss: 0.3364 - mae: 0.4111 - val_loss: 0.4219 - val_mae: 0.4065\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2067 - mae: 0.3821\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3271 - mae: 0.4153\n145/528 [=======&gt;......................] - ETA: 0s - loss: 0.3442 - mae: 0.4235\n215/528 [===========&gt;..................] - ETA: 0s - loss: 0.3459 - mae: 0.4227\n282/528 [===============&gt;..............] - ETA: 0s - loss: 0.3489 - mae: 0.4185\n357/528 [===================&gt;..........] - ETA: 0s - loss: 0.3420 - mae: 0.4173\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3377 - mae: 0.4155\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3402 - mae: 0.4139\n528/528 [==============================] - 0s 943us/step - loss: 0.3353 - mae: 0.4127 - val_loss: 0.4575 - val_mae: 0.4600\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3037 - mae: 0.4766\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2900 - mae: 0.4032\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2923 - mae: 0.4038\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.2851 - mae: 0.3980\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.2849 - mae: 0.3974\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3008 - mae: 0.4024\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3342 - mae: 0.4084\n528/528 [==============================] - 0s 846us/step - loss: 0.3351 - mae: 0.4106 - val_loss: 0.4076 - val_mae: 0.4026\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2358 - mae: 0.3901\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.2744 - mae: 0.4078\n148/528 [=======&gt;......................] - ETA: 0s - loss: 0.2717 - mae: 0.3971\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.3136 - mae: 0.4031\n287/528 [===============&gt;..............] - ETA: 0s - loss: 0.3284 - mae: 0.4073\n352/528 [===================&gt;..........] - ETA: 0s - loss: 0.3192 - mae: 0.4072\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3281 - mae: 0.4103\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3349 - mae: 0.4092\n528/528 [==============================] - 0s 935us/step - loss: 0.3346 - mae: 0.4095 - val_loss: 0.4072 - val_mae: 0.4025\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2929 - mae: 0.4180\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.4173 - mae: 0.4160\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3315 - mae: 0.3993\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3181 - mae: 0.4005\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3447 - mae: 0.4078\n374/528 [====================&gt;.........] - ETA: 0s - loss: 0.3388 - mae: 0.4079\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3313 - mae: 0.4072\n528/528 [==============================] - 0s 869us/step - loss: 0.3330 - mae: 0.4084 - val_loss: 0.4125 - val_mae: 0.4091\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.0960 - mae: 0.6798\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3668 - mae: 0.4132\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3600 - mae: 0.4158\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3667 - mae: 0.4109\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3608 - mae: 0.4147\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3435 - mae: 0.4101\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3374 - mae: 0.4077\n528/528 [==============================] - 0s 859us/step - loss: 0.3294 - mae: 0.4060 - val_loss: 0.4102 - val_mae: 0.3965\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5533 - mae: 0.4633\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4007 - mae: 0.4281\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.4023 - mae: 0.4244\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3680 - mae: 0.4168\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3428 - mae: 0.4101\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3294 - mae: 0.4067\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3340 - mae: 0.4067\n528/528 [==============================] - 0s 834us/step - loss: 0.3315 - mae: 0.4055 - val_loss: 0.4892 - val_mae: 0.4926\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2544 - mae: 0.4633\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2961 - mae: 0.4011\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3410 - mae: 0.4122\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3325 - mae: 0.4081\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3235 - mae: 0.4081\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3207 - mae: 0.4087\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3205 - mae: 0.4076\n528/528 [==============================] - 0s 825us/step - loss: 0.3318 - mae: 0.4091 - val_loss: 0.4015 - val_mae: 0.4070\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2006 - mae: 0.3594\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4011 - mae: 0.4242\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3612 - mae: 0.4157\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3397 - mae: 0.4110\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3299 - mae: 0.4094\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3500 - mae: 0.4135\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3322 - mae: 0.4091\n528/528 [==============================] - 0s 833us/step - loss: 0.3328 - mae: 0.4094 - val_loss: 0.3975 - val_mae: 0.3955\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3256 - mae: 0.4328\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3389 - mae: 0.4038\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3243 - mae: 0.4060\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3537 - mae: 0.4119\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3457 - mae: 0.4055\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3392 - mae: 0.4050\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3314 - mae: 0.4038\n528/528 [==============================] - 0s 818us/step - loss: 0.3285 - mae: 0.4038 - val_loss: 0.4632 - val_mae: 0.4627\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1965 - mae: 0.3792\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3465 - mae: 0.4011\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3146 - mae: 0.3981\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3608 - mae: 0.4087\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3410 - mae: 0.4058\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3297 - mae: 0.4068\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3309 - mae: 0.4066\n528/528 [==============================] - 0s 847us/step - loss: 0.3307 - mae: 0.4066 - val_loss: 0.4249 - val_mae: 0.4172\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1843 - mae: 0.3316\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2755 - mae: 0.3834\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3150 - mae: 0.3930\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3472 - mae: 0.4058\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3384 - mae: 0.4088\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3281 - mae: 0.4064\n469/528 [=========================&gt;....] - ETA: 0s - loss: 0.3377 - mae: 0.4081\n528/528 [==============================] - 0s 835us/step - loss: 0.3297 - mae: 0.4076 - val_loss: 0.4377 - val_mae: 0.4188\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1623 - mae: 0.3198\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3999 - mae: 0.4400\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3527 - mae: 0.4194\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3345 - mae: 0.4162\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3430 - mae: 0.4123\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3463 - mae: 0.4117\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3307 - mae: 0.4067\n528/528 [==============================] - 0s 841us/step - loss: 0.3316 - mae: 0.4079 - val_loss: 0.4244 - val_mae: 0.4336\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2288 - mae: 0.3532\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3247 - mae: 0.4091\n140/528 [======&gt;.......................] - ETA: 0s - loss: 0.3081 - mae: 0.4063\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3113 - mae: 0.4079\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.2962 - mae: 0.4004\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.2966 - mae: 0.3997\n455/528 [========================&gt;.....] - ETA: 0s - loss: 0.3164 - mae: 0.4025\n528/528 [==============================] - 0s 848us/step - loss: 0.3261 - mae: 0.4029 - val_loss: 0.4212 - val_mae: 0.4329\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2747 - mae: 0.3603\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3026 - mae: 0.3953\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2941 - mae: 0.3977\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.2944 - mae: 0.4007\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.2969 - mae: 0.4003\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3082 - mae: 0.4029\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3146 - mae: 0.4037\n528/528 [==============================] - 0s 834us/step - loss: 0.3287 - mae: 0.4063 - val_loss: 0.4003 - val_mae: 0.4063\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1015 - mae: 0.2593\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2983 - mae: 0.4051\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3116 - mae: 0.4022\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3380 - mae: 0.4056\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3414 - mae: 0.4078\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3318 - mae: 0.4061\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3340 - mae: 0.4068\n528/528 [==============================] - 0s 843us/step - loss: 0.3287 - mae: 0.4048 - val_loss: 0.4274 - val_mae: 0.4120\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1802 - mae: 0.3178\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3408 - mae: 0.4180\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3528 - mae: 0.4089\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3427 - mae: 0.4069\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3501 - mae: 0.4089\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3392 - mae: 0.4061\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3311 - mae: 0.4052\n528/528 [==============================] - 0s 825us/step - loss: 0.3259 - mae: 0.4046 - val_loss: 0.4786 - val_mae: 0.4470\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3052 - mae: 0.4874\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3677 - mae: 0.4124\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3512 - mae: 0.4026\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3281 - mae: 0.3988\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3284 - mae: 0.4019\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3237 - mae: 0.4021\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3183 - mae: 0.4002\n528/528 [==============================] - 0s 825us/step - loss: 0.3272 - mae: 0.4035 - val_loss: 0.4299 - val_mae: 0.4422\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5810 - mae: 0.6155\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2851 - mae: 0.3998\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2618 - mae: 0.3869\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3109 - mae: 0.3926\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3129 - mae: 0.3957\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3334 - mae: 0.4022\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3249 - mae: 0.4020\n528/528 [==============================] - 0s 813us/step - loss: 0.3271 - mae: 0.4024 - val_loss: 0.4077 - val_mae: 0.4162\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3774 - mae: 0.4668\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3059 - mae: 0.4004\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3392 - mae: 0.4028\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3214 - mae: 0.3992\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3285 - mae: 0.4030\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3249 - mae: 0.4023\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3324 - mae: 0.4037\n528/528 [==============================] - 0s 852us/step - loss: 0.3258 - mae: 0.4019 - val_loss: 0.4151 - val_mae: 0.4194\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4540 - mae: 0.3880\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3463 - mae: 0.3981\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3419 - mae: 0.4094\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3151 - mae: 0.4024\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3371 - mae: 0.4056\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3408 - mae: 0.4066\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3303 - mae: 0.4032\n528/528 [==============================] - 0s 808us/step - loss: 0.3249 - mae: 0.4019 - val_loss: 0.4005 - val_mae: 0.3963\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1434 - mae: 0.3098\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2865 - mae: 0.3871\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3242 - mae: 0.3948\n214/528 [===========&gt;..................] - ETA: 0s - loss: 0.3257 - mae: 0.3958\n286/528 [===============&gt;..............] - ETA: 0s - loss: 0.3182 - mae: 0.3964\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3111 - mae: 0.3957\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3265 - mae: 0.4005\n528/528 [==============================] - 0s 863us/step - loss: 0.3247 - mae: 0.4026 - val_loss: 0.4158 - val_mae: 0.4003\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3641 - mae: 0.4781\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2975 - mae: 0.4017\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3183 - mae: 0.4008\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3271 - mae: 0.4021\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3296 - mae: 0.4031\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3362 - mae: 0.4024\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3278 - mae: 0.4023\n528/528 [==============================] - 0s 847us/step - loss: 0.3252 - mae: 0.4017 - val_loss: 0.4004 - val_mae: 0.3967\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2731 - mae: 0.3280\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3314 - mae: 0.4088\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3012 - mae: 0.3974\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3029 - mae: 0.4000\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3163 - mae: 0.3988\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3319 - mae: 0.4013\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3269 - mae: 0.4004\n528/528 [==============================] - 0s 825us/step - loss: 0.3225 - mae: 0.4004 - val_loss: 0.4133 - val_mae: 0.4000\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3257 - mae: 0.4470\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3210 - mae: 0.3999\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3036 - mae: 0.3972\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3100 - mae: 0.3984\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3211 - mae: 0.4013\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3259 - mae: 0.4024\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3281 - mae: 0.4020\n528/528 [==============================] - 0s 813us/step - loss: 0.3248 - mae: 0.4019 - val_loss: 0.4041 - val_mae: 0.4015\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.4750 - mae: 0.5919\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3225 - mae: 0.4141\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3918 - mae: 0.4229\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3748 - mae: 0.4158\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3496 - mae: 0.4094\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3346 - mae: 0.4037\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3236 - mae: 0.4013\n528/528 [==============================] - 0s 823us/step - loss: 0.3241 - mae: 0.4015 - val_loss: 0.4143 - val_mae: 0.4209\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2958 - mae: 0.4066\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3018 - mae: 0.3912\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2721 - mae: 0.3813\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3021 - mae: 0.3903\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3258 - mae: 0.3970\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3328 - mae: 0.4023\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3276 - mae: 0.4016\n528/528 [==============================] - 0s 821us/step - loss: 0.3240 - mae: 0.4001 - val_loss: 0.4053 - val_mae: 0.4126\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1738 - mae: 0.3222\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2703 - mae: 0.3963\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2721 - mae: 0.3983\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3382 - mae: 0.4087\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3347 - mae: 0.4034\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3255 - mae: 0.4015\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3303 - mae: 0.4011\n528/528 [==============================] - 0s 854us/step - loss: 0.3213 - mae: 0.3989 - val_loss: 0.4024 - val_mae: 0.4095\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2057 - mae: 0.3553\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.4235 - mae: 0.4082\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3550 - mae: 0.4015\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3413 - mae: 0.4040\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3279 - mae: 0.4037\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3169 - mae: 0.3981\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3131 - mae: 0.3976\n528/528 [==============================] - 0s 838us/step - loss: 0.3219 - mae: 0.3994 - val_loss: 0.4054 - val_mae: 0.4028\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1628 - mae: 0.3483\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3243 - mae: 0.4019\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3030 - mae: 0.3930\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.2960 - mae: 0.3906\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3079 - mae: 0.3902\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3147 - mae: 0.3959\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3265 - mae: 0.4002\n528/528 [==============================] - 0s 827us/step - loss: 0.3202 - mae: 0.3978 - val_loss: 0.4797 - val_mae: 0.4453\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1564 - mae: 0.3401\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3395 - mae: 0.3851\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3253 - mae: 0.3929\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3290 - mae: 0.3969\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3285 - mae: 0.3977\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3155 - mae: 0.3931\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3106 - mae: 0.3960\n528/528 [==============================] - 0s 843us/step - loss: 0.3222 - mae: 0.3986 - val_loss: 0.4027 - val_mae: 0.4019\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4602 - mae: 0.4354\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3488 - mae: 0.4026\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3469 - mae: 0.4057\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3313 - mae: 0.4047\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3253 - mae: 0.4009\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3132 - mae: 0.3990\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3143 - mae: 0.3979\n528/528 [==============================] - 0s 847us/step - loss: 0.3211 - mae: 0.3979 - val_loss: 0.4216 - val_mae: 0.4098\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5896 - mae: 0.5241\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3091 - mae: 0.3943\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3176 - mae: 0.4004\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3399 - mae: 0.4042\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3403 - mae: 0.4028\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3287 - mae: 0.3999\n463/528 [=========================&gt;....] - ETA: 0s - loss: 0.3219 - mae: 0.3987\n528/528 [==============================] - 0s 847us/step - loss: 0.3234 - mae: 0.3983 - val_loss: 0.4012 - val_mae: 0.4058\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1795 - mae: 0.3499\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2997 - mae: 0.3940\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3134 - mae: 0.3944\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3097 - mae: 0.3963\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3290 - mae: 0.3999\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3240 - mae: 0.3996\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3291 - mae: 0.4002\n528/528 [==============================] - 0s 830us/step - loss: 0.3213 - mae: 0.3987 - val_loss: 0.4048 - val_mae: 0.3978\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2737 - mae: 0.3651\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2711 - mae: 0.3890\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.2965 - mae: 0.3974\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3361 - mae: 0.4071\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3446 - mae: 0.4043\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3325 - mae: 0.4011\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3263 - mae: 0.4004\n528/528 [==============================] - 0s 807us/step - loss: 0.3212 - mae: 0.3988 - val_loss: 0.4111 - val_mae: 0.4025\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3105 - mae: 0.4733\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2812 - mae: 0.3859\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.2729 - mae: 0.3846\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.2917 - mae: 0.3912\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.2798 - mae: 0.3894\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.2892 - mae: 0.3927\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3164 - mae: 0.3959\n528/528 [==============================] - 0s 817us/step - loss: 0.3183 - mae: 0.3973 - val_loss: 0.4081 - val_mae: 0.4056\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2032 - mae: 0.3453\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2847 - mae: 0.3936\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2921 - mae: 0.3967\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3149 - mae: 0.3968\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3030 - mae: 0.3931\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3171 - mae: 0.3954\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3089 - mae: 0.3949\n528/528 [==============================] - 0s 811us/step - loss: 0.3221 - mae: 0.3969 - val_loss: 0.4007 - val_mae: 0.4033\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4863 - mae: 0.5132\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3014 - mae: 0.4023\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3616 - mae: 0.4080\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3524 - mae: 0.4080\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3355 - mae: 0.4031\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3330 - mae: 0.4017\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3248 - mae: 0.3996\n528/528 [==============================] - 0s 827us/step - loss: 0.3198 - mae: 0.3985 - val_loss: 0.4041 - val_mae: 0.4082\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1707 - mae: 0.3477\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2539 - mae: 0.3878\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.2773 - mae: 0.3967\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.2767 - mae: 0.3928\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3204 - mae: 0.3975\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3254 - mae: 0.3996\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3194 - mae: 0.3971\n528/528 [==============================] - 0s 809us/step - loss: 0.3210 - mae: 0.3971 - val_loss: 0.4086 - val_mae: 0.4069\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2368 - mae: 0.4151\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3717 - mae: 0.4096\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3528 - mae: 0.4029\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3476 - mae: 0.4075\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3287 - mae: 0.4019\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3167 - mae: 0.3980\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3241 - mae: 0.3980\n528/528 [==============================] - 0s 813us/step - loss: 0.3189 - mae: 0.3968 - val_loss: 0.4217 - val_mae: 0.4263\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4158 - mae: 0.4875\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3639 - mae: 0.3994\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3496 - mae: 0.4017\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3383 - mae: 0.3986\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3250 - mae: 0.3956\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3174 - mae: 0.3954\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3118 - mae: 0.3945\n528/528 [==============================] - 0s 827us/step - loss: 0.3203 - mae: 0.3950 - val_loss: 0.4299 - val_mae: 0.4360\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2107 - mae: 0.3846\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3032 - mae: 0.3934\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3218 - mae: 0.3950\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3382 - mae: 0.3992\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3408 - mae: 0.4017\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3250 - mae: 0.3964\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3151 - mae: 0.3937\n528/528 [==============================] - 0s 831us/step - loss: 0.3155 - mae: 0.3948 - val_loss: 0.4026 - val_mae: 0.4071\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1355 - mae: 0.3063\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3164 - mae: 0.3907\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3011 - mae: 0.3906\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.2917 - mae: 0.3892\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.2959 - mae: 0.3915\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.2948 - mae: 0.3902\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3010 - mae: 0.3928\n528/528 [==============================] - 0s 853us/step - loss: 0.3150 - mae: 0.3949 - val_loss: 0.4036 - val_mae: 0.3990\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1861 - mae: 0.3269\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3748 - mae: 0.4060\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3291 - mae: 0.3989\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3107 - mae: 0.3957\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.2945 - mae: 0.3907\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.2892 - mae: 0.3917\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3228 - mae: 0.3985\n528/528 [==============================] - 0s 836us/step - loss: 0.3186 - mae: 0.3976 - val_loss: 0.4012 - val_mae: 0.3958\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0978 - mae: 0.2497\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2683 - mae: 0.3763\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3315 - mae: 0.3932\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3327 - mae: 0.3955\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3281 - mae: 0.3970\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3148 - mae: 0.3951\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3124 - mae: 0.3943\n528/528 [==============================] - 0s 833us/step - loss: 0.3184 - mae: 0.3950 - val_loss: 0.3986 - val_mae: 0.4043\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2546 - mae: 0.4046\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2459 - mae: 0.3776\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.2546 - mae: 0.3794\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.2970 - mae: 0.3952\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3183 - mae: 0.3966\n388/528 [=====================&gt;........] - ETA: 0s - loss: 0.3187 - mae: 0.3976\n468/528 [=========================&gt;....] - ETA: 0s - loss: 0.3243 - mae: 0.3975\n528/528 [==============================] - 0s 849us/step - loss: 0.3175 - mae: 0.3965 - val_loss: 0.4254 - val_mae: 0.4296\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2385 - mae: 0.4355\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3148 - mae: 0.4000\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3411 - mae: 0.4033\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3238 - mae: 0.3981\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3220 - mae: 0.3952\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3138 - mae: 0.3934\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3096 - mae: 0.3921\n528/528 [==============================] - 0s 849us/step - loss: 0.3158 - mae: 0.3939 - val_loss: 0.3986 - val_mae: 0.3956\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2958 - mae: 0.4267\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2895 - mae: 0.3944\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3522 - mae: 0.3986\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3502 - mae: 0.3962\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3271 - mae: 0.3917\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3295 - mae: 0.3958\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3185 - mae: 0.3924\n528/528 [==============================] - 0s 856us/step - loss: 0.3196 - mae: 0.3923 - val_loss: 0.3976 - val_mae: 0.3960\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3616 - mae: 0.4200\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2767 - mae: 0.3793\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3116 - mae: 0.3910\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.2919 - mae: 0.3871\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3104 - mae: 0.3912\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3229 - mae: 0.3942\n477/528 [==========================&gt;...] - ETA: 0s - loss: 0.3179 - mae: 0.3929\n528/528 [==============================] - 0s 828us/step - loss: 0.3188 - mae: 0.3943 - val_loss: 0.4041 - val_mae: 0.4007\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5737 - mae: 0.6081\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3154 - mae: 0.3965\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3243 - mae: 0.3972\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3250 - mae: 0.3941\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3133 - mae: 0.3924\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3211 - mae: 0.3962\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3271 - mae: 0.3975\n528/528 [==============================] - 0s 839us/step - loss: 0.3195 - mae: 0.3952 - val_loss: 0.4014 - val_mae: 0.4014\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2017 - mae: 0.3680\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2733 - mae: 0.3858\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3114 - mae: 0.3896\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.2910 - mae: 0.3857\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3083 - mae: 0.3876\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3005 - mae: 0.3888\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3102 - mae: 0.3929\n528/528 [==============================] - 0s 822us/step - loss: 0.3155 - mae: 0.3939 - val_loss: 0.4137 - val_mae: 0.4039\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0595 - mae: 0.1973\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2603 - mae: 0.3647\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.2796 - mae: 0.3770\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.2739 - mae: 0.3807\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3115 - mae: 0.3874\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3114 - mae: 0.3896\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3124 - mae: 0.3919\n528/528 [==============================] - 0s 850us/step - loss: 0.3173 - mae: 0.3929 - val_loss: 0.4322 - val_mae: 0.4162\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2653 - mae: 0.3812\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3699 - mae: 0.3938\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3285 - mae: 0.3911\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3187 - mae: 0.3950\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3235 - mae: 0.3972\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3117 - mae: 0.3932\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3086 - mae: 0.3917\n528/528 [==============================] - 0s 847us/step - loss: 0.3167 - mae: 0.3940 - val_loss: 0.4078 - val_mae: 0.4096\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2360 - mae: 0.3672\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3180 - mae: 0.3980\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3154 - mae: 0.3991\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3464 - mae: 0.4039\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3461 - mae: 0.4005\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3351 - mae: 0.3974\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3207 - mae: 0.3939\n528/528 [==============================] - 0s 823us/step - loss: 0.3152 - mae: 0.3924 - val_loss: 0.4201 - val_mae: 0.4058\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2998 - mae: 0.4773\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3733 - mae: 0.4026\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3327 - mae: 0.3894\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3201 - mae: 0.3906\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3213 - mae: 0.3943\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3215 - mae: 0.3915\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3170 - mae: 0.3925\n528/528 [==============================] - 0s 811us/step - loss: 0.3151 - mae: 0.3931 - val_loss: 0.3988 - val_mae: 0.3951\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3178 - mae: 0.4310\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2717 - mae: 0.3863\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3191 - mae: 0.3983\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3361 - mae: 0.3978\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3156 - mae: 0.3942\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3231 - mae: 0.3927\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3162 - mae: 0.3908\n528/528 [==============================] - 0s 814us/step - loss: 0.3144 - mae: 0.3909 - val_loss: 0.4249 - val_mae: 0.4040\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2626 - mae: 0.3598\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3050 - mae: 0.3888\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.2878 - mae: 0.3857\n211/528 [==========&gt;...................] - ETA: 0s - loss: 0.3220 - mae: 0.3932\n292/528 [===============&gt;..............] - ETA: 0s - loss: 0.3283 - mae: 0.3954\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3170 - mae: 0.3936\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3158 - mae: 0.3948\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3150 - mae: 0.3947\n528/528 [==============================] - 1s 1ms/step - loss: 0.3170 - mae: 0.3946 - val_loss: 0.3987 - val_mae: 0.4042\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3218 - mae: 0.4587\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.4364 - mae: 0.4320\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3480 - mae: 0.4071\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3230 - mae: 0.3976\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3353 - mae: 0.4012\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3215 - mae: 0.3949\n448/528 [========================&gt;.....] - ETA: 0s - loss: 0.3198 - mae: 0.3947\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3122 - mae: 0.3932\n528/528 [==============================] - 0s 871us/step - loss: 0.3122 - mae: 0.3932 - val_loss: 0.4172 - val_mae: 0.4082\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2897 - mae: 0.4234\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2580 - mae: 0.3753\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3166 - mae: 0.3900\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3373 - mae: 0.3997\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3364 - mae: 0.3995\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3230 - mae: 0.3951\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3170 - mae: 0.3931\n528/528 [==============================] - 0s 834us/step - loss: 0.3157 - mae: 0.3923 - val_loss: 0.3966 - val_mae: 0.3964\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2699 - mae: 0.4502\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3032 - mae: 0.3862\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.3157 - mae: 0.3877\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3514 - mae: 0.3936\n312/528 [================&gt;.............] - ETA: 0s - loss: 0.3263 - mae: 0.3894\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3226 - mae: 0.3921\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3211 - mae: 0.3931\n528/528 [==============================] - 0s 840us/step - loss: 0.3144 - mae: 0.3912 - val_loss: 0.4040 - val_mae: 0.4114\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3080 - mae: 0.4469\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2160 - mae: 0.3566\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.2667 - mae: 0.3790\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3020 - mae: 0.3864\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3224 - mae: 0.3892\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3244 - mae: 0.3923\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3201 - mae: 0.3910\n528/528 [==============================] - 0s 825us/step - loss: 0.3148 - mae: 0.3895 - val_loss: 0.3979 - val_mae: 0.3926\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1112 - mae: 0.2576\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.2554 - mae: 0.3735\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.2577 - mae: 0.3761\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.2665 - mae: 0.3784\n298/528 [===============&gt;..............] - ETA: 0s - loss: 0.2827 - mae: 0.3824\n351/528 [==================&gt;...........] - ETA: 0s - loss: 0.2870 - mae: 0.3843\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3122 - mae: 0.3903\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3132 - mae: 0.3915\n528/528 [==============================] - 0s 913us/step - loss: 0.3147 - mae: 0.3917 - val_loss: 0.4004 - val_mae: 0.3938\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1668 - mae: 0.3349\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2574 - mae: 0.3814\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2733 - mae: 0.3850\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.2689 - mae: 0.3785\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.2825 - mae: 0.3822\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.2872 - mae: 0.3834\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.2973 - mae: 0.3860\n528/528 [==============================] - 0s 851us/step - loss: 0.3149 - mae: 0.3908 - val_loss: 0.4068 - val_mae: 0.4053\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2333 - mae: 0.3851\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2986 - mae: 0.3865\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2895 - mae: 0.3829\n199/528 [==========&gt;...................] - ETA: 0s - loss: 0.2966 - mae: 0.3868\n258/528 [=============&gt;................] - ETA: 0s - loss: 0.3074 - mae: 0.3868\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3098 - mae: 0.3886\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3069 - mae: 0.3897\n491/528 [==========================&gt;...] - ETA: 0s - loss: 0.3160 - mae: 0.3901\n528/528 [==============================] - 0s 902us/step - loss: 0.3166 - mae: 0.3905 - val_loss: 0.3993 - val_mae: 0.3946\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2091 - mae: 0.3694\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3508 - mae: 0.3929\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3284 - mae: 0.3887\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3285 - mae: 0.3886\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3351 - mae: 0.3945\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3170 - mae: 0.3904\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3109 - mae: 0.3890\n528/528 [==============================] - 0s 803us/step - loss: 0.3145 - mae: 0.3899 - val_loss: 0.4003 - val_mae: 0.4040\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4131 - mae: 0.4735\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2802 - mae: 0.3832\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3258 - mae: 0.3941\n208/528 [==========&gt;...................] - ETA: 0s - loss: 0.3102 - mae: 0.3908\n281/528 [==============&gt;...............] - ETA: 0s - loss: 0.2990 - mae: 0.3859\n354/528 [===================&gt;..........] - ETA: 0s - loss: 0.2936 - mae: 0.3860\n429/528 [=======================&gt;......] - ETA: 0s - loss: 0.3018 - mae: 0.3878\n513/528 [============================&gt;.] - ETA: 0s - loss: 0.3175 - mae: 0.3896\n528/528 [==============================] - 0s 885us/step - loss: 0.3152 - mae: 0.3890 - val_loss: 0.4011 - val_mae: 0.3979\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1165 - mae: 0.2755\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2998 - mae: 0.3768\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3104 - mae: 0.3903\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3278 - mae: 0.3936\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3289 - mae: 0.3904\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3160 - mae: 0.3882\n455/528 [========================&gt;.....] - ETA: 0s - loss: 0.3179 - mae: 0.3905\n528/528 [==============================] - 0s 860us/step - loss: 0.3142 - mae: 0.3902 - val_loss: 0.4053 - val_mae: 0.3984\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1986 - mae: 0.3619\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3603 - mae: 0.3900\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3317 - mae: 0.3948\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3111 - mae: 0.3894\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3086 - mae: 0.3897\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3043 - mae: 0.3885\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3044 - mae: 0.3893\n528/528 [==============================] - 0s 835us/step - loss: 0.3151 - mae: 0.3897 - val_loss: 0.3989 - val_mae: 0.4055\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1791 - mae: 0.3442\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2616 - mae: 0.3705\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.2938 - mae: 0.3870\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.2772 - mae: 0.3841\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.2942 - mae: 0.3874\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3113 - mae: 0.3892\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3115 - mae: 0.3898\n528/528 [==============================] - 0s 803us/step - loss: 0.3107 - mae: 0.3896 - val_loss: 0.4237 - val_mae: 0.4136\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0928 - mae: 0.2547\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2876 - mae: 0.3832\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3472 - mae: 0.3970\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3305 - mae: 0.3917\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3209 - mae: 0.3888\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3051 - mae: 0.3865\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3148 - mae: 0.3882\n528/528 [==============================] - 0s 794us/step - loss: 0.3134 - mae: 0.3887 - val_loss: 0.3985 - val_mae: 0.4033\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1766 - mae: 0.3536\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2734 - mae: 0.3764\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3338 - mae: 0.3869\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3211 - mae: 0.3886\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3089 - mae: 0.3864\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3232 - mae: 0.3901\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3147 - mae: 0.3901\n528/528 [==============================] - 0s 803us/step - loss: 0.3117 - mae: 0.3894 - val_loss: 0.4233 - val_mae: 0.4308\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2796 - mae: 0.4265\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2797 - mae: 0.3928\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2765 - mae: 0.3856\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3060 - mae: 0.3882\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3016 - mae: 0.3903\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3103 - mae: 0.3916\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3167 - mae: 0.3916\n528/528 [==============================] - 0s 827us/step - loss: 0.3144 - mae: 0.3908 - val_loss: 0.4098 - val_mae: 0.4008\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1211 - mae: 0.2591\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3351 - mae: 0.3784\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3170 - mae: 0.3830\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3192 - mae: 0.3828\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3063 - mae: 0.3837\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3039 - mae: 0.3846\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3125 - mae: 0.3892\n528/528 [==============================] - 0s 788us/step - loss: 0.3131 - mae: 0.3895 - val_loss: 0.4066 - val_mae: 0.4024\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1371 - mae: 0.3075\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2699 - mae: 0.3777\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.2628 - mae: 0.3782\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.2867 - mae: 0.3810\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.2947 - mae: 0.3814\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.2959 - mae: 0.3834\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3116 - mae: 0.3880\n528/528 [==============================] - 0s 861us/step - loss: 0.3112 - mae: 0.3876 - val_loss: 0.4060 - val_mae: 0.4067\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1855 - mae: 0.3363\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.2732 - mae: 0.3830\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.3407 - mae: 0.3972\n214/528 [===========&gt;..................] - ETA: 0s - loss: 0.3465 - mae: 0.3983\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3340 - mae: 0.3901\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3229 - mae: 0.3896\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3210 - mae: 0.3905\n528/528 [==============================] - 0s 866us/step - loss: 0.3129 - mae: 0.3890 - val_loss: 0.4167 - val_mae: 0.3987\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2036 - mae: 0.3823\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3215 - mae: 0.3896\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3425 - mae: 0.3946\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.3273 - mae: 0.3950\n297/528 [===============&gt;..............] - ETA: 0s - loss: 0.3157 - mae: 0.3909\n363/528 [===================&gt;..........] - ETA: 0s - loss: 0.3119 - mae: 0.3926\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3082 - mae: 0.3917\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3132 - mae: 0.3896\n528/528 [==============================] - 0s 921us/step - loss: 0.3092 - mae: 0.3871 - val_loss: 0.3993 - val_mae: 0.3969\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2057 - mae: 0.3696\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.3518 - mae: 0.3802\n135/528 [======&gt;.......................] - ETA: 0s - loss: 0.3299 - mae: 0.3844\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3105 - mae: 0.3863\n287/528 [===============&gt;..............] - ETA: 0s - loss: 0.2932 - mae: 0.3818\n362/528 [===================&gt;..........] - ETA: 0s - loss: 0.3225 - mae: 0.3881\n441/528 [========================&gt;.....] - ETA: 0s - loss: 0.3201 - mae: 0.3913\n520/528 [============================&gt;.] - ETA: 0s - loss: 0.3124 - mae: 0.3891\n528/528 [==============================] - 0s 884us/step - loss: 0.3109 - mae: 0.3885 - val_loss: 0.4044 - val_mae: 0.3961\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.5250 - mae: 0.5946\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3055 - mae: 0.3839\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3167 - mae: 0.3916\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3431 - mae: 0.3961\n297/528 [===============&gt;..............] - ETA: 0s - loss: 0.3329 - mae: 0.3944\n357/528 [===================&gt;..........] - ETA: 0s - loss: 0.3368 - mae: 0.3927\n428/528 [=======================&gt;......] - ETA: 0s - loss: 0.3238 - mae: 0.3893\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3147 - mae: 0.3887\n528/528 [==============================] - 0s 893us/step - loss: 0.3130 - mae: 0.3887 - val_loss: 0.3964 - val_mae: 0.3984\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2081 - mae: 0.3681\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2779 - mae: 0.3821\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2872 - mae: 0.3820\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.2824 - mae: 0.3838\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3042 - mae: 0.3885\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3184 - mae: 0.3919\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3059 - mae: 0.3862\n528/528 [==============================] - 0s 810us/step - loss: 0.3080 - mae: 0.3873 - val_loss: 0.4007 - val_mae: 0.4011\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6744 - mae: 0.5099\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2861 - mae: 0.3722\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.2723 - mae: 0.3748\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.2660 - mae: 0.3790\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.2884 - mae: 0.3876\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.2972 - mae: 0.3881\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3032 - mae: 0.3870\n528/528 [==============================] - 0s 811us/step - loss: 0.3127 - mae: 0.3881 - val_loss: 0.4138 - val_mae: 0.4007\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2625 - mae: 0.4152\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3245 - mae: 0.3796\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3235 - mae: 0.3927\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3554 - mae: 0.3986\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3308 - mae: 0.3958\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3069 - mae: 0.3862\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3074 - mae: 0.3865\n528/528 [==============================] - 0s 810us/step - loss: 0.3106 - mae: 0.3879 - val_loss: 0.4054 - val_mae: 0.4123\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1164 - mae: 0.2980\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.2525 - mae: 0.3753\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3234 - mae: 0.3882\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3050 - mae: 0.3870\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3015 - mae: 0.3850\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3008 - mae: 0.3848\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3095 - mae: 0.3863\n528/528 [==============================] - 0s 820us/step - loss: 0.3103 - mae: 0.3872 - val_loss: 0.3954 - val_mae: 0.3947\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3024 - mae: 0.4215\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3597 - mae: 0.4010\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3609 - mae: 0.3972\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3341 - mae: 0.3894\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3304 - mae: 0.3909\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3223 - mae: 0.3888\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3137 - mae: 0.3854\n528/528 [==============================] - 0s 833us/step - loss: 0.3084 - mae: 0.3851 - val_loss: 0.4162 - val_mae: 0.3981\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2496 - mae: 0.4287\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2516 - mae: 0.3716\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3152 - mae: 0.3829\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3080 - mae: 0.3834\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3000 - mae: 0.3814\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3098 - mae: 0.3837\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3136 - mae: 0.3878\n528/528 [==============================] - 0s 830us/step - loss: 0.3083 - mae: 0.3867 - val_loss: 0.4006 - val_mae: 0.3941\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1437 - mae: 0.2953\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2872 - mae: 0.3904\n133/528 [======&gt;.......................] - ETA: 0s - loss: 0.2724 - mae: 0.3832\n197/528 [==========&gt;...................] - ETA: 0s - loss: 0.2999 - mae: 0.3860\n280/528 [==============&gt;...............] - ETA: 0s - loss: 0.3244 - mae: 0.3909\n363/528 [===================&gt;..........] - ETA: 0s - loss: 0.3165 - mae: 0.3867\n434/528 [=======================&gt;......] - ETA: 0s - loss: 0.3167 - mae: 0.3872\n517/528 [============================&gt;.] - ETA: 0s - loss: 0.3089 - mae: 0.3852\n528/528 [==============================] - 0s 874us/step - loss: 0.3107 - mae: 0.3859 - val_loss: 0.4056 - val_mae: 0.4068\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1825 - mae: 0.3409\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3038 - mae: 0.3922\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.2855 - mae: 0.3810\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.2855 - mae: 0.3851\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3010 - mae: 0.3854\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.2941 - mae: 0.3854\n440/528 [========================&gt;.....] - ETA: 0s - loss: 0.3147 - mae: 0.3884\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3149 - mae: 0.3896\n528/528 [==============================] - 0s 929us/step - loss: 0.3090 - mae: 0.3871 - val_loss: 0.3932 - val_mae: 0.3952\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7665 - mae: 0.4762\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3648 - mae: 0.3973\n155/528 [=======&gt;......................] - ETA: 0s - loss: 0.3370 - mae: 0.3884\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3069 - mae: 0.3818\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.2961 - mae: 0.3830\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.2906 - mae: 0.3806\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3034 - mae: 0.3846\n528/528 [==============================] - 0s 843us/step - loss: 0.3086 - mae: 0.3858 - val_loss: 0.4024 - val_mae: 0.3937\nProcessing fold # 2 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 124.0880 - mae: 11.1310\n 62/528 [==&gt;...........................] - ETA: 0s - loss: 63.0647 - mae: 7.3305  \n133/528 [======&gt;.......................] - ETA: 0s - loss: 32.5152 - mae: 4.4109\n216/528 [===========&gt;..................] - ETA: 0s - loss: 20.6762 - mae: 3.0720\n298/528 [===============&gt;..............] - ETA: 0s - loss: 15.3299 - mae: 2.4215\n375/528 [====================&gt;.........] - ETA: 0s - loss: 12.3294 - mae: 2.0444\n458/528 [=========================&gt;....] - ETA: 0s - loss: 10.2004 - mae: 1.7675\n528/528 [==============================] - 1s 1ms/step - loss: 8.9044 - mae: 1.5958 - val_loss: 0.3670 - val_mae: 0.4255\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2434 - mae: 0.3852\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3851 - mae: 0.4551\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3925 - mae: 0.4471\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.4190 - mae: 0.4468\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.4209 - mae: 0.4465\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.4261 - mae: 0.4469\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.4168 - mae: 0.4431\n528/528 [==============================] - 0s 818us/step - loss: 0.4144 - mae: 0.4430 - val_loss: 0.3352 - val_mae: 0.4217\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1696 - mae: 0.3253\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4240 - mae: 0.4473\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.4111 - mae: 0.4386\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.4141 - mae: 0.4391\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.4049 - mae: 0.4358\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3953 - mae: 0.4338\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3812 - mae: 0.4306\n528/528 [==============================] - 0s 810us/step - loss: 0.3898 - mae: 0.4304 - val_loss: 0.4232 - val_mae: 0.5128\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5181 - mae: 0.5990\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4469 - mae: 0.4510\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4345 - mae: 0.4420\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3916 - mae: 0.4383\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3673 - mae: 0.4294\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3759 - mae: 0.4286\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3878 - mae: 0.4302\n528/528 [==============================] - 0s 821us/step - loss: 0.3885 - mae: 0.4306 - val_loss: 0.3121 - val_mae: 0.3991\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1355 - mae: 0.3093\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3457 - mae: 0.4125\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3940 - mae: 0.4157\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.4155 - mae: 0.4205\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3840 - mae: 0.4195\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3836 - mae: 0.4215\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3768 - mae: 0.4229\n528/528 [==============================] - 0s 808us/step - loss: 0.3822 - mae: 0.4236 - val_loss: 0.3416 - val_mae: 0.4394\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2803 - mae: 0.4036\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2986 - mae: 0.4199\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3293 - mae: 0.4176\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3607 - mae: 0.4207\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3521 - mae: 0.4203\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3579 - mae: 0.4204\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3819 - mae: 0.4229\n528/528 [==============================] - 0s 803us/step - loss: 0.3780 - mae: 0.4222 - val_loss: 0.3734 - val_mae: 0.4545\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6580 - mae: 0.5588\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3411 - mae: 0.4144\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3915 - mae: 0.4119\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3848 - mae: 0.4147\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3721 - mae: 0.4148\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3634 - mae: 0.4129\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3802 - mae: 0.4171\n528/528 [==============================] - 0s 802us/step - loss: 0.3753 - mae: 0.4170 - val_loss: 0.3057 - val_mae: 0.3990\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1807 - mae: 0.3745\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4357 - mae: 0.4274\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4495 - mae: 0.4272\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.4193 - mae: 0.4223\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3948 - mae: 0.4208\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3745 - mae: 0.4203\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3854 - mae: 0.4214\n528/528 [==============================] - 1s 1ms/step - loss: 0.3759 - mae: 0.4193 - val_loss: 0.3020 - val_mae: 0.3958\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0781 - mae: 0.2085\n 57/528 [==&gt;...........................] - ETA: 0s - loss: 0.4192 - mae: 0.4275\n112/528 [=====&gt;........................] - ETA: 0s - loss: 0.3843 - mae: 0.4182\n174/528 [========&gt;.....................] - ETA: 0s - loss: 0.3593 - mae: 0.4166\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.4057 - mae: 0.4245\n271/528 [==============&gt;...............] - ETA: 0s - loss: 0.3878 - mae: 0.4216\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3819 - mae: 0.4218\n355/528 [===================&gt;..........] - ETA: 0s - loss: 0.3775 - mae: 0.4217\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3922 - mae: 0.4219\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3836 - mae: 0.4197\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3732 - mae: 0.4174\n528/528 [==============================] - 1s 1ms/step - loss: 0.3752 - mae: 0.4188 - val_loss: 0.2976 - val_mae: 0.3860\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1816 - mae: 0.3535\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3148 - mae: 0.4129\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3413 - mae: 0.4124\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3581 - mae: 0.4151\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3414 - mae: 0.4123\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3506 - mae: 0.4149\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3564 - mae: 0.4149\n528/528 [==============================] - 0s 839us/step - loss: 0.3741 - mae: 0.4168 - val_loss: 0.3063 - val_mae: 0.3987\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7589 - mae: 0.5189\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3431 - mae: 0.4130\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3753 - mae: 0.4100\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3452 - mae: 0.4060\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3671 - mae: 0.4111\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3607 - mae: 0.4131\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3770 - mae: 0.4181\n528/528 [==============================] - 0s 839us/step - loss: 0.3698 - mae: 0.4170 - val_loss: 0.3097 - val_mae: 0.4078\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3575 - mae: 0.4582\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2922 - mae: 0.3960\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3593 - mae: 0.4047\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3769 - mae: 0.4078\n301/528 [================&gt;.............] - ETA: 0s - loss: 0.3630 - mae: 0.4080\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3553 - mae: 0.4089\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3649 - mae: 0.4130\n528/528 [==============================] - 0s 862us/step - loss: 0.3719 - mae: 0.4164 - val_loss: 0.3858 - val_mae: 0.4518\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3870 - mae: 0.4293\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4802 - mae: 0.4526\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.4268 - mae: 0.4338\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.4148 - mae: 0.4299\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.4027 - mae: 0.4223\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3968 - mae: 0.4227\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3786 - mae: 0.4190\n528/528 [==============================] - 0s 843us/step - loss: 0.3703 - mae: 0.4167 - val_loss: 0.3646 - val_mae: 0.4353\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2134 - mae: 0.3800\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3424 - mae: 0.4103\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3127 - mae: 0.4066\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3578 - mae: 0.4084\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3599 - mae: 0.4111\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3618 - mae: 0.4091\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3517 - mae: 0.4081\n528/528 [==============================] - 0s 910us/step - loss: 0.3698 - mae: 0.4127 - val_loss: 0.2924 - val_mae: 0.3877\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.1555 - mae: 0.6412\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3044 - mae: 0.4067\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3662 - mae: 0.4106\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3546 - mae: 0.4063\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3998 - mae: 0.4150\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3812 - mae: 0.4137\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3767 - mae: 0.4137\n521/528 [============================&gt;.] - ETA: 0s - loss: 0.3722 - mae: 0.4150\n528/528 [==============================] - 0s 922us/step - loss: 0.3707 - mae: 0.4146 - val_loss: 0.2990 - val_mae: 0.3963\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4206 - mae: 0.5312\n 64/528 [==&gt;...........................] - ETA: 0s - loss: 0.3730 - mae: 0.4079\n130/528 [======&gt;.......................] - ETA: 0s - loss: 0.3774 - mae: 0.4088\n191/528 [=========&gt;....................] - ETA: 0s - loss: 0.3425 - mae: 0.4048\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3355 - mae: 0.4059\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3788 - mae: 0.4113\n346/528 [==================&gt;...........] - ETA: 0s - loss: 0.3621 - mae: 0.4068\n395/528 [=====================&gt;........] - ETA: 0s - loss: 0.3538 - mae: 0.4069\n440/528 [========================&gt;.....] - ETA: 0s - loss: 0.3522 - mae: 0.4070\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3659 - mae: 0.4112\n528/528 [==============================] - 1s 1ms/step - loss: 0.3693 - mae: 0.4123 - val_loss: 0.2953 - val_mae: 0.3903\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1646 - mae: 0.3298\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3249 - mae: 0.4060\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.3141 - mae: 0.4049\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3054 - mae: 0.4044\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3457 - mae: 0.4111\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3566 - mae: 0.4126\n444/528 [========================&gt;.....] - ETA: 0s - loss: 0.3444 - mae: 0.4099\n518/528 [============================&gt;.] - ETA: 0s - loss: 0.3583 - mae: 0.4110\n528/528 [==============================] - 0s 924us/step - loss: 0.3668 - mae: 0.4117 - val_loss: 0.3017 - val_mae: 0.3897\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2175 - mae: 0.3614\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.3067 - mae: 0.3897\n132/528 [======&gt;.......................] - ETA: 0s - loss: 0.2845 - mae: 0.3902\n201/528 [==========&gt;...................] - ETA: 0s - loss: 0.2989 - mae: 0.3913\n259/528 [=============&gt;................] - ETA: 0s - loss: 0.3220 - mae: 0.4001\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3534 - mae: 0.4074\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3487 - mae: 0.4088\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3712 - mae: 0.4120\n528/528 [==============================] - 1s 966us/step - loss: 0.3640 - mae: 0.4108 - val_loss: 0.3058 - val_mae: 0.3936\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1775 - mae: 0.3448\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.4485 - mae: 0.4143\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3965 - mae: 0.4208\n218/528 [===========&gt;..................] - ETA: 0s - loss: 0.3927 - mae: 0.4186\n292/528 [===============&gt;..............] - ETA: 0s - loss: 0.3818 - mae: 0.4178\n365/528 [===================&gt;..........] - ETA: 0s - loss: 0.3631 - mae: 0.4155\n442/528 [========================&gt;.....] - ETA: 0s - loss: 0.3780 - mae: 0.4163\n518/528 [============================&gt;.] - ETA: 0s - loss: 0.3692 - mae: 0.4126\n528/528 [==============================] - 0s 900us/step - loss: 0.3680 - mae: 0.4126 - val_loss: 0.3220 - val_mae: 0.4014\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2260 - mae: 0.3688\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3482 - mae: 0.4072\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3211 - mae: 0.4049\n226/528 [===========&gt;..................] - ETA: 0s - loss: 0.3196 - mae: 0.4055\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3361 - mae: 0.4043\n369/528 [===================&gt;..........] - ETA: 0s - loss: 0.3622 - mae: 0.4066\n438/528 [=======================&gt;......] - ETA: 0s - loss: 0.3659 - mae: 0.4099\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3646 - mae: 0.4091\n528/528 [==============================] - 0s 910us/step - loss: 0.3659 - mae: 0.4101 - val_loss: 0.2936 - val_mae: 0.3913\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1769 - mae: 0.3415\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3056 - mae: 0.3823\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.3471 - mae: 0.4030\n220/528 [===========&gt;..................] - ETA: 0s - loss: 0.3335 - mae: 0.4017\n299/528 [===============&gt;..............] - ETA: 0s - loss: 0.3402 - mae: 0.4033\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3831 - mae: 0.4111\n464/528 [=========================&gt;....] - ETA: 0s - loss: 0.3744 - mae: 0.4091\n528/528 [==============================] - 0s 852us/step - loss: 0.3639 - mae: 0.4086 - val_loss: 0.2987 - val_mae: 0.3954\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3964 - mae: 0.5173\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2871 - mae: 0.3992\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3664 - mae: 0.4128\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3587 - mae: 0.4089\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3491 - mae: 0.4095\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3565 - mae: 0.4074\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3666 - mae: 0.4096\n528/528 [==============================] - 0s 796us/step - loss: 0.3653 - mae: 0.4097 - val_loss: 0.3177 - val_mae: 0.4155\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2206 - mae: 0.3716\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4705 - mae: 0.4238\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.4250 - mae: 0.4262\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.4047 - mae: 0.4201\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3902 - mae: 0.4147\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3839 - mae: 0.4126\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3684 - mae: 0.4101\n528/528 [==============================] - 0s 828us/step - loss: 0.3651 - mae: 0.4100 - val_loss: 0.2908 - val_mae: 0.3838\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2860 - mae: 0.3545\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4294 - mae: 0.4107\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3586 - mae: 0.4039\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3354 - mae: 0.3999\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3426 - mae: 0.4035\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3461 - mae: 0.4040\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3590 - mae: 0.4070\n528/528 [==============================] - 0s 804us/step - loss: 0.3646 - mae: 0.4083 - val_loss: 0.3134 - val_mae: 0.4077\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1893 - mae: 0.3416\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3607 - mae: 0.4049\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3915 - mae: 0.4064\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3548 - mae: 0.4023\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3748 - mae: 0.4095\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3583 - mae: 0.4057\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3656 - mae: 0.4065\n528/528 [==============================] - 0s 805us/step - loss: 0.3642 - mae: 0.4075 - val_loss: 0.3039 - val_mae: 0.3955\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0834 - mae: 0.2375\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2768 - mae: 0.3896\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4354 - mae: 0.4104\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.4081 - mae: 0.4170\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3928 - mae: 0.4146\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3677 - mae: 0.4087\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3699 - mae: 0.4097\n528/528 [==============================] - 0s 813us/step - loss: 0.3646 - mae: 0.4088 - val_loss: 0.3486 - val_mae: 0.4197\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1836 - mae: 0.3352\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2771 - mae: 0.3904\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3391 - mae: 0.4044\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3640 - mae: 0.4090\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3446 - mae: 0.4061\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3753 - mae: 0.4072\n491/528 [==========================&gt;...] - ETA: 0s - loss: 0.3586 - mae: 0.4031\n528/528 [==============================] - 0s 820us/step - loss: 0.3635 - mae: 0.4067 - val_loss: 0.3485 - val_mae: 0.4469\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3693 - mae: 0.5052\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3322 - mae: 0.4080\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4386 - mae: 0.4256\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.4360 - mae: 0.4238\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3905 - mae: 0.4124\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3802 - mae: 0.4112\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3678 - mae: 0.4101\n528/528 [==============================] - 0s 826us/step - loss: 0.3610 - mae: 0.4076 - val_loss: 0.2908 - val_mae: 0.3809\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1439 - mae: 0.2963\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2913 - mae: 0.4087\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2937 - mae: 0.3986\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3400 - mae: 0.4068\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3658 - mae: 0.4081\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3586 - mae: 0.4062\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3600 - mae: 0.4060\n528/528 [==============================] - 0s 806us/step - loss: 0.3612 - mae: 0.4070 - val_loss: 0.2995 - val_mae: 0.3878\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1885 - mae: 0.3630\n 60/528 [==&gt;...........................] - ETA: 0s - loss: 0.3916 - mae: 0.4123\n134/528 [======&gt;.......................] - ETA: 0s - loss: 0.3691 - mae: 0.4027\n212/528 [===========&gt;..................] - ETA: 0s - loss: 0.3439 - mae: 0.4003\n287/528 [===============&gt;..............] - ETA: 0s - loss: 0.3387 - mae: 0.4026\n363/528 [===================&gt;..........] - ETA: 0s - loss: 0.3473 - mae: 0.4049\n438/528 [=======================&gt;......] - ETA: 0s - loss: 0.3456 - mae: 0.4066\n513/528 [============================&gt;.] - ETA: 0s - loss: 0.3630 - mae: 0.4068\n528/528 [==============================] - 0s 896us/step - loss: 0.3593 - mae: 0.4057 - val_loss: 0.3042 - val_mae: 0.3904\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1359 - mae: 0.3158\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3528 - mae: 0.4050\n147/528 [=======&gt;......................] - ETA: 0s - loss: 0.3700 - mae: 0.3996\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3590 - mae: 0.4017\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3621 - mae: 0.4042\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3611 - mae: 0.4035\n438/528 [=======================&gt;......] - ETA: 0s - loss: 0.3552 - mae: 0.4035\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3616 - mae: 0.4044\n528/528 [==============================] - 0s 887us/step - loss: 0.3615 - mae: 0.4056 - val_loss: 0.3180 - val_mae: 0.4042\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5715 - mae: 0.6025\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2926 - mae: 0.4002\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3114 - mae: 0.3957\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3174 - mae: 0.3969\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3529 - mae: 0.4026\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3546 - mae: 0.4036\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3711 - mae: 0.4057\n528/528 [==============================] - 0s 835us/step - loss: 0.3611 - mae: 0.4062 - val_loss: 0.2925 - val_mae: 0.3901\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1912 - mae: 0.3878\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3247 - mae: 0.4059\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.2888 - mae: 0.3933\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3258 - mae: 0.4041\n291/528 [===============&gt;..............] - ETA: 0s - loss: 0.3628 - mae: 0.4104\n358/528 [===================&gt;..........] - ETA: 0s - loss: 0.3501 - mae: 0.4097\n431/528 [=======================&gt;......] - ETA: 0s - loss: 0.3475 - mae: 0.4070\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3528 - mae: 0.4071\n528/528 [==============================] - 0s 916us/step - loss: 0.3634 - mae: 0.4076 - val_loss: 0.2974 - val_mae: 0.3894\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4110 - mae: 0.4953\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.3048 - mae: 0.4017\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2759 - mae: 0.3924\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3313 - mae: 0.4067\n293/528 [===============&gt;..............] - ETA: 0s - loss: 0.3385 - mae: 0.4060\n378/528 [====================&gt;.........] - ETA: 0s - loss: 0.3349 - mae: 0.4015\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3441 - mae: 0.4022\n528/528 [==============================] - 0s 852us/step - loss: 0.3558 - mae: 0.4051 - val_loss: 0.3068 - val_mae: 0.3994\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5015 - mae: 0.6020\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4130 - mae: 0.4045\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.4070 - mae: 0.4108\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.4137 - mae: 0.4101\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.4074 - mae: 0.4143\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3851 - mae: 0.4105\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3691 - mae: 0.4081\n528/528 [==============================] - 0s 816us/step - loss: 0.3590 - mae: 0.4056 - val_loss: 0.3126 - val_mae: 0.4111\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1447 - mae: 0.2804\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3696 - mae: 0.4056\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3505 - mae: 0.4099\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3394 - mae: 0.4036\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3405 - mae: 0.4034\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3777 - mae: 0.4081\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3704 - mae: 0.4075\n528/528 [==============================] - 0s 808us/step - loss: 0.3632 - mae: 0.4061 - val_loss: 0.3135 - val_mae: 0.3918\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5456 - mae: 0.4207\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4099 - mae: 0.4108\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.4531 - mae: 0.4185\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.4070 - mae: 0.4133\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3761 - mae: 0.4082\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3880 - mae: 0.4115\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3713 - mae: 0.4101\n528/528 [==============================] - 0s 822us/step - loss: 0.3614 - mae: 0.4073 - val_loss: 0.2995 - val_mae: 0.3890\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1535 - mae: 0.3023\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3268 - mae: 0.3962\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3782 - mae: 0.4066\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3729 - mae: 0.4096\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3910 - mae: 0.4140\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3891 - mae: 0.4145\n472/528 [=========================&gt;....] - ETA: 0s - loss: 0.3711 - mae: 0.4103\n528/528 [==============================] - 0s 852us/step - loss: 0.3611 - mae: 0.4073 - val_loss: 0.3010 - val_mae: 0.3910\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1894 - mae: 0.3696\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.3228 - mae: 0.3814\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3478 - mae: 0.3989\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3594 - mae: 0.4075\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3629 - mae: 0.4093\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3509 - mae: 0.4085\n465/528 [=========================&gt;....] - ETA: 0s - loss: 0.3620 - mae: 0.4063\n528/528 [==============================] - 0s 833us/step - loss: 0.3593 - mae: 0.4060 - val_loss: 0.3482 - val_mae: 0.4239\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1547 - mae: 0.3345\n 73/528 [===&gt;..........................] - ETA: 0s - loss: 0.2927 - mae: 0.4053\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3284 - mae: 0.4092\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3163 - mae: 0.4052\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3271 - mae: 0.3982\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3607 - mae: 0.4041\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3653 - mae: 0.4051\n528/528 [==============================] - 0s 814us/step - loss: 0.3589 - mae: 0.4037 - val_loss: 0.3151 - val_mae: 0.4103\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2341 - mae: 0.4056\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3658 - mae: 0.4048\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3551 - mae: 0.3982\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3605 - mae: 0.4005\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3732 - mae: 0.4064\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3575 - mae: 0.4059\n459/528 [=========================&gt;....] - ETA: 0s - loss: 0.3739 - mae: 0.4088\n528/528 [==============================] - 0s 857us/step - loss: 0.3626 - mae: 0.4063 - val_loss: 0.3315 - val_mae: 0.4289\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3320 - mae: 0.3031\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.2916 - mae: 0.3967\n148/528 [=======&gt;......................] - ETA: 0s - loss: 0.3475 - mae: 0.3936\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3506 - mae: 0.3968\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3550 - mae: 0.4024\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3446 - mae: 0.4024\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3663 - mae: 0.4066\n528/528 [==============================] - 0s 868us/step - loss: 0.3624 - mae: 0.4065 - val_loss: 0.3053 - val_mae: 0.3901\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1461 - mae: 0.3088\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3648 - mae: 0.4074\n148/528 [=======&gt;......................] - ETA: 0s - loss: 0.3425 - mae: 0.4021\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3240 - mae: 0.3987\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3462 - mae: 0.4039\n367/528 [===================&gt;..........] - ETA: 0s - loss: 0.3323 - mae: 0.4034\n447/528 [========================&gt;.....] - ETA: 0s - loss: 0.3554 - mae: 0.4034\n524/528 [============================&gt;.] - ETA: 0s - loss: 0.3597 - mae: 0.4045\n528/528 [==============================] - 0s 868us/step - loss: 0.3590 - mae: 0.4046 - val_loss: 0.3256 - val_mae: 0.4026\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1623 - mae: 0.3379\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2931 - mae: 0.4026\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2964 - mae: 0.4069\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3267 - mae: 0.4067\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3578 - mae: 0.4088\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3549 - mae: 0.4053\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3652 - mae: 0.4066\n528/528 [==============================] - 0s 809us/step - loss: 0.3607 - mae: 0.4054 - val_loss: 0.3043 - val_mae: 0.3991\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1638 - mae: 0.2623\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4340 - mae: 0.4121\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3944 - mae: 0.4097\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3937 - mae: 0.4078\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.4064 - mae: 0.4125\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3817 - mae: 0.4086\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3647 - mae: 0.4064\n528/528 [==============================] - 0s 838us/step - loss: 0.3588 - mae: 0.4057 - val_loss: 0.3146 - val_mae: 0.4069\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2020 - mae: 0.3191\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2567 - mae: 0.3898\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3448 - mae: 0.4029\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3462 - mae: 0.4015\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3443 - mae: 0.4026\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3411 - mae: 0.4036\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3599 - mae: 0.4052\n528/528 [==============================] - 0s 859us/step - loss: 0.3596 - mae: 0.4033 - val_loss: 0.3002 - val_mae: 0.3879\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3029 - mae: 0.4252\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2734 - mae: 0.3850\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.2666 - mae: 0.3871\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3538 - mae: 0.4025\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3734 - mae: 0.4056\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3659 - mae: 0.4050\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3678 - mae: 0.4035\n528/528 [==============================] - 0s 834us/step - loss: 0.3584 - mae: 0.4036 - val_loss: 0.3273 - val_mae: 0.4025\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3013 - mae: 0.4179\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.5405 - mae: 0.4210\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.4066 - mae: 0.4079\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3688 - mae: 0.4034\n308/528 [================&gt;.............] - ETA: 0s - loss: 0.3771 - mae: 0.4086\n385/528 [====================&gt;.........] - ETA: 0s - loss: 0.3516 - mae: 0.4024\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3522 - mae: 0.4010\n528/528 [==============================] - 0s 874us/step - loss: 0.3563 - mae: 0.4034 - val_loss: 0.2994 - val_mae: 0.3925\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3079 - mae: 0.3788\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2772 - mae: 0.4005\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3157 - mae: 0.4019\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.4061 - mae: 0.4128\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3905 - mae: 0.4125\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3730 - mae: 0.4092\n452/528 [========================&gt;.....] - ETA: 0s - loss: 0.3630 - mae: 0.4060\n528/528 [==============================] - 0s 863us/step - loss: 0.3566 - mae: 0.4053 - val_loss: 0.3191 - val_mae: 0.3993\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2151 - mae: 0.3802\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3023 - mae: 0.4126\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3261 - mae: 0.4015\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3778 - mae: 0.4087\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3692 - mae: 0.4072\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3575 - mae: 0.4059\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3570 - mae: 0.4050\n528/528 [==============================] - 0s 814us/step - loss: 0.3581 - mae: 0.4045 - val_loss: 0.3621 - val_mae: 0.4342\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1863 - mae: 0.3807\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3456 - mae: 0.3924\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3306 - mae: 0.3993\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3636 - mae: 0.4058\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.3597 - mae: 0.4039\n396/528 [=====================&gt;........] - ETA: 0s - loss: 0.3674 - mae: 0.4056\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3615 - mae: 0.4037\n528/528 [==============================] - 0s 833us/step - loss: 0.3577 - mae: 0.4048 - val_loss: 0.3109 - val_mae: 0.3900\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1588 - mae: 0.2811\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3015 - mae: 0.3948\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3886 - mae: 0.4091\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3639 - mae: 0.4061\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3820 - mae: 0.4060\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3596 - mae: 0.4024\n488/528 [==========================&gt;...] - ETA: 0s - loss: 0.3497 - mae: 0.4011\n528/528 [==============================] - 0s 818us/step - loss: 0.3573 - mae: 0.4027 - val_loss: 0.3008 - val_mae: 0.3879\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3067 - mae: 0.3836\n 62/528 [==&gt;...........................] - ETA: 0s - loss: 0.3313 - mae: 0.3695\n139/528 [======&gt;.......................] - ETA: 0s - loss: 0.3926 - mae: 0.3957\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3575 - mae: 0.3960\n294/528 [===============&gt;..............] - ETA: 0s - loss: 0.3539 - mae: 0.3975\n371/528 [====================&gt;.........] - ETA: 0s - loss: 0.3493 - mae: 0.3981\n450/528 [========================&gt;.....] - ETA: 0s - loss: 0.3436 - mae: 0.3987\n526/528 [============================&gt;.] - ETA: 0s - loss: 0.3569 - mae: 0.4028\n528/528 [==============================] - 0s 868us/step - loss: 0.3565 - mae: 0.4028 - val_loss: 0.3530 - val_mae: 0.4235\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3949 - mae: 0.4231\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3141 - mae: 0.4043\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2948 - mae: 0.3939\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3914 - mae: 0.4102\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3837 - mae: 0.4066\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3744 - mae: 0.4065\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3677 - mae: 0.4031\n528/528 [==============================] - 0s 830us/step - loss: 0.3595 - mae: 0.4017 - val_loss: 0.3094 - val_mae: 0.3916\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1776 - mae: 0.3247\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3265 - mae: 0.3981\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3265 - mae: 0.4002\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3258 - mae: 0.4007\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3189 - mae: 0.3992\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3356 - mae: 0.4014\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3658 - mae: 0.4047\n528/528 [==============================] - 0s 821us/step - loss: 0.3572 - mae: 0.4030 - val_loss: 0.3286 - val_mae: 0.4282\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3503 - mae: 0.4911\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3268 - mae: 0.3882\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3017 - mae: 0.3857\n220/528 [===========&gt;..................] - ETA: 0s - loss: 0.3543 - mae: 0.3990\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3452 - mae: 0.3978\n377/528 [====================&gt;.........] - ETA: 0s - loss: 0.3333 - mae: 0.3974\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3385 - mae: 0.3983\n528/528 [==============================] - 0s 859us/step - loss: 0.3556 - mae: 0.4022 - val_loss: 0.3082 - val_mae: 0.3925\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2977 - mae: 0.4133\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.5090 - mae: 0.4243\n122/528 [=====&gt;........................] - ETA: 0s - loss: 0.4092 - mae: 0.4093\n195/528 [==========&gt;...................] - ETA: 0s - loss: 0.3781 - mae: 0.4016\n274/528 [==============&gt;...............] - ETA: 0s - loss: 0.3533 - mae: 0.4010\n352/528 [===================&gt;..........] - ETA: 0s - loss: 0.3479 - mae: 0.3977\n430/528 [=======================&gt;......] - ETA: 0s - loss: 0.3428 - mae: 0.3980\n514/528 [============================&gt;.] - ETA: 0s - loss: 0.3483 - mae: 0.3997\n528/528 [==============================] - 0s 908us/step - loss: 0.3551 - mae: 0.4011 - val_loss: 0.3067 - val_mae: 0.3981\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4143 - mae: 0.4869\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3578 - mae: 0.4034\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3388 - mae: 0.3979\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3745 - mae: 0.4024\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3657 - mae: 0.3978\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3547 - mae: 0.3995\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3603 - mae: 0.4014\n528/528 [==============================] - 0s 804us/step - loss: 0.3585 - mae: 0.4013 - val_loss: 0.3094 - val_mae: 0.4071\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2570 - mae: 0.4377\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3653 - mae: 0.3969\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3583 - mae: 0.3985\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3493 - mae: 0.3958\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3316 - mae: 0.3931\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3506 - mae: 0.3973\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3550 - mae: 0.3976\n528/528 [==============================] - 0s 807us/step - loss: 0.3551 - mae: 0.3992 - val_loss: 0.3553 - val_mae: 0.4488\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2905 - mae: 0.4046\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4401 - mae: 0.4149\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3813 - mae: 0.4036\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3666 - mae: 0.4003\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3561 - mae: 0.4006\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3711 - mae: 0.4035\n484/528 [==========================&gt;...] - ETA: 0s - loss: 0.3610 - mae: 0.4011\n528/528 [==============================] - 0s 817us/step - loss: 0.3534 - mae: 0.3993 - val_loss: 0.3111 - val_mae: 0.4053\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1505 - mae: 0.3321\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3079 - mae: 0.3773\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3543 - mae: 0.3955\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3649 - mae: 0.3960\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3977 - mae: 0.4040\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3725 - mae: 0.4007\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3572 - mae: 0.3992\n528/528 [==============================] - 0s 811us/step - loss: 0.3551 - mae: 0.3997 - val_loss: 0.2996 - val_mae: 0.3947\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3509 - mae: 0.4801\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3605 - mae: 0.4043\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4394 - mae: 0.4157\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.4017 - mae: 0.4076\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3673 - mae: 0.4036\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3472 - mae: 0.3985\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3545 - mae: 0.3994\n528/528 [==============================] - 0s 824us/step - loss: 0.3552 - mae: 0.4009 - val_loss: 0.3061 - val_mae: 0.3980\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1767 - mae: 0.3248\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4060 - mae: 0.4096\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3717 - mae: 0.4002\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3659 - mae: 0.4032\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3515 - mae: 0.4026\n400/528 [=====================&gt;........] - ETA: 0s - loss: 0.3381 - mae: 0.4012\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3435 - mae: 0.4041\n528/528 [==============================] - 0s 828us/step - loss: 0.3560 - mae: 0.4030 - val_loss: 0.4349 - val_mae: 0.5130\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7090 - mae: 0.6318\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.5312 - mae: 0.4305\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.4236 - mae: 0.4175\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.4166 - mae: 0.4113\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3876 - mae: 0.4076\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3606 - mae: 0.4013\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3527 - mae: 0.3998\n528/528 [==============================] - 0s 840us/step - loss: 0.3508 - mae: 0.4006 - val_loss: 0.3079 - val_mae: 0.3979\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2102 - mae: 0.3721\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4994 - mae: 0.4205\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4423 - mae: 0.4148\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3879 - mae: 0.4024\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3549 - mae: 0.3976\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3649 - mae: 0.3985\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3519 - mae: 0.3975\n528/528 [==============================] - 0s 819us/step - loss: 0.3526 - mae: 0.3975 - val_loss: 0.3192 - val_mae: 0.4162\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2209 - mae: 0.3937\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.2740 - mae: 0.3932\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.2711 - mae: 0.3891\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3045 - mae: 0.3880\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3171 - mae: 0.3885\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3509 - mae: 0.3976\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3555 - mae: 0.3984\n528/528 [==============================] - 0s 800us/step - loss: 0.3515 - mae: 0.3988 - val_loss: 0.3074 - val_mae: 0.3883\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2352 - mae: 0.3815\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3479 - mae: 0.3913\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3430 - mae: 0.3858\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3519 - mae: 0.3933\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3378 - mae: 0.3941\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3652 - mae: 0.3984\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3500 - mae: 0.3972\n528/528 [==============================] - 0s 817us/step - loss: 0.3522 - mae: 0.3990 - val_loss: 0.3042 - val_mae: 0.3867\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2336 - mae: 0.3713\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.5005 - mae: 0.4282\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.4230 - mae: 0.4163\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3635 - mae: 0.4046\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3637 - mae: 0.4063\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3544 - mae: 0.4026\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3614 - mae: 0.4018\n528/528 [==============================] - 0s 811us/step - loss: 0.3498 - mae: 0.3981 - val_loss: 0.3075 - val_mae: 0.3870\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.3237\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3329 - mae: 0.3900\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3336 - mae: 0.3954\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3865 - mae: 0.4020\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3821 - mae: 0.4029\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3762 - mae: 0.4010\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3563 - mae: 0.3989\n528/528 [==============================] - 0s 813us/step - loss: 0.3523 - mae: 0.3996 - val_loss: 0.2960 - val_mae: 0.3881\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2422 - mae: 0.3530\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2893 - mae: 0.3956\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3452 - mae: 0.4025\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3215 - mae: 0.3971\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3210 - mae: 0.3949\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3233 - mae: 0.3925\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3363 - mae: 0.3972\n528/528 [==============================] - 0s 798us/step - loss: 0.3530 - mae: 0.3991 - val_loss: 0.3028 - val_mae: 0.3977\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1602 - mae: 0.3416\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2518 - mae: 0.3717\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.2997 - mae: 0.3822\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3310 - mae: 0.3907\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3294 - mae: 0.3885\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3447 - mae: 0.3907\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3552 - mae: 0.3958\n528/528 [==============================] - 0s 800us/step - loss: 0.3510 - mae: 0.3962 - val_loss: 0.3047 - val_mae: 0.3861\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.6127 - mae: 0.6745\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2908 - mae: 0.3962\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3126 - mae: 0.3902\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.2893 - mae: 0.3838\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3115 - mae: 0.3904\n399/528 [=====================&gt;........] - ETA: 0s - loss: 0.3329 - mae: 0.3948\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3349 - mae: 0.3965\n528/528 [==============================] - 0s 818us/step - loss: 0.3511 - mae: 0.3978 - val_loss: 0.2938 - val_mae: 0.3855\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3836 - mae: 0.4956\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2567 - mae: 0.3797\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2935 - mae: 0.3846\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3125 - mae: 0.3891\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3143 - mae: 0.3917\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3382 - mae: 0.3953\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3484 - mae: 0.3967\n528/528 [==============================] - 0s 809us/step - loss: 0.3482 - mae: 0.3981 - val_loss: 0.3043 - val_mae: 0.3961\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1910 - mae: 0.3540\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.4013 - mae: 0.4120\n152/528 [=======&gt;......................] - ETA: 0s - loss: 0.4003 - mae: 0.4100\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3556 - mae: 0.4030\n290/528 [===============&gt;..............] - ETA: 0s - loss: 0.3426 - mae: 0.4007\n353/528 [===================&gt;..........] - ETA: 0s - loss: 0.3468 - mae: 0.4011\n438/528 [=======================&gt;......] - ETA: 0s - loss: 0.3269 - mae: 0.3965\n520/528 [============================&gt;.] - ETA: 0s - loss: 0.3411 - mae: 0.3982\n528/528 [==============================] - 0s 871us/step - loss: 0.3505 - mae: 0.3986 - val_loss: 0.3332 - val_mae: 0.4272\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4983 - mae: 0.5605\n 87/528 [===&gt;..........................] - ETA: 0s - loss: 0.3193 - mae: 0.3873\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3017 - mae: 0.3888\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3397 - mae: 0.3956\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3248 - mae: 0.3949\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3285 - mae: 0.3953\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3371 - mae: 0.3980\n528/528 [==============================] - 0s 831us/step - loss: 0.3476 - mae: 0.3983 - val_loss: 0.2978 - val_mae: 0.3898\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1412 - mae: 0.3113\n 60/528 [==&gt;...........................] - ETA: 0s - loss: 0.4729 - mae: 0.4097\n138/528 [======&gt;.......................] - ETA: 0s - loss: 0.4325 - mae: 0.4042\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.3968 - mae: 0.4012\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3812 - mae: 0.4022\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3738 - mae: 0.3996\n469/528 [=========================&gt;....] - ETA: 0s - loss: 0.3591 - mae: 0.3992\n528/528 [==============================] - 0s 842us/step - loss: 0.3529 - mae: 0.3988 - val_loss: 0.3060 - val_mae: 0.4008\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1863 - mae: 0.3439\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3186 - mae: 0.3951\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.2969 - mae: 0.3964\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.2829 - mae: 0.3869\n318/528 [=================&gt;............] - ETA: 0s - loss: 0.2915 - mae: 0.3844\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3551 - mae: 0.3938\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3476 - mae: 0.3942\n527/528 [============================&gt;.] - ETA: 0s - loss: 0.3484 - mae: 0.3945\n528/528 [==============================] - 0s 869us/step - loss: 0.3481 - mae: 0.3943 - val_loss: 0.2984 - val_mae: 0.3843\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0863 - mae: 0.2539\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4510 - mae: 0.4241\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3942 - mae: 0.4149\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3900 - mae: 0.4098\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3742 - mae: 0.4019\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3554 - mae: 0.4004\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3509 - mae: 0.3972\n528/528 [==============================] - 0s 805us/step - loss: 0.3486 - mae: 0.3966 - val_loss: 0.3013 - val_mae: 0.3903\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1427 - mae: 0.3008\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3082 - mae: 0.3783\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3346 - mae: 0.3841\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3169 - mae: 0.3883\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3281 - mae: 0.3915\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3391 - mae: 0.3916\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3530 - mae: 0.3953\n528/528 [==============================] - 0s 805us/step - loss: 0.3494 - mae: 0.3949 - val_loss: 0.2991 - val_mae: 0.3817\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3616 - mae: 0.4716\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4048 - mae: 0.4115\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3943 - mae: 0.4083\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3707 - mae: 0.4002\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3451 - mae: 0.3974\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3271 - mae: 0.3936\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3446 - mae: 0.3942\n528/528 [==============================] - 0s 810us/step - loss: 0.3495 - mae: 0.3959 - val_loss: 0.3042 - val_mae: 0.3886\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1393 - mae: 0.3111\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.4794 - mae: 0.4116\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3708 - mae: 0.3970\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.4153 - mae: 0.4048\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3998 - mae: 0.4026\n375/528 [====================&gt;.........] - ETA: 0s - loss: 0.3698 - mae: 0.3987\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3555 - mae: 0.3947\n528/528 [==============================] - ETA: 0s - loss: 0.3476 - mae: 0.3947\n528/528 [==============================] - 0s 871us/step - loss: 0.3476 - mae: 0.3947 - val_loss: 0.3034 - val_mae: 0.3898\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1387 - mae: 0.3068\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3185 - mae: 0.3957\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3335 - mae: 0.3956\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3736 - mae: 0.4005\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3463 - mae: 0.3948\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3411 - mae: 0.3933\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3400 - mae: 0.3925\n528/528 [==============================] - 0s 843us/step - loss: 0.3483 - mae: 0.3955 - val_loss: 0.2985 - val_mae: 0.3827\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2196 - mae: 0.4168\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3044 - mae: 0.3851\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3565 - mae: 0.3907\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3595 - mae: 0.3946\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3784 - mae: 0.3979\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3534 - mae: 0.3941\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3484 - mae: 0.3947\n528/528 [==============================] - 0s 808us/step - loss: 0.3464 - mae: 0.3937 - val_loss: 0.2995 - val_mae: 0.3874\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1282 - mae: 0.2881\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3526 - mae: 0.3922\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3574 - mae: 0.3942\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3286 - mae: 0.3901\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3487 - mae: 0.3915\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3410 - mae: 0.3906\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3551 - mae: 0.3929\n528/528 [==============================] - 0s 854us/step - loss: 0.3487 - mae: 0.3940 - val_loss: 0.3056 - val_mae: 0.3872\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2414 - mae: 0.4000\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3127 - mae: 0.3773\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3709 - mae: 0.3925\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3479 - mae: 0.3916\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3244 - mae: 0.3871\n385/528 [====================&gt;.........] - ETA: 0s - loss: 0.3256 - mae: 0.3893\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3337 - mae: 0.3921\n528/528 [==============================] - 0s 865us/step - loss: 0.3487 - mae: 0.3935 - val_loss: 0.2914 - val_mae: 0.3818\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1264 - mae: 0.2742\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3746 - mae: 0.3990\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3618 - mae: 0.3916\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3492 - mae: 0.3902\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3295 - mae: 0.3888\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3384 - mae: 0.3914\n440/528 [========================&gt;.....] - ETA: 0s - loss: 0.3286 - mae: 0.3904\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3389 - mae: 0.3923\n528/528 [==============================] - 0s 929us/step - loss: 0.3445 - mae: 0.3935 - val_loss: 0.3465 - val_mae: 0.4334\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3830 - mae: 0.4878\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2726 - mae: 0.3932\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3642 - mae: 0.4009\n222/528 [===========&gt;..................] - ETA: 0s - loss: 0.3391 - mae: 0.3979\n300/528 [================&gt;.............] - ETA: 0s - loss: 0.3394 - mae: 0.3960\n384/528 [====================&gt;.........] - ETA: 0s - loss: 0.3506 - mae: 0.3953\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3558 - mae: 0.3952\n528/528 [==============================] - 0s 847us/step - loss: 0.3481 - mae: 0.3938 - val_loss: 0.3007 - val_mae: 0.3914\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0753 - mae: 0.1956\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3192 - mae: 0.3826\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3686 - mae: 0.3996\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3377 - mae: 0.3956\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3872 - mae: 0.4011\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3644 - mae: 0.3991\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3505 - mae: 0.3959\n528/528 [==============================] - 0s 833us/step - loss: 0.3464 - mae: 0.3948 - val_loss: 0.2934 - val_mae: 0.3823\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2332 - mae: 0.4041\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2592 - mae: 0.3771\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3184 - mae: 0.3921\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3886 - mae: 0.4023\n324/528 [=================&gt;............] - ETA: 0s - loss: 0.3568 - mae: 0.3950\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3344 - mae: 0.3911\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3523 - mae: 0.3943\n528/528 [==============================] - 0s 814us/step - loss: 0.3478 - mae: 0.3945 - val_loss: 0.2991 - val_mae: 0.3894\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0673 - mae: 0.1920\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3078 - mae: 0.3828\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.2858 - mae: 0.3834\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3110 - mae: 0.3894\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3491 - mae: 0.3937\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3556 - mae: 0.3942\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3408 - mae: 0.3927\n528/528 [==============================] - 0s 830us/step - loss: 0.3469 - mae: 0.3926 - val_loss: 0.3118 - val_mae: 0.4117\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1556 - mae: 0.3370\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2839 - mae: 0.3883\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.2830 - mae: 0.3886\n220/528 [===========&gt;..................] - ETA: 0s - loss: 0.2984 - mae: 0.3887\n293/528 [===============&gt;..............] - ETA: 0s - loss: 0.3180 - mae: 0.3908\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3555 - mae: 0.3952\n443/528 [========================&gt;.....] - ETA: 0s - loss: 0.3512 - mae: 0.3950\n520/528 [============================&gt;.] - ETA: 0s - loss: 0.3493 - mae: 0.3946\n528/528 [==============================] - 0s 899us/step - loss: 0.3482 - mae: 0.3944 - val_loss: 0.2904 - val_mae: 0.3851\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2274 - mae: 0.3810\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.4405 - mae: 0.4051\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.3799 - mae: 0.3960\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3520 - mae: 0.3908\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3592 - mae: 0.3910\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3430 - mae: 0.3908\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3510 - mae: 0.3924\n522/528 [============================&gt;.] - ETA: 0s - loss: 0.3448 - mae: 0.3922\n528/528 [==============================] - 0s 873us/step - loss: 0.3451 - mae: 0.3927 - val_loss: 0.3155 - val_mae: 0.4074\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2646 - mae: 0.4268\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3286 - mae: 0.4041\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3531 - mae: 0.4034\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3718 - mae: 0.4052\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3596 - mae: 0.3969\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3513 - mae: 0.3945\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3548 - mae: 0.3951\n528/528 [==============================] - 0s 836us/step - loss: 0.3467 - mae: 0.3927 - val_loss: 0.2991 - val_mae: 0.3906\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2777 - mae: 0.4126\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3112 - mae: 0.4013\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.2938 - mae: 0.3911\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.2844 - mae: 0.3896\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3101 - mae: 0.3903\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3327 - mae: 0.3915\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3451 - mae: 0.3916\n528/528 [==============================] - 0s 830us/step - loss: 0.3461 - mae: 0.3920 - val_loss: 0.2946 - val_mae: 0.3856\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1705 - mae: 0.3521\n 68/528 [==&gt;...........................] - ETA: 0s - loss: 0.3590 - mae: 0.3825\n139/528 [======&gt;.......................] - ETA: 0s - loss: 0.3009 - mae: 0.3727\n215/528 [===========&gt;..................] - ETA: 0s - loss: 0.3605 - mae: 0.3899\n291/528 [===============&gt;..............] - ETA: 0s - loss: 0.3496 - mae: 0.3965\n370/528 [====================&gt;.........] - ETA: 0s - loss: 0.3331 - mae: 0.3920\n453/528 [========================&gt;.....] - ETA: 0s - loss: 0.3509 - mae: 0.3948\n528/528 [==============================] - 0s 860us/step - loss: 0.3475 - mae: 0.3933 - val_loss: 0.3023 - val_mae: 0.3885\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5028 - mae: 0.4812\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3454 - mae: 0.3943\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.4201 - mae: 0.4081\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3622 - mae: 0.3947\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3674 - mae: 0.3908\n383/528 [====================&gt;.........] - ETA: 0s - loss: 0.3730 - mae: 0.3935\n461/528 [=========================&gt;....] - ETA: 0s - loss: 0.3607 - mae: 0.3937\n528/528 [==============================] - 0s 876us/step - loss: 0.3457 - mae: 0.3919 - val_loss: 0.3140 - val_mae: 0.4117\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0740 - mae: 0.2332\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3669 - mae: 0.3996\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3697 - mae: 0.3934\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3573 - mae: 0.3936\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3538 - mae: 0.3951\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3461 - mae: 0.3916\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3464 - mae: 0.3913\n528/528 [==============================] - 0s 816us/step - loss: 0.3437 - mae: 0.3921 - val_loss: 0.2997 - val_mae: 0.3842\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2600 - mae: 0.4033\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4531 - mae: 0.4147\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.4051 - mae: 0.4029\n223/528 [===========&gt;..................] - ETA: 0s - loss: 0.3746 - mae: 0.3988\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3462 - mae: 0.3947\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3575 - mae: 0.3957\n459/528 [=========================&gt;....] - ETA: 0s - loss: 0.3412 - mae: 0.3918\n528/528 [==============================] - 0s 865us/step - loss: 0.3454 - mae: 0.3921 - val_loss: 0.2944 - val_mae: 0.3910\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2180 - mae: 0.4074\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2744 - mae: 0.3865\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3975 - mae: 0.4013\n232/528 [============&gt;.................] - ETA: 0s - loss: 0.3775 - mae: 0.3986\n306/528 [================&gt;.............] - ETA: 0s - loss: 0.3743 - mae: 0.3988\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3643 - mae: 0.3977\n458/528 [=========================&gt;....] - ETA: 0s - loss: 0.3620 - mae: 0.3972\n528/528 [==============================] - 0s 846us/step - loss: 0.3466 - mae: 0.3936 - val_loss: 0.2880 - val_mae: 0.3780\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.3148 - mae: 0.6140\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3744 - mae: 0.3961\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3530 - mae: 0.3914\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3748 - mae: 0.3933\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3452 - mae: 0.3899\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3516 - mae: 0.3922\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3507 - mae: 0.3947\n528/528 [==============================] - 0s 802us/step - loss: 0.3447 - mae: 0.3940 - val_loss: 0.2974 - val_mae: 0.3910\nProcessing fold # 3 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 132.8168 - mae: 11.5127\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 56.7664 - mae: 6.6998  \n159/528 [========&gt;.....................] - ETA: 0s - loss: 29.6516 - mae: 4.0652\n243/528 [============&gt;.................] - ETA: 0s - loss: 19.9183 - mae: 2.9657\n315/528 [================&gt;.............] - ETA: 0s - loss: 15.6216 - mae: 2.4469\n397/528 [=====================&gt;........] - ETA: 0s - loss: 12.6184 - mae: 2.0785\n480/528 [==========================&gt;...] - ETA: 0s - loss: 10.5475 - mae: 1.8113\n528/528 [==============================] - 1s 1ms/step - loss: 9.6395 - mae: 1.6923 - val_loss: 0.4646 - val_mae: 0.4688\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2793 - mae: 0.4253\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4904 - mae: 0.4652\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.4265 - mae: 0.4540\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.4158 - mae: 0.4541\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.4303 - mae: 0.4501\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.4192 - mae: 0.4465\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.4185 - mae: 0.4430\n528/528 [==============================] - 0s 800us/step - loss: 0.4125 - mae: 0.4409 - val_loss: 0.3371 - val_mae: 0.4045\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2502 - mae: 0.3532\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3755 - mae: 0.4266\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4309 - mae: 0.4348\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3889 - mae: 0.4275\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3746 - mae: 0.4267\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3704 - mae: 0.4243\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3823 - mae: 0.4248\n528/528 [==============================] - 0s 807us/step - loss: 0.3801 - mae: 0.4243 - val_loss: 0.3663 - val_mae: 0.4199\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3851 - mae: 0.4555\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3258 - mae: 0.4198\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3255 - mae: 0.4181\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3797 - mae: 0.4201\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3626 - mae: 0.4188\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3701 - mae: 0.4188\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3699 - mae: 0.4192\n528/528 [==============================] - 0s 809us/step - loss: 0.3704 - mae: 0.4193 - val_loss: 0.3372 - val_mae: 0.4040\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2842 - mae: 0.4004\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3366 - mae: 0.4242\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3477 - mae: 0.4160\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3680 - mae: 0.4179\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3614 - mae: 0.4183\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3498 - mae: 0.4152\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3642 - mae: 0.4170\n528/528 [==============================] - 0s 838us/step - loss: 0.3716 - mae: 0.4185 - val_loss: 0.3213 - val_mae: 0.3914\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4346 - mae: 0.5448\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2835 - mae: 0.3970\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3756 - mae: 0.4155\n219/528 [===========&gt;..................] - ETA: 0s - loss: 0.3636 - mae: 0.4196\n295/528 [===============&gt;..............] - ETA: 0s - loss: 0.3839 - mae: 0.4188\n374/528 [====================&gt;.........] - ETA: 0s - loss: 0.3857 - mae: 0.4175\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3694 - mae: 0.4173\n528/528 [==============================] - 0s 905us/step - loss: 0.3641 - mae: 0.4159 - val_loss: 0.3699 - val_mae: 0.4433\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3116 - mae: 0.4210\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2727 - mae: 0.4024\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3239 - mae: 0.4087\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3596 - mae: 0.4133\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3680 - mae: 0.4153\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3485 - mae: 0.4105\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3618 - mae: 0.4139\n528/528 [==============================] - 0s 800us/step - loss: 0.3647 - mae: 0.4150 - val_loss: 0.3548 - val_mae: 0.4130\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0626 - mae: 0.2228\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3901 - mae: 0.4250\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3631 - mae: 0.4130\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3472 - mae: 0.4149\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3320 - mae: 0.4115\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3436 - mae: 0.4150\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3628 - mae: 0.4177\n528/528 [==============================] - 0s 791us/step - loss: 0.3648 - mae: 0.4178 - val_loss: 0.3326 - val_mae: 0.4071\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2050 - mae: 0.4038\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2986 - mae: 0.4087\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3396 - mae: 0.4178\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3384 - mae: 0.4155\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3295 - mae: 0.4127\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3726 - mae: 0.4176\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3622 - mae: 0.4155\n528/528 [==============================] - 0s 791us/step - loss: 0.3610 - mae: 0.4155 - val_loss: 0.3382 - val_mae: 0.4030\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4602 - mae: 0.4403\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4360 - mae: 0.4227\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3701 - mae: 0.4112\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3565 - mae: 0.4084\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3621 - mae: 0.4121\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3647 - mae: 0.4122\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3564 - mae: 0.4125\n528/528 [==============================] - 0s 788us/step - loss: 0.3617 - mae: 0.4121 - val_loss: 0.3292 - val_mae: 0.4008\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3253 - mae: 0.4399\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2880 - mae: 0.4065\n144/528 [=======&gt;......................] - ETA: 0s - loss: 0.3185 - mae: 0.4062\n223/528 [===========&gt;..................] - ETA: 0s - loss: 0.3498 - mae: 0.4094\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3530 - mae: 0.4083\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3700 - mae: 0.4140\n456/528 [========================&gt;.....] - ETA: 0s - loss: 0.3633 - mae: 0.4107\n528/528 [==============================] - 0s 854us/step - loss: 0.3557 - mae: 0.4103 - val_loss: 0.3291 - val_mae: 0.3949\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2178 - mae: 0.3664\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3356 - mae: 0.4098\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3397 - mae: 0.4062\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3707 - mae: 0.4089\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3571 - mae: 0.4131\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3413 - mae: 0.4106\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3585 - mae: 0.4125\n528/528 [==============================] - 0s 810us/step - loss: 0.3554 - mae: 0.4117 - val_loss: 0.3650 - val_mae: 0.4159\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3125 - mae: 0.4267\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4260 - mae: 0.4142\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.4760 - mae: 0.4217\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.4075 - mae: 0.4122\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3844 - mae: 0.4131\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3680 - mae: 0.4094\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3593 - mae: 0.4095\n528/528 [==============================] - 0s 824us/step - loss: 0.3567 - mae: 0.4098 - val_loss: 0.3444 - val_mae: 0.4155\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2284 - mae: 0.3470\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3826 - mae: 0.4120\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3304 - mae: 0.4052\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3628 - mae: 0.4163\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3766 - mae: 0.4149\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3650 - mae: 0.4128\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3506 - mae: 0.4102\n528/528 [==============================] - 0s 811us/step - loss: 0.3554 - mae: 0.4103 - val_loss: 0.3447 - val_mae: 0.4194\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1320 - mae: 0.2936\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3897 - mae: 0.4172\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4836 - mae: 0.4299\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.4172 - mae: 0.4184\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3831 - mae: 0.4143\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3577 - mae: 0.4081\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3557 - mae: 0.4084\n528/528 [==============================] - 0s 818us/step - loss: 0.3557 - mae: 0.4088 - val_loss: 0.3384 - val_mae: 0.4085\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2605 - mae: 0.4198\n 67/528 [==&gt;...........................] - ETA: 0s - loss: 0.3528 - mae: 0.4181\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3097 - mae: 0.3997\n235/528 [============&gt;.................] - ETA: 0s - loss: 0.3146 - mae: 0.4006\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3668 - mae: 0.4088\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3782 - mae: 0.4098\n491/528 [==========================&gt;...] - ETA: 0s - loss: 0.3562 - mae: 0.4058\n528/528 [==============================] - 0s 809us/step - loss: 0.3550 - mae: 0.4065 - val_loss: 0.3380 - val_mae: 0.4105\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1907 - mae: 0.3182\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4245 - mae: 0.4160\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3847 - mae: 0.4100\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3793 - mae: 0.4116\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3802 - mae: 0.4126\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3703 - mae: 0.4116\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3533 - mae: 0.4083\n528/528 [==============================] - 0s 797us/step - loss: 0.3536 - mae: 0.4087 - val_loss: 0.3427 - val_mae: 0.4133\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1502 - mae: 0.3031\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2483 - mae: 0.3875\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2824 - mae: 0.3931\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.2884 - mae: 0.3915\n320/528 [=================&gt;............] - ETA: 0s - loss: 0.3052 - mae: 0.3954\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3328 - mae: 0.4019\n485/528 [==========================&gt;...] - ETA: 0s - loss: 0.3516 - mae: 0.4053\n528/528 [==============================] - 0s 836us/step - loss: 0.3481 - mae: 0.4047 - val_loss: 0.3715 - val_mae: 0.4174\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3774 - mae: 0.4654\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3237 - mae: 0.3937\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3057 - mae: 0.3927\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3643 - mae: 0.3988\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3465 - mae: 0.4007\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3418 - mae: 0.4050\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3542 - mae: 0.4071\n528/528 [==============================] - 0s 803us/step - loss: 0.3538 - mae: 0.4074 - val_loss: 0.3462 - val_mae: 0.4176\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1471 - mae: 0.2923\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2739 - mae: 0.3870\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3126 - mae: 0.3961\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3526 - mae: 0.4050\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3432 - mae: 0.4053\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3331 - mae: 0.4030\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3477 - mae: 0.4046\n528/528 [==============================] - 0s 818us/step - loss: 0.3493 - mae: 0.4045 - val_loss: 0.3341 - val_mae: 0.3981\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2890 - mae: 0.4427\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3445 - mae: 0.4009\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3310 - mae: 0.4054\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3245 - mae: 0.3982\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3587 - mae: 0.4042\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3491 - mae: 0.4042\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3500 - mae: 0.4045\n528/528 [==============================] - 0s 803us/step - loss: 0.3517 - mae: 0.4037 - val_loss: 0.3496 - val_mae: 0.4053\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1372 - mae: 0.3011\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3520 - mae: 0.4051\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2999 - mae: 0.3966\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3410 - mae: 0.4060\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3299 - mae: 0.4017\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3335 - mae: 0.4010\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3427 - mae: 0.4036\n528/528 [==============================] - 0s 787us/step - loss: 0.3512 - mae: 0.4040 - val_loss: 0.3882 - val_mae: 0.4594\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6725 - mae: 0.6330\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3989 - mae: 0.4171\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3487 - mae: 0.3999\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3390 - mae: 0.3994\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3575 - mae: 0.4031\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3475 - mae: 0.4042\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3511 - mae: 0.4028\n528/528 [==============================] - 0s 787us/step - loss: 0.3492 - mae: 0.4029 - val_loss: 0.3407 - val_mae: 0.4033\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2288 - mae: 0.3529\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4011 - mae: 0.4244\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3239 - mae: 0.4045\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3383 - mae: 0.4077\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3360 - mae: 0.4052\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3595 - mae: 0.4051\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3504 - mae: 0.4054\n528/528 [==============================] - 0s 796us/step - loss: 0.3485 - mae: 0.4055 - val_loss: 0.3336 - val_mae: 0.4036\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2728 - mae: 0.3564\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2751 - mae: 0.3925\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3653 - mae: 0.4028\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3303 - mae: 0.3967\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3445 - mae: 0.4013\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3510 - mae: 0.4016\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3528 - mae: 0.4030\n528/528 [==============================] - 0s 833us/step - loss: 0.3476 - mae: 0.4025 - val_loss: 0.3541 - val_mae: 0.4254\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3690 - mae: 0.5273\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3418 - mae: 0.4057\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3253 - mae: 0.3983\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3586 - mae: 0.4075\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3527 - mae: 0.4053\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3590 - mae: 0.4078\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3545 - mae: 0.4049\n528/528 [==============================] - 0s 800us/step - loss: 0.3481 - mae: 0.4035 - val_loss: 0.3359 - val_mae: 0.4015\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 5.7977 - mae: 0.9495\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4742 - mae: 0.4252\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.4224 - mae: 0.4196\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3653 - mae: 0.4047\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3354 - mae: 0.4010\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3416 - mae: 0.4015\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3419 - mae: 0.4017\n528/528 [==============================] - 0s 796us/step - loss: 0.3438 - mae: 0.4024 - val_loss: 0.3480 - val_mae: 0.4099\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6496 - mae: 0.5991\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3780 - mae: 0.4098\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3633 - mae: 0.4077\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.4020 - mae: 0.4123\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3862 - mae: 0.4098\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3602 - mae: 0.4034\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3500 - mae: 0.4018\n528/528 [==============================] - 0s 794us/step - loss: 0.3474 - mae: 0.4014 - val_loss: 0.3374 - val_mae: 0.3985\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3896 - mae: 0.4424\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2758 - mae: 0.3868\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3676 - mae: 0.4021\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3844 - mae: 0.4092\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3784 - mae: 0.4094\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3529 - mae: 0.4058\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3373 - mae: 0.4013\n528/528 [==============================] - 0s 789us/step - loss: 0.3464 - mae: 0.4019 - val_loss: 0.3354 - val_mae: 0.4065\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0461 - mae: 0.1622\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3558 - mae: 0.4059\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3395 - mae: 0.4005\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3686 - mae: 0.4044\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3502 - mae: 0.4022\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3451 - mae: 0.4004\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3412 - mae: 0.4016\n528/528 [==============================] - 0s 841us/step - loss: 0.3434 - mae: 0.4017 - val_loss: 0.3398 - val_mae: 0.3970\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1622 - mae: 0.3455\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.2529 - mae: 0.3781\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3734 - mae: 0.4105\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3501 - mae: 0.4013\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3378 - mae: 0.3992\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3331 - mae: 0.3984\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3485 - mae: 0.4004\n528/528 [==============================] - 0s 804us/step - loss: 0.3459 - mae: 0.4014 - val_loss: 0.3360 - val_mae: 0.3982\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2512 - mae: 0.4212\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4724 - mae: 0.4233\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3800 - mae: 0.4118\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3605 - mae: 0.4067\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3574 - mae: 0.4011\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3560 - mae: 0.4007\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3439 - mae: 0.3988\n528/528 [==============================] - 0s 808us/step - loss: 0.3482 - mae: 0.4010 - val_loss: 0.3399 - val_mae: 0.4105\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2396 - mae: 0.3923\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3501 - mae: 0.3897\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3230 - mae: 0.3962\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3125 - mae: 0.3990\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.3346 - mae: 0.4038\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3200 - mae: 0.3999\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3255 - mae: 0.3984\n528/528 [==============================] - 0s 802us/step - loss: 0.3463 - mae: 0.4008 - val_loss: 0.4282 - val_mae: 0.4668\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2268 - mae: 0.3285\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3812 - mae: 0.4295\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3210 - mae: 0.4067\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3296 - mae: 0.4018\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3267 - mae: 0.4005\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3272 - mae: 0.3998\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3466 - mae: 0.4018\n528/528 [==============================] - 0s 800us/step - loss: 0.3460 - mae: 0.4018 - val_loss: 0.3365 - val_mae: 0.4105\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2635 - mae: 0.4617\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3583 - mae: 0.4040\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3841 - mae: 0.4080\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3536 - mae: 0.4056\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3352 - mae: 0.4025\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3388 - mae: 0.4019\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3440 - mae: 0.4029\n528/528 [==============================] - 0s 818us/step - loss: 0.3455 - mae: 0.4032 - val_loss: 0.3370 - val_mae: 0.3972\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3286 - mae: 0.4317\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2969 - mae: 0.3912\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3243 - mae: 0.3926\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3384 - mae: 0.3951\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3665 - mae: 0.4005\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3537 - mae: 0.4006\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3461 - mae: 0.3988\n528/528 [==============================] - 0s 809us/step - loss: 0.3447 - mae: 0.3987 - val_loss: 0.3425 - val_mae: 0.4010\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3179 - mae: 0.4870\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3720 - mae: 0.4173\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3129 - mae: 0.3994\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3441 - mae: 0.4052\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3375 - mae: 0.4036\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3159 - mae: 0.3976\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3232 - mae: 0.3970\n528/528 [==============================] - 0s 805us/step - loss: 0.3446 - mae: 0.4009 - val_loss: 0.4094 - val_mae: 0.4505\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2867 - mae: 0.4248\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3134 - mae: 0.4004\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3898 - mae: 0.4097\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3447 - mae: 0.3988\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3327 - mae: 0.3992\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3587 - mae: 0.4039\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3507 - mae: 0.4021\n528/528 [==============================] - 0s 800us/step - loss: 0.3439 - mae: 0.3997 - val_loss: 0.3748 - val_mae: 0.4395\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1479 - mae: 0.3132\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3975 - mae: 0.4115\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3965 - mae: 0.4143\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3760 - mae: 0.4061\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3468 - mae: 0.4007\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3665 - mae: 0.4057\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3518 - mae: 0.4022\n528/528 [==============================] - 0s 816us/step - loss: 0.3472 - mae: 0.4005 - val_loss: 0.3383 - val_mae: 0.4092\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1933 - mae: 0.3834\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2681 - mae: 0.3746\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2818 - mae: 0.3875\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.3001 - mae: 0.3910\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3240 - mae: 0.3960\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3445 - mae: 0.3991\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3410 - mae: 0.3984\n528/528 [==============================] - 0s 817us/step - loss: 0.3455 - mae: 0.3999 - val_loss: 0.3337 - val_mae: 0.3967\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1188 - mae: 0.3074\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2900 - mae: 0.3871\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.2903 - mae: 0.3915\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3123 - mae: 0.3956\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3332 - mae: 0.4013\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3340 - mae: 0.4002\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3486 - mae: 0.4009\n528/528 [==============================] - 0s 808us/step - loss: 0.3426 - mae: 0.3999 - val_loss: 0.3333 - val_mae: 0.4012\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1410 - mae: 0.2905\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3096 - mae: 0.3845\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3019 - mae: 0.3903\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3442 - mae: 0.3919\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3327 - mae: 0.3899\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3307 - mae: 0.3912\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3412 - mae: 0.3951\n528/528 [==============================] - 0s 811us/step - loss: 0.3407 - mae: 0.3966 - val_loss: 0.3311 - val_mae: 0.3927\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0656 - mae: 0.2069\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.2860 - mae: 0.3835\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.3288 - mae: 0.3908\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.2987 - mae: 0.3846\n343/528 [==================&gt;...........] - ETA: 0s - loss: 0.3484 - mae: 0.3958\n427/528 [=======================&gt;......] - ETA: 0s - loss: 0.3515 - mae: 0.3986\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3486 - mae: 0.3995\n528/528 [==============================] - 0s 823us/step - loss: 0.3460 - mae: 0.3986 - val_loss: 0.3762 - val_mae: 0.4186\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3852 - mae: 0.5307\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2832 - mae: 0.3824\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3183 - mae: 0.3865\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.2971 - mae: 0.3816\n301/528 [================&gt;.............] - ETA: 0s - loss: 0.3103 - mae: 0.3869\n376/528 [====================&gt;.........] - ETA: 0s - loss: 0.3132 - mae: 0.3911\n437/528 [=======================&gt;......] - ETA: 0s - loss: 0.3224 - mae: 0.3924\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3326 - mae: 0.3954\n528/528 [==============================] - 1s 950us/step - loss: 0.3412 - mae: 0.3971 - val_loss: 0.3418 - val_mae: 0.4044\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2043 - mae: 0.3605\n 67/528 [==&gt;...........................] - ETA: 0s - loss: 0.2671 - mae: 0.3832\n126/528 [======&gt;.......................] - ETA: 0s - loss: 0.3291 - mae: 0.3844\n177/528 [=========&gt;....................] - ETA: 0s - loss: 0.3207 - mae: 0.3882\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3428 - mae: 0.3954\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3620 - mae: 0.3999\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3455 - mae: 0.3971\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3484 - mae: 0.3979\n528/528 [==============================] - 0s 936us/step - loss: 0.3422 - mae: 0.3978 - val_loss: 0.3464 - val_mae: 0.4063\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2467 - mae: 0.3734\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3775 - mae: 0.4083\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3640 - mae: 0.4095\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3430 - mae: 0.4055\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3373 - mae: 0.3998\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3399 - mae: 0.3989\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3483 - mae: 0.3995\n528/528 [==============================] - 0s 817us/step - loss: 0.3436 - mae: 0.3993 - val_loss: 0.3528 - val_mae: 0.4064\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0588 - mae: 0.1830\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3590 - mae: 0.4006\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3880 - mae: 0.4039\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3549 - mae: 0.4032\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3558 - mae: 0.3997\n405/528 [======================&gt;.......] - ETA: 0s - loss: 0.3617 - mae: 0.4010\n489/528 [==========================&gt;...] - ETA: 0s - loss: 0.3482 - mae: 0.3998\n528/528 [==============================] - 0s 819us/step - loss: 0.3429 - mae: 0.3982 - val_loss: 0.3335 - val_mae: 0.4010\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1688 - mae: 0.3451\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3920 - mae: 0.4149\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3242 - mae: 0.3955\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3236 - mae: 0.3969\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3233 - mae: 0.3940\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3242 - mae: 0.3957\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3352 - mae: 0.3978\n528/528 [==============================] - 0s 818us/step - loss: 0.3421 - mae: 0.3973 - val_loss: 0.3450 - val_mae: 0.4023\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2658 - mae: 0.4016\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3338 - mae: 0.3951\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3051 - mae: 0.3892\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3132 - mae: 0.3908\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3089 - mae: 0.3929\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3252 - mae: 0.3924\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3453 - mae: 0.4001\n528/528 [==============================] - 0s 800us/step - loss: 0.3415 - mae: 0.3992 - val_loss: 0.3393 - val_mae: 0.4098\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5119 - mae: 0.4826\n 68/528 [==&gt;...........................] - ETA: 0s - loss: 0.2751 - mae: 0.3862\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3173 - mae: 0.3934\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.3507 - mae: 0.4027\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3250 - mae: 0.3960\n406/528 [======================&gt;.......] - ETA: 0s - loss: 0.3322 - mae: 0.3963\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3290 - mae: 0.3945\n528/528 [==============================] - 0s 852us/step - loss: 0.3395 - mae: 0.3974 - val_loss: 0.3483 - val_mae: 0.4063\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1082 - mae: 0.2537\n 54/528 [==&gt;...........................] - ETA: 0s - loss: 0.3269 - mae: 0.3939\n134/528 [======&gt;.......................] - ETA: 0s - loss: 0.4232 - mae: 0.4077\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3916 - mae: 0.4000\n299/528 [===============&gt;..............] - ETA: 0s - loss: 0.3850 - mae: 0.4033\n385/528 [====================&gt;.........] - ETA: 0s - loss: 0.3659 - mae: 0.4019\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3495 - mae: 0.3988\n528/528 [==============================] - 0s 836us/step - loss: 0.3404 - mae: 0.3959 - val_loss: 0.3594 - val_mae: 0.4082\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3669 - mae: 0.4636\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4091 - mae: 0.3922\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3395 - mae: 0.3903\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3668 - mae: 0.4001\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3794 - mae: 0.4037\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3570 - mae: 0.3994\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3389 - mae: 0.3946\n528/528 [==============================] - 0s 794us/step - loss: 0.3382 - mae: 0.3951 - val_loss: 0.3675 - val_mae: 0.4102\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3190 - mae: 0.3806\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2645 - mae: 0.3700\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3645 - mae: 0.4011\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3830 - mae: 0.4021\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3679 - mae: 0.4020\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3683 - mae: 0.4044\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3464 - mae: 0.3985\n528/528 [==============================] - 0s 803us/step - loss: 0.3402 - mae: 0.3970 - val_loss: 0.3404 - val_mae: 0.3963\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6389 - mae: 0.5157\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3599 - mae: 0.3996\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3592 - mae: 0.4001\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3576 - mae: 0.4002\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3850 - mae: 0.4072\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3577 - mae: 0.4012\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3470 - mae: 0.3988\n528/528 [==============================] - 0s 824us/step - loss: 0.3398 - mae: 0.3966 - val_loss: 0.3382 - val_mae: 0.3973\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2024 - mae: 0.3624\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2752 - mae: 0.3871\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.2565 - mae: 0.3782\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.2947 - mae: 0.3870\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3109 - mae: 0.3875\n407/528 [======================&gt;.......] - ETA: 0s - loss: 0.3092 - mae: 0.3874\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3342 - mae: 0.3937\n528/528 [==============================] - 0s 815us/step - loss: 0.3408 - mae: 0.3942 - val_loss: 0.3891 - val_mae: 0.4596\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3565 - mae: 0.4661\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2828 - mae: 0.3894\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3188 - mae: 0.3963\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3389 - mae: 0.3947\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3448 - mae: 0.3986\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3408 - mae: 0.3977\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3460 - mae: 0.3975\n528/528 [==============================] - 0s 817us/step - loss: 0.3419 - mae: 0.3970 - val_loss: 0.3488 - val_mae: 0.3994\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2348 - mae: 0.3884\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2754 - mae: 0.3817\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3163 - mae: 0.3933\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.2972 - mae: 0.3914\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3260 - mae: 0.3943\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3443 - mae: 0.3976\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3397 - mae: 0.3952\n528/528 [==============================] - 0s 823us/step - loss: 0.3392 - mae: 0.3955 - val_loss: 0.3305 - val_mae: 0.3993\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2875 - mae: 0.4576\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2664 - mae: 0.3816\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.2960 - mae: 0.3793\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3045 - mae: 0.3812\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3199 - mae: 0.3865\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3254 - mae: 0.3892\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3384 - mae: 0.3960\n528/528 [==============================] - 0s 796us/step - loss: 0.3367 - mae: 0.3951 - val_loss: 0.3610 - val_mae: 0.4086\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2153 - mae: 0.3850\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3992 - mae: 0.4151\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3266 - mae: 0.3966\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3635 - mae: 0.4017\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3496 - mae: 0.3986\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3424 - mae: 0.3996\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3432 - mae: 0.3971\n528/528 [==============================] - 0s 819us/step - loss: 0.3366 - mae: 0.3954 - val_loss: 0.3365 - val_mae: 0.4035\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1565 - mae: 0.3282\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.4251 - mae: 0.3965\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.4137 - mae: 0.4001\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3840 - mae: 0.3976\n341/528 [==================&gt;...........] - ETA: 0s - loss: 0.3563 - mae: 0.3952\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3537 - mae: 0.3957\n511/528 [============================&gt;.] - ETA: 0s - loss: 0.3442 - mae: 0.3962\n528/528 [==============================] - 0s 795us/step - loss: 0.3409 - mae: 0.3960 - val_loss: 0.3454 - val_mae: 0.3996\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3420 - mae: 0.4782\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4647 - mae: 0.4218\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3721 - mae: 0.4042\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3518 - mae: 0.3954\n313/528 [================&gt;.............] - ETA: 0s - loss: 0.3347 - mae: 0.3940\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3386 - mae: 0.3946\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3489 - mae: 0.3951\n528/528 [==============================] - 0s 847us/step - loss: 0.3398 - mae: 0.3932 - val_loss: 0.3277 - val_mae: 0.3916\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1071 - mae: 0.2439\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3210 - mae: 0.3971\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2943 - mae: 0.3866\n237/528 [============&gt;.................] - ETA: 0s - loss: 0.3180 - mae: 0.3909\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3018 - mae: 0.3866\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3326 - mae: 0.3913\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3297 - mae: 0.3910\n528/528 [==============================] - 0s 818us/step - loss: 0.3359 - mae: 0.3928 - val_loss: 0.3340 - val_mae: 0.3992\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1484 - mae: 0.2949\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.4796 - mae: 0.4117\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.4174 - mae: 0.4074\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3532 - mae: 0.3930\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3377 - mae: 0.3951\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3343 - mae: 0.3920\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3327 - mae: 0.3910\n528/528 [==============================] - 0s 800us/step - loss: 0.3349 - mae: 0.3920 - val_loss: 0.3355 - val_mae: 0.4082\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2437 - mae: 0.4061\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3279 - mae: 0.3847\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3371 - mae: 0.3907\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.3350 - mae: 0.3917\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3326 - mae: 0.3919\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3321 - mae: 0.3926\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3293 - mae: 0.3926\n528/528 [==============================] - 0s 832us/step - loss: 0.3374 - mae: 0.3934 - val_loss: 0.3375 - val_mae: 0.3998\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1569 - mae: 0.2953\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2876 - mae: 0.3819\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3661 - mae: 0.3928\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3255 - mae: 0.3873\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3421 - mae: 0.3940\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3253 - mae: 0.3925\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3282 - mae: 0.3940\n528/528 [==============================] - 0s 814us/step - loss: 0.3399 - mae: 0.3961 - val_loss: 0.3298 - val_mae: 0.3953\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1330 - mae: 0.2862\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3496 - mae: 0.3904\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3958 - mae: 0.4031\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3646 - mae: 0.4024\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3380 - mae: 0.3971\n426/528 [=======================&gt;......] - ETA: 0s - loss: 0.3541 - mae: 0.3981\n511/528 [============================&gt;.] - ETA: 0s - loss: 0.3405 - mae: 0.3962\n528/528 [==============================] - 0s 800us/step - loss: 0.3383 - mae: 0.3958 - val_loss: 0.3493 - val_mae: 0.4110\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2365 - mae: 0.3680\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3189 - mae: 0.3771\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3129 - mae: 0.3895\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3127 - mae: 0.3952\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3328 - mae: 0.3954\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3469 - mae: 0.3977\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3425 - mae: 0.3965\n528/528 [==============================] - 0s 801us/step - loss: 0.3375 - mae: 0.3949 - val_loss: 0.3281 - val_mae: 0.3988\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3983 - mae: 0.4728\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3660 - mae: 0.3972\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3261 - mae: 0.3968\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3019 - mae: 0.3911\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3170 - mae: 0.3925\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3282 - mae: 0.3968\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3393 - mae: 0.3947\n528/528 [==============================] - 0s 800us/step - loss: 0.3378 - mae: 0.3942 - val_loss: 0.3586 - val_mae: 0.4093\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1739 - mae: 0.2835\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2604 - mae: 0.3770\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3026 - mae: 0.3851\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3267 - mae: 0.3908\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3549 - mae: 0.3966\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3469 - mae: 0.3956\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3469 - mae: 0.3956\n528/528 [==============================] - 0s 814us/step - loss: 0.3366 - mae: 0.3932 - val_loss: 0.3451 - val_mae: 0.4140\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3999 - mae: 0.5092\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3716 - mae: 0.4012\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3372 - mae: 0.3964\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3193 - mae: 0.3914\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3257 - mae: 0.3905\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3293 - mae: 0.3920\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3414 - mae: 0.3941\n528/528 [==============================] - 0s 795us/step - loss: 0.3368 - mae: 0.3926 - val_loss: 0.3472 - val_mae: 0.3988\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1806 - mae: 0.3290\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4224 - mae: 0.4050\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3888 - mae: 0.3947\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3665 - mae: 0.3964\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3497 - mae: 0.3969\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3426 - mae: 0.3957\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3393 - mae: 0.3938\n528/528 [==============================] - 0s 803us/step - loss: 0.3374 - mae: 0.3938 - val_loss: 0.3256 - val_mae: 0.3910\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1867 - mae: 0.3326\n 57/528 [==&gt;...........................] - ETA: 0s - loss: 0.3036 - mae: 0.3907\n119/528 [=====&gt;........................] - ETA: 0s - loss: 0.2778 - mae: 0.3837\n204/528 [==========&gt;...................] - ETA: 0s - loss: 0.3388 - mae: 0.3947\n285/528 [===============&gt;..............] - ETA: 0s - loss: 0.3370 - mae: 0.3933\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3255 - mae: 0.3930\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3337 - mae: 0.3918\n528/528 [==============================] - 0s 872us/step - loss: 0.3350 - mae: 0.3921 - val_loss: 0.3735 - val_mae: 0.4206\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1934 - mae: 0.3491\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2948 - mae: 0.3935\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3596 - mae: 0.4015\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3657 - mae: 0.3975\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3505 - mae: 0.3920\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3515 - mae: 0.3955\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3349 - mae: 0.3927\n528/528 [==============================] - 0s 808us/step - loss: 0.3358 - mae: 0.3930 - val_loss: 0.3584 - val_mae: 0.4176\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1589 - mae: 0.2925\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.4734 - mae: 0.4116\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.4007 - mae: 0.4012\n230/528 [============&gt;.................] - ETA: 0s - loss: 0.3722 - mae: 0.3983\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3557 - mae: 0.3970\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3540 - mae: 0.3954\n471/528 [=========================&gt;....] - ETA: 0s - loss: 0.3379 - mae: 0.3912\n528/528 [==============================] - 0s 864us/step - loss: 0.3370 - mae: 0.3932 - val_loss: 0.3383 - val_mae: 0.3963\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4264 - mae: 0.5076\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3514 - mae: 0.3898\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.4122 - mae: 0.4006\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3877 - mae: 0.4041\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3615 - mae: 0.3977\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3448 - mae: 0.3950\n511/528 [============================&gt;.] - ETA: 0s - loss: 0.3352 - mae: 0.3912\n528/528 [==============================] - 0s 788us/step - loss: 0.3356 - mae: 0.3917 - val_loss: 0.3311 - val_mae: 0.3978\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1139 - mae: 0.2988\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2783 - mae: 0.3863\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3329 - mae: 0.3930\n242/528 [============&gt;.................] - ETA: 0s - loss: 0.3470 - mae: 0.3934\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3551 - mae: 0.3941\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3437 - mae: 0.3943\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3317 - mae: 0.3930\n528/528 [==============================] - 0s 811us/step - loss: 0.3367 - mae: 0.3938 - val_loss: 0.3337 - val_mae: 0.4012\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1397 - mae: 0.3119\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3017 - mae: 0.3686\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3157 - mae: 0.3766\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3212 - mae: 0.3813\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3318 - mae: 0.3912\n404/528 [=====================&gt;........] - ETA: 0s - loss: 0.3504 - mae: 0.3941\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3424 - mae: 0.3945\n528/528 [==============================] - 0s 814us/step - loss: 0.3372 - mae: 0.3920 - val_loss: 0.3443 - val_mae: 0.4004\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0788 - mae: 0.2253\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3374 - mae: 0.3876\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3467 - mae: 0.3919\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3670 - mae: 0.3958\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3554 - mae: 0.3958\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3412 - mae: 0.3942\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3356 - mae: 0.3922\n528/528 [==============================] - 0s 793us/step - loss: 0.3358 - mae: 0.3932 - val_loss: 0.3432 - val_mae: 0.4009\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1259 - mae: 0.3006\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.2827 - mae: 0.3894\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3676 - mae: 0.3996\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3399 - mae: 0.3960\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3126 - mae: 0.3909\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3450 - mae: 0.3936\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3411 - mae: 0.3941\n528/528 [==============================] - 0s 812us/step - loss: 0.3326 - mae: 0.3915 - val_loss: 0.3407 - val_mae: 0.4001\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1433 - mae: 0.2811\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3227 - mae: 0.3907\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3639 - mae: 0.4003\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3799 - mae: 0.3999\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3518 - mae: 0.3950\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3457 - mae: 0.3949\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3415 - mae: 0.3935\n528/528 [==============================] - 0s 801us/step - loss: 0.3368 - mae: 0.3922 - val_loss: 0.3461 - val_mae: 0.4178\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2004 - mae: 0.3755\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3052 - mae: 0.3970\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.2913 - mae: 0.3896\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3355 - mae: 0.3968\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3163 - mae: 0.3903\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3309 - mae: 0.3934\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3290 - mae: 0.3931\n528/528 [==============================] - 0s 792us/step - loss: 0.3350 - mae: 0.3932 - val_loss: 0.3328 - val_mae: 0.3972\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1076 - mae: 0.2510\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2605 - mae: 0.3671\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.2995 - mae: 0.3812\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.2968 - mae: 0.3844\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3156 - mae: 0.3868\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3389 - mae: 0.3921\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3389 - mae: 0.3928\n528/528 [==============================] - 0s 806us/step - loss: 0.3394 - mae: 0.3926 - val_loss: 0.3507 - val_mae: 0.4193\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2739 - mae: 0.4237\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.4196 - mae: 0.4190\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3807 - mae: 0.4035\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3537 - mae: 0.3994\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3623 - mae: 0.3969\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3536 - mae: 0.3966\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3380 - mae: 0.3939\n528/528 [==============================] - 0s 800us/step - loss: 0.3329 - mae: 0.3924 - val_loss: 0.3380 - val_mae: 0.4001\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2721 - mae: 0.4245\n 60/528 [==&gt;...........................] - ETA: 0s - loss: 0.3258 - mae: 0.3929\n140/528 [======&gt;.......................] - ETA: 0s - loss: 0.3206 - mae: 0.3844\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3336 - mae: 0.3879\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3234 - mae: 0.3906\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3280 - mae: 0.3931\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3441 - mae: 0.3959\n528/528 [==============================] - 0s 828us/step - loss: 0.3355 - mae: 0.3932 - val_loss: 0.3359 - val_mae: 0.4008\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2343 - mae: 0.4068\n 60/528 [==&gt;...........................] - ETA: 0s - loss: 0.2991 - mae: 0.3822\n132/528 [======&gt;.......................] - ETA: 0s - loss: 0.3070 - mae: 0.3876\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3406 - mae: 0.3890\n303/528 [================&gt;.............] - ETA: 0s - loss: 0.3725 - mae: 0.3970\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3525 - mae: 0.3973\n475/528 [=========================&gt;....] - ETA: 0s - loss: 0.3443 - mae: 0.3947\n528/528 [==============================] - 0s 824us/step - loss: 0.3337 - mae: 0.3925 - val_loss: 0.3431 - val_mae: 0.3973\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1681 - mae: 0.3189\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3062 - mae: 0.3851\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.3160 - mae: 0.3835\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3624 - mae: 0.3944\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3432 - mae: 0.3928\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3314 - mae: 0.3932\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3375 - mae: 0.3907\n528/528 [==============================] - 0s 792us/step - loss: 0.3345 - mae: 0.3896 - val_loss: 0.3417 - val_mae: 0.4132\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1438 - mae: 0.3036\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3553 - mae: 0.4070\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3425 - mae: 0.3943\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3142 - mae: 0.3911\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3199 - mae: 0.3901\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3198 - mae: 0.3887\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3314 - mae: 0.3903\n528/528 [==============================] - 0s 787us/step - loss: 0.3315 - mae: 0.3910 - val_loss: 0.3427 - val_mae: 0.3962\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2286 - mae: 0.3522\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3560 - mae: 0.3978\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3940 - mae: 0.4021\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3650 - mae: 0.3954\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3359 - mae: 0.3911\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3443 - mae: 0.3928\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3324 - mae: 0.3894\n528/528 [==============================] - 0s 817us/step - loss: 0.3339 - mae: 0.3901 - val_loss: 0.3849 - val_mae: 0.4547\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2542 - mae: 0.4354\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3355 - mae: 0.3900\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3519 - mae: 0.3943\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3366 - mae: 0.3910\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3207 - mae: 0.3880\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3378 - mae: 0.3923\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3248 - mae: 0.3901\n528/528 [==============================] - 0s 786us/step - loss: 0.3348 - mae: 0.3913 - val_loss: 0.3454 - val_mae: 0.4160\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1657 - mae: 0.3065\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.2718 - mae: 0.3706\n171/528 [========&gt;.....................] - ETA: 0s - loss: 0.2904 - mae: 0.3824\n257/528 [=============&gt;................] - ETA: 0s - loss: 0.2983 - mae: 0.3862\n341/528 [==================&gt;...........] - ETA: 0s - loss: 0.3338 - mae: 0.3923\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3282 - mae: 0.3911\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3258 - mae: 0.3915\n528/528 [==============================] - 0s 806us/step - loss: 0.3340 - mae: 0.3926 - val_loss: 0.3429 - val_mae: 0.4107\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1448 - mae: 0.2595\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.2422 - mae: 0.3598\n143/528 [=======&gt;......................] - ETA: 0s - loss: 0.3167 - mae: 0.3835\n225/528 [===========&gt;..................] - ETA: 0s - loss: 0.3118 - mae: 0.3861\n309/528 [================&gt;.............] - ETA: 0s - loss: 0.3204 - mae: 0.3887\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3125 - mae: 0.3895\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3294 - mae: 0.3913\n528/528 [==============================] - 0s 825us/step - loss: 0.3339 - mae: 0.3909 - val_loss: 0.3439 - val_mae: 0.4055\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.9397 - mae: 0.6478\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3438 - mae: 0.3840\n173/528 [========&gt;.....................] - ETA: 0s - loss: 0.3441 - mae: 0.3925\n259/528 [=============&gt;................] - ETA: 0s - loss: 0.3328 - mae: 0.3935\n345/528 [==================&gt;...........] - ETA: 0s - loss: 0.3315 - mae: 0.3926\n430/528 [=======================&gt;......] - ETA: 0s - loss: 0.3523 - mae: 0.3939\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3375 - mae: 0.3910\n528/528 [==============================] - 0s 785us/step - loss: 0.3352 - mae: 0.3906 - val_loss: 0.3424 - val_mae: 0.4014\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1988 - mae: 0.3831\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2623 - mae: 0.3785\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.2867 - mae: 0.3803\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.2991 - mae: 0.3842\n341/528 [==================&gt;...........] - ETA: 0s - loss: 0.3031 - mae: 0.3825\n427/528 [=======================&gt;......] - ETA: 0s - loss: 0.3123 - mae: 0.3853\n513/528 [============================&gt;.] - ETA: 0s - loss: 0.3292 - mae: 0.3891\n528/528 [==============================] - 0s 810us/step - loss: 0.3325 - mae: 0.3906 - val_loss: 0.3403 - val_mae: 0.4091\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2380 - mae: 0.4252\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3800 - mae: 0.3932\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.4076 - mae: 0.3942\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3581 - mae: 0.3891\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3426 - mae: 0.3847\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3469 - mae: 0.3908\n511/528 [============================&gt;.] - ETA: 0s - loss: 0.3353 - mae: 0.3909\n528/528 [==============================] - 0s 788us/step - loss: 0.3341 - mae: 0.3907 - val_loss: 0.3486 - val_mae: 0.4050\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3099 - mae: 0.3908\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2935 - mae: 0.3870\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3372 - mae: 0.3910\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3229 - mae: 0.3896\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.3469 - mae: 0.3936\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3310 - mae: 0.3902\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3387 - mae: 0.3912\n528/528 [==============================] - 0s 805us/step - loss: 0.3364 - mae: 0.3916 - val_loss: 0.3448 - val_mae: 0.4107\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2408 - mae: 0.3706\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.4147 - mae: 0.3996\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3544 - mae: 0.3939\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3665 - mae: 0.3964\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3569 - mae: 0.4004\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3486 - mae: 0.3952\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3360 - mae: 0.3912\n528/528 [==============================] - 0s 810us/step - loss: 0.3314 - mae: 0.3902 - val_loss: 0.3428 - val_mae: 0.4001\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5680 - mae: 0.6168\n 86/528 [===&gt;..........................] - ETA: 0s - loss: 0.2619 - mae: 0.3740\n172/528 [========&gt;.....................] - ETA: 0s - loss: 0.2902 - mae: 0.3781\n258/528 [=============&gt;................] - ETA: 0s - loss: 0.3183 - mae: 0.3842\n345/528 [==================&gt;...........] - ETA: 0s - loss: 0.3324 - mae: 0.3858\n429/528 [=======================&gt;......] - ETA: 0s - loss: 0.3254 - mae: 0.3852\n512/528 [============================&gt;.] - ETA: 0s - loss: 0.3358 - mae: 0.3896\n528/528 [==============================] - 0s 803us/step - loss: 0.3347 - mae: 0.3896 - val_loss: 0.3415 - val_mae: 0.4009\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1828 - mae: 0.3333\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3598 - mae: 0.3943\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3210 - mae: 0.3925\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3750 - mae: 0.4019\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3616 - mae: 0.3968\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3558 - mae: 0.3940\n491/528 [==========================&gt;...] - ETA: 0s - loss: 0.3451 - mae: 0.3930\n528/528 [==============================] - 0s 826us/step - loss: 0.3354 - mae: 0.3906 - val_loss: 0.3340 - val_mae: 0.3964\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1777 - mae: 0.3792\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3091 - mae: 0.3698\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3542 - mae: 0.3905\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3285 - mae: 0.3900\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3278 - mae: 0.3888\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3384 - mae: 0.3888\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3356 - mae: 0.3902\n528/528 [==============================] - 0s 804us/step - loss: 0.3350 - mae: 0.3910 - val_loss: 0.3489 - val_mae: 0.4019\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0970 - mae: 0.2744\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2515 - mae: 0.3734\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3029 - mae: 0.3853\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3124 - mae: 0.3865\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3281 - mae: 0.3912\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3245 - mae: 0.3893\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3157 - mae: 0.3883\n528/528 [==============================] - 0s 791us/step - loss: 0.3308 - mae: 0.3905 - val_loss: 0.3493 - val_mae: 0.4086\nProcessing fold # 4 \nEpoch 1/100\n\n  1/528 [..............................] - ETA: 0s - loss: 124.8734 - mae: 11.1679\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 42.2848 - mae: 5.4251  \n156/528 [=======&gt;......................] - ETA: 0s - loss: 21.6622 - mae: 3.2510\n242/528 [============&gt;.................] - ETA: 0s - loss: 14.4444 - mae: 2.3739\n327/528 [=================&gt;............] - ETA: 0s - loss: 10.9027 - mae: 1.9229\n412/528 [======================&gt;.......] - ETA: 0s - loss: 8.7732 - mae: 1.6360 \n495/528 [===========================&gt;..] - ETA: 0s - loss: 7.3819 - mae: 1.4446\n528/528 [==============================] - 1s 982us/step - loss: 6.9446 - mae: 1.3841 - val_loss: 0.4743 - val_mae: 0.4925\nEpoch 2/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6499 - mae: 0.5818\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.5470 - mae: 0.4864\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.4255 - mae: 0.4554\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.4249 - mae: 0.4528\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.4160 - mae: 0.4524\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.4286 - mae: 0.4509\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.4159 - mae: 0.4481\n528/528 [==============================] - 0s 810us/step - loss: 0.4208 - mae: 0.4493 - val_loss: 0.3797 - val_mae: 0.4354\nEpoch 3/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.0320 - mae: 0.7123\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3645 - mae: 0.4240\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3983 - mae: 0.4376\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3767 - mae: 0.4341\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3816 - mae: 0.4323\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3907 - mae: 0.4349\n481/528 [==========================&gt;...] - ETA: 0s - loss: 0.3911 - mae: 0.4362\n528/528 [==============================] - 0s 834us/step - loss: 0.3865 - mae: 0.4344 - val_loss: 0.5789 - val_mae: 0.5972\nEpoch 4/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.8259 - mae: 0.6990\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4929 - mae: 0.4480\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.4338 - mae: 0.4359\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3935 - mae: 0.4317\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.4075 - mae: 0.4347\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3842 - mae: 0.4293\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3823 - mae: 0.4272\n528/528 [==============================] - 0s 813us/step - loss: 0.3808 - mae: 0.4273 - val_loss: 0.3826 - val_mae: 0.4324\nEpoch 5/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3272 - mae: 0.4140\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4005 - mae: 0.4384\n170/528 [========&gt;.....................] - ETA: 0s - loss: 0.4182 - mae: 0.4337\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3737 - mae: 0.4256\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3551 - mae: 0.4240\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3436 - mae: 0.4210\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3825 - mae: 0.4271\n528/528 [==============================] - 0s 797us/step - loss: 0.3768 - mae: 0.4253 - val_loss: 0.5195 - val_mae: 0.5568\nEpoch 6/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4911 - mae: 0.5750\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2794 - mae: 0.3980\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3166 - mae: 0.4119\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3601 - mae: 0.4196\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3630 - mae: 0.4230\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3778 - mae: 0.4236\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3750 - mae: 0.4220\n528/528 [==============================] - 0s 811us/step - loss: 0.3716 - mae: 0.4215 - val_loss: 0.3617 - val_mae: 0.4182\nEpoch 7/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1885 - mae: 0.3732\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.4480 - mae: 0.4301\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.4199 - mae: 0.4278\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3751 - mae: 0.4152\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3797 - mae: 0.4188\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3764 - mae: 0.4173\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3635 - mae: 0.4154\n528/528 [==============================] - 0s 801us/step - loss: 0.3666 - mae: 0.4167 - val_loss: 0.3314 - val_mae: 0.3948\nEpoch 8/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4323 - mae: 0.5691\n 70/528 [==&gt;...........................] - ETA: 0s - loss: 0.2853 - mae: 0.4016\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3762 - mae: 0.4156\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3527 - mae: 0.4164\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3445 - mae: 0.4130\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3625 - mae: 0.4152\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3595 - mae: 0.4163\n528/528 [==============================] - 0s 810us/step - loss: 0.3658 - mae: 0.4166 - val_loss: 0.3647 - val_mae: 0.4189\nEpoch 9/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1270 - mae: 0.2750\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4004 - mae: 0.4175\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.4021 - mae: 0.4114\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3807 - mae: 0.4155\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3758 - mae: 0.4150\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3750 - mae: 0.4157\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3637 - mae: 0.4168\n528/528 [==============================] - 0s 804us/step - loss: 0.3663 - mae: 0.4180 - val_loss: 0.3431 - val_mae: 0.4101\nEpoch 10/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1040 - mae: 0.2721\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3695 - mae: 0.4194\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3818 - mae: 0.4185\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.4080 - mae: 0.4236\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3763 - mae: 0.4170\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3777 - mae: 0.4175\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3617 - mae: 0.4143\n528/528 [==============================] - 0s 808us/step - loss: 0.3642 - mae: 0.4164 - val_loss: 0.4245 - val_mae: 0.4638\nEpoch 11/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5229 - mae: 0.5547\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.3603 - mae: 0.4012\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3959 - mae: 0.4129\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.4076 - mae: 0.4156\n323/528 [=================&gt;............] - ETA: 0s - loss: 0.3832 - mae: 0.4125\n381/528 [====================&gt;.........] - ETA: 0s - loss: 0.3800 - mae: 0.4133\n449/528 [========================&gt;.....] - ETA: 0s - loss: 0.3793 - mae: 0.4175\n528/528 [==============================] - 0s 862us/step - loss: 0.3633 - mae: 0.4150 - val_loss: 0.3435 - val_mae: 0.4020\nEpoch 12/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1835 - mae: 0.3373\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3849 - mae: 0.4158\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3395 - mae: 0.4074\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3269 - mae: 0.4069\n340/528 [==================&gt;...........] - ETA: 0s - loss: 0.3782 - mae: 0.4158\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3646 - mae: 0.4159\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3524 - mae: 0.4133\n528/528 [==============================] - 0s 813us/step - loss: 0.3618 - mae: 0.4151 - val_loss: 0.3351 - val_mae: 0.3980\nEpoch 13/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2875 - mae: 0.4251\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3621 - mae: 0.4202\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3733 - mae: 0.4185\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3776 - mae: 0.4149\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3544 - mae: 0.4094\n410/528 [======================&gt;.......] - ETA: 0s - loss: 0.3564 - mae: 0.4108\n494/528 [===========================&gt;..] - ETA: 0s - loss: 0.3579 - mae: 0.4117\n528/528 [==============================] - 0s 821us/step - loss: 0.3575 - mae: 0.4126 - val_loss: 0.3355 - val_mae: 0.3983\nEpoch 14/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1994 - mae: 0.3483\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.4072 - mae: 0.4210\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3662 - mae: 0.4158\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3771 - mae: 0.4167\n341/528 [==================&gt;...........] - ETA: 0s - loss: 0.3617 - mae: 0.4162\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3784 - mae: 0.4183\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3644 - mae: 0.4165\n528/528 [==============================] - 0s 794us/step - loss: 0.3592 - mae: 0.4145 - val_loss: 0.3355 - val_mae: 0.4077\nEpoch 15/100\n\n  1/528 [..............................] - ETA: 0s - loss: 6.2996 - mae: 1.0529\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3748 - mae: 0.4103\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3540 - mae: 0.4093\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3951 - mae: 0.4200\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3771 - mae: 0.4197\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3780 - mae: 0.4165\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3627 - mae: 0.4145\n528/528 [==============================] - 0s 810us/step - loss: 0.3577 - mae: 0.4134 - val_loss: 0.3919 - val_mae: 0.4367\nEpoch 16/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4836 - mae: 0.5148\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3878 - mae: 0.4186\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.4460 - mae: 0.4285\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3935 - mae: 0.4190\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3792 - mae: 0.4159\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3759 - mae: 0.4146\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3606 - mae: 0.4119\n528/528 [==============================] - 0s 805us/step - loss: 0.3564 - mae: 0.4122 - val_loss: 0.3455 - val_mae: 0.4158\nEpoch 17/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1550 - mae: 0.3339\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3715 - mae: 0.4063\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3499 - mae: 0.4095\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3557 - mae: 0.4125\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3540 - mae: 0.4112\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3352 - mae: 0.4058\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3554 - mae: 0.4124\n528/528 [==============================] - 0s 828us/step - loss: 0.3596 - mae: 0.4120 - val_loss: 0.3237 - val_mae: 0.3910\nEpoch 18/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1870 - mae: 0.3478\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2907 - mae: 0.3951\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3130 - mae: 0.3936\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3280 - mae: 0.4084\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3247 - mae: 0.4075\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3320 - mae: 0.4099\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3511 - mae: 0.4131\n528/528 [==============================] - 0s 807us/step - loss: 0.3594 - mae: 0.4135 - val_loss: 0.3729 - val_mae: 0.4476\nEpoch 19/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3216 - mae: 0.4913\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.3203 - mae: 0.4091\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.4196 - mae: 0.4203\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3793 - mae: 0.4158\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3611 - mae: 0.4119\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3530 - mae: 0.4076\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3551 - mae: 0.4100\n528/528 [==============================] - 0s 812us/step - loss: 0.3530 - mae: 0.4092 - val_loss: 0.3305 - val_mae: 0.3991\nEpoch 20/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2323 - mae: 0.3719\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3857 - mae: 0.4201\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3734 - mae: 0.4104\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3378 - mae: 0.4030\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3432 - mae: 0.4051\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3476 - mae: 0.4069\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3587 - mae: 0.4105\n528/528 [==============================] - 0s 800us/step - loss: 0.3558 - mae: 0.4098 - val_loss: 0.3580 - val_mae: 0.4286\nEpoch 21/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2666 - mae: 0.4410\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3356 - mae: 0.3937\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3228 - mae: 0.3985\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3821 - mae: 0.4082\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3636 - mae: 0.4052\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3493 - mae: 0.4040\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3563 - mae: 0.4061\n528/528 [==============================] - 0s 794us/step - loss: 0.3529 - mae: 0.4065 - val_loss: 0.5238 - val_mae: 0.5368\nEpoch 22/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4493 - mae: 0.5240\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.4300 - mae: 0.4348\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.4155 - mae: 0.4245\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3877 - mae: 0.4218\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3847 - mae: 0.4209\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3721 - mae: 0.4155\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3563 - mae: 0.4115\n528/528 [==============================] - 0s 843us/step - loss: 0.3515 - mae: 0.4100 - val_loss: 0.3284 - val_mae: 0.3932\nEpoch 23/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2057 - mae: 0.3511\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3174 - mae: 0.3871\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3100 - mae: 0.3964\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3246 - mae: 0.4011\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3355 - mae: 0.4031\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3543 - mae: 0.4055\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3547 - mae: 0.4073\n528/528 [==============================] - 0s 805us/step - loss: 0.3548 - mae: 0.4088 - val_loss: 0.3518 - val_mae: 0.4092\nEpoch 24/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2416 - mae: 0.4137\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.4203 - mae: 0.4131\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.4080 - mae: 0.4187\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3861 - mae: 0.4150\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3827 - mae: 0.4152\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3773 - mae: 0.4138\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3571 - mae: 0.4096\n528/528 [==============================] - 0s 801us/step - loss: 0.3534 - mae: 0.4082 - val_loss: 0.3320 - val_mae: 0.4001\nEpoch 25/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1575 - mae: 0.3167\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2986 - mae: 0.4006\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3310 - mae: 0.4052\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3192 - mae: 0.4032\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3330 - mae: 0.4054\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3678 - mae: 0.4100\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3565 - mae: 0.4079\n528/528 [==============================] - 0s 855us/step - loss: 0.3496 - mae: 0.4065 - val_loss: 0.3264 - val_mae: 0.4002\nEpoch 26/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1884 - mae: 0.3474\n 60/528 [==&gt;...........................] - ETA: 0s - loss: 0.2852 - mae: 0.3936\n116/528 [=====&gt;........................] - ETA: 0s - loss: 0.2928 - mae: 0.3990\n190/528 [=========&gt;....................] - ETA: 0s - loss: 0.3943 - mae: 0.4160\n272/528 [==============&gt;...............] - ETA: 0s - loss: 0.3653 - mae: 0.4108\n357/528 [===================&gt;..........] - ETA: 0s - loss: 0.3463 - mae: 0.4060\n438/528 [=======================&gt;......] - ETA: 0s - loss: 0.3370 - mae: 0.4027\n522/528 [============================&gt;.] - ETA: 0s - loss: 0.3489 - mae: 0.4049\n528/528 [==============================] - 0s 880us/step - loss: 0.3516 - mae: 0.4062 - val_loss: 0.3500 - val_mae: 0.4118\nEpoch 27/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2201 - mae: 0.3538\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3225 - mae: 0.4007\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3053 - mae: 0.3972\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3175 - mae: 0.4024\n328/528 [=================&gt;............] - ETA: 0s - loss: 0.3719 - mae: 0.4054\n391/528 [=====================&gt;........] - ETA: 0s - loss: 0.3617 - mae: 0.4031\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3546 - mae: 0.4051\n528/528 [==============================] - 0s 841us/step - loss: 0.3502 - mae: 0.4062 - val_loss: 0.3284 - val_mae: 0.3983\nEpoch 28/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.6049 - mae: 0.4877\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3755 - mae: 0.3920\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3742 - mae: 0.4066\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3432 - mae: 0.4021\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3411 - mae: 0.4017\n364/528 [===================&gt;..........] - ETA: 0s - loss: 0.3333 - mae: 0.4024\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3410 - mae: 0.4033\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3280 - mae: 0.4006\n528/528 [==============================] - 1s 993us/step - loss: 0.3468 - mae: 0.4040 - val_loss: 0.3269 - val_mae: 0.3945\nEpoch 29/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3010 - mae: 0.4253\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.2660 - mae: 0.4019\n149/528 [=======&gt;......................] - ETA: 0s - loss: 0.3547 - mae: 0.4145\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.3512 - mae: 0.4144\n302/528 [================&gt;.............] - ETA: 0s - loss: 0.3831 - mae: 0.4132\n380/528 [====================&gt;.........] - ETA: 0s - loss: 0.3687 - mae: 0.4123\n460/528 [=========================&gt;....] - ETA: 0s - loss: 0.3444 - mae: 0.4053\n528/528 [==============================] - 0s 863us/step - loss: 0.3486 - mae: 0.4044 - val_loss: 0.3331 - val_mae: 0.4031\nEpoch 30/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1297 - mae: 0.3194\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3345 - mae: 0.4128\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3691 - mae: 0.4096\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3487 - mae: 0.4039\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3240 - mae: 0.3983\n418/528 [======================&gt;.......] - ETA: 0s - loss: 0.3423 - mae: 0.4014\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3374 - mae: 0.4033\n528/528 [==============================] - 0s 830us/step - loss: 0.3499 - mae: 0.4051 - val_loss: 0.3406 - val_mae: 0.4092\nEpoch 31/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.8375 - mae: 0.5971\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.4029 - mae: 0.4185\n132/528 [======&gt;.......................] - ETA: 0s - loss: 0.3892 - mae: 0.4117\n198/528 [==========&gt;...................] - ETA: 0s - loss: 0.3557 - mae: 0.4051\n285/528 [===============&gt;..............] - ETA: 0s - loss: 0.3942 - mae: 0.4077\n368/528 [===================&gt;..........] - ETA: 0s - loss: 0.3618 - mae: 0.3998\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3551 - mae: 0.4014\n528/528 [==============================] - 0s 848us/step - loss: 0.3485 - mae: 0.4027 - val_loss: 0.3657 - val_mae: 0.4197\nEpoch 32/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3944 - mae: 0.5398\n 76/528 [===&gt;..........................] - ETA: 0s - loss: 0.2545 - mae: 0.3904\n158/528 [=======&gt;......................] - ETA: 0s - loss: 0.2590 - mae: 0.3883\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.2870 - mae: 0.3992\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3030 - mae: 0.4013\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3250 - mae: 0.4004\n474/528 [=========================&gt;....] - ETA: 0s - loss: 0.3534 - mae: 0.4077\n528/528 [==============================] - 0s 834us/step - loss: 0.3464 - mae: 0.4062 - val_loss: 0.3405 - val_mae: 0.4110\nEpoch 33/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2023 - mae: 0.3507\n 72/528 [===&gt;..........................] - ETA: 0s - loss: 0.4256 - mae: 0.4139\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3900 - mae: 0.4106\n221/528 [===========&gt;..................] - ETA: 0s - loss: 0.3961 - mae: 0.4067\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3802 - mae: 0.4074\n390/528 [=====================&gt;........] - ETA: 0s - loss: 0.3575 - mae: 0.4039\n476/528 [==========================&gt;...] - ETA: 0s - loss: 0.3471 - mae: 0.4023\n528/528 [==============================] - 0s 838us/step - loss: 0.3493 - mae: 0.4038 - val_loss: 0.4467 - val_mae: 0.5091\nEpoch 34/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3251 - mae: 0.4047\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3918 - mae: 0.4128\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3548 - mae: 0.4012\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3451 - mae: 0.4012\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3649 - mae: 0.4046\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3579 - mae: 0.4051\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3489 - mae: 0.4030\n528/528 [==============================] - 0s 803us/step - loss: 0.3454 - mae: 0.4019 - val_loss: 0.3313 - val_mae: 0.3951\nEpoch 35/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1800 - mae: 0.3608\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2708 - mae: 0.3918\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3166 - mae: 0.4022\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3397 - mae: 0.4057\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3202 - mae: 0.3995\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3274 - mae: 0.3997\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3300 - mae: 0.4004\n528/528 [==============================] - 0s 813us/step - loss: 0.3442 - mae: 0.4029 - val_loss: 0.3638 - val_mae: 0.4160\nEpoch 36/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1366 - mae: 0.2439\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2965 - mae: 0.3960\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3051 - mae: 0.4016\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.2921 - mae: 0.3981\n327/528 [=================&gt;............] - ETA: 0s - loss: 0.2969 - mae: 0.4010\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3240 - mae: 0.4040\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3509 - mae: 0.4051\n528/528 [==============================] - 0s 824us/step - loss: 0.3474 - mae: 0.4045 - val_loss: 0.3515 - val_mae: 0.4301\nEpoch 37/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1732 - mae: 0.3193\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2825 - mae: 0.3960\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2837 - mae: 0.3887\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3162 - mae: 0.3928\n326/528 [=================&gt;............] - ETA: 0s - loss: 0.3544 - mae: 0.3975\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3574 - mae: 0.4008\n491/528 [==========================&gt;...] - ETA: 0s - loss: 0.3481 - mae: 0.4027\n528/528 [==============================] - 0s 830us/step - loss: 0.3445 - mae: 0.4019 - val_loss: 0.3454 - val_mae: 0.4105\nEpoch 38/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1058 - mae: 0.2585\n 85/528 [===&gt;..........................] - ETA: 0s - loss: 0.3581 - mae: 0.4018\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3383 - mae: 0.3972\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3587 - mae: 0.4049\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3412 - mae: 0.4033\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3507 - mae: 0.4021\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3477 - mae: 0.4024\n528/528 [==============================] - 0s 796us/step - loss: 0.3456 - mae: 0.4025 - val_loss: 0.4174 - val_mae: 0.4796\nEpoch 39/100\n\n  1/528 [..............................] - ETA: 0s - loss: 4.2359 - mae: 0.7980\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3074 - mae: 0.3892\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.2919 - mae: 0.3938\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3479 - mae: 0.4052\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3601 - mae: 0.4065\n409/528 [======================&gt;.......] - ETA: 0s - loss: 0.3446 - mae: 0.4042\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3484 - mae: 0.4066\n528/528 [==============================] - 0s 807us/step - loss: 0.3423 - mae: 0.4050 - val_loss: 0.3356 - val_mae: 0.4044\nEpoch 40/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1014 - mae: 0.2712\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.4025 - mae: 0.4079\n159/528 [========&gt;.....................] - ETA: 0s - loss: 0.3808 - mae: 0.4062\n240/528 [============&gt;.................] - ETA: 0s - loss: 0.3769 - mae: 0.4082\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3537 - mae: 0.4057\n408/528 [======================&gt;.......] - ETA: 0s - loss: 0.3414 - mae: 0.4027\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3490 - mae: 0.4020\n528/528 [==============================] - 0s 830us/step - loss: 0.3445 - mae: 0.4012 - val_loss: 0.3278 - val_mae: 0.3956\nEpoch 41/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2995 - mae: 0.4282\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2879 - mae: 0.3895\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.2891 - mae: 0.3909\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3034 - mae: 0.3931\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3265 - mae: 0.3999\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3397 - mae: 0.4007\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3375 - mae: 0.4004\n528/528 [==============================] - 0s 801us/step - loss: 0.3451 - mae: 0.4009 - val_loss: 0.3525 - val_mae: 0.4132\nEpoch 42/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3213 - mae: 0.4187\n 66/528 [==&gt;...........................] - ETA: 0s - loss: 0.2769 - mae: 0.3850\n150/528 [=======&gt;......................] - ETA: 0s - loss: 0.3248 - mae: 0.3953\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3682 - mae: 0.3992\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3575 - mae: 0.4010\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3620 - mae: 0.4026\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3489 - mae: 0.4015\n528/528 [==============================] - 0s 837us/step - loss: 0.3449 - mae: 0.4030 - val_loss: 0.3509 - val_mae: 0.4205\nEpoch 43/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2898 - mae: 0.4004\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3832 - mae: 0.4121\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3158 - mae: 0.3964\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3206 - mae: 0.3986\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3406 - mae: 0.3978\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3464 - mae: 0.4030\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3453 - mae: 0.4002\n528/528 [==============================] - 0s 804us/step - loss: 0.3429 - mae: 0.4005 - val_loss: 0.3481 - val_mae: 0.4029\nEpoch 44/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0472 - mae: 0.1966\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3488 - mae: 0.4028\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.4291 - mae: 0.4187\n256/528 [=============&gt;................] - ETA: 0s - loss: 0.4067 - mae: 0.4117\n342/528 [==================&gt;...........] - ETA: 0s - loss: 0.3741 - mae: 0.4041\n430/528 [=======================&gt;......] - ETA: 0s - loss: 0.3578 - mae: 0.4026\n516/528 [============================&gt;.] - ETA: 0s - loss: 0.3405 - mae: 0.4004\n528/528 [==============================] - 0s 792us/step - loss: 0.3443 - mae: 0.4010 - val_loss: 0.3366 - val_mae: 0.3976\nEpoch 45/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2744 - mae: 0.4004\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.2872 - mae: 0.3812\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3121 - mae: 0.3895\n255/528 [=============&gt;................] - ETA: 0s - loss: 0.3505 - mae: 0.3986\n342/528 [==================&gt;...........] - ETA: 0s - loss: 0.3364 - mae: 0.3971\n425/528 [=======================&gt;......] - ETA: 0s - loss: 0.3437 - mae: 0.3997\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3453 - mae: 0.4003\n528/528 [==============================] - 0s 800us/step - loss: 0.3423 - mae: 0.4001 - val_loss: 0.3343 - val_mae: 0.3968\nEpoch 46/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2845 - mae: 0.3629\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2553 - mae: 0.3880\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3167 - mae: 0.3998\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3458 - mae: 0.4018\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3394 - mae: 0.3988\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3346 - mae: 0.3978\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3414 - mae: 0.3984\n528/528 [==============================] - 0s 814us/step - loss: 0.3400 - mae: 0.3994 - val_loss: 0.3590 - val_mae: 0.4126\nEpoch 47/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1667 - mae: 0.3370\n 88/528 [====&gt;.........................] - ETA: 0s - loss: 0.2755 - mae: 0.3890\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3225 - mae: 0.3956\n234/528 [============&gt;.................] - ETA: 0s - loss: 0.3259 - mae: 0.3976\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3258 - mae: 0.3962\n403/528 [=====================&gt;........] - ETA: 0s - loss: 0.3287 - mae: 0.3956\n480/528 [==========================&gt;...] - ETA: 0s - loss: 0.3417 - mae: 0.3991\n528/528 [==============================] - 0s 856us/step - loss: 0.3427 - mae: 0.3981 - val_loss: 0.3312 - val_mae: 0.3980\nEpoch 48/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1381 - mae: 0.3051\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3672 - mae: 0.4004\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3545 - mae: 0.4004\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3619 - mae: 0.4046\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3445 - mae: 0.4028\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3209 - mae: 0.3952\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3404 - mae: 0.3980\n528/528 [==============================] - 0s 792us/step - loss: 0.3412 - mae: 0.3987 - val_loss: 0.5056 - val_mae: 0.5507\nEpoch 49/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3826 - mae: 0.5532\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3449 - mae: 0.4027\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3211 - mae: 0.3997\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3425 - mae: 0.4043\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3265 - mae: 0.3994\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3385 - mae: 0.4013\n502/528 [===========================&gt;..] - ETA: 0s - loss: 0.3356 - mae: 0.3997\n528/528 [==============================] - 0s 798us/step - loss: 0.3425 - mae: 0.4003 - val_loss: 0.3399 - val_mae: 0.3972\nEpoch 50/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1881 - mae: 0.3460\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3163 - mae: 0.3792\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3439 - mae: 0.4002\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3236 - mae: 0.3969\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3252 - mae: 0.3969\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3241 - mae: 0.3992\n496/528 [===========================&gt;..] - ETA: 0s - loss: 0.3492 - mae: 0.4014\n528/528 [==============================] - 0s 811us/step - loss: 0.3426 - mae: 0.4001 - val_loss: 0.3519 - val_mae: 0.4228\nEpoch 51/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1327 - mae: 0.2544\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.4297 - mae: 0.4172\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3380 - mae: 0.3960\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3541 - mae: 0.3996\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3511 - mae: 0.4007\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3576 - mae: 0.4043\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3477 - mae: 0.4028\n528/528 [==============================] - 0s 839us/step - loss: 0.3429 - mae: 0.4019 - val_loss: 0.3317 - val_mae: 0.3929\nEpoch 52/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2538 - mae: 0.4223\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3700 - mae: 0.4062\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3310 - mae: 0.3982\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3775 - mae: 0.4044\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3752 - mae: 0.4035\n413/528 [======================&gt;.......] - ETA: 0s - loss: 0.3528 - mae: 0.3975\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3409 - mae: 0.3946\n528/528 [==============================] - 0s 804us/step - loss: 0.3415 - mae: 0.3949 - val_loss: 0.3634 - val_mae: 0.4268\nEpoch 53/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1692 - mae: 0.3410\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3200 - mae: 0.4055\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.2961 - mae: 0.3996\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.2936 - mae: 0.3944\n329/528 [=================&gt;............] - ETA: 0s - loss: 0.2855 - mae: 0.3883\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.2980 - mae: 0.3928\n495/528 [===========================&gt;..] - ETA: 0s - loss: 0.3198 - mae: 0.3949\n528/528 [==============================] - 0s 816us/step - loss: 0.3407 - mae: 0.3975 - val_loss: 0.3691 - val_mae: 0.4364\nEpoch 54/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2283 - mae: 0.3521\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3525 - mae: 0.4015\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.3231 - mae: 0.3924\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3355 - mae: 0.3971\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3403 - mae: 0.3935\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3378 - mae: 0.3960\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3453 - mae: 0.3992\n528/528 [==============================] - 0s 801us/step - loss: 0.3446 - mae: 0.3997 - val_loss: 0.3665 - val_mae: 0.4135\nEpoch 55/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2462 - mae: 0.4071\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3103 - mae: 0.4007\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3625 - mae: 0.4025\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3544 - mae: 0.4052\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3457 - mae: 0.4028\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3579 - mae: 0.4023\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3448 - mae: 0.4001\n528/528 [==============================] - 0s 807us/step - loss: 0.3421 - mae: 0.3984 - val_loss: 0.3702 - val_mae: 0.4387\nEpoch 56/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1865 - mae: 0.3771\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.2440 - mae: 0.3668\n169/528 [========&gt;.....................] - ETA: 0s - loss: 0.2708 - mae: 0.3819\n254/528 [=============&gt;................] - ETA: 0s - loss: 0.3177 - mae: 0.3958\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3239 - mae: 0.3978\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3567 - mae: 0.4014\n487/528 [==========================&gt;...] - ETA: 0s - loss: 0.3441 - mae: 0.3988\n528/528 [==============================] - 0s 825us/step - loss: 0.3406 - mae: 0.3981 - val_loss: 0.3279 - val_mae: 0.3986\nEpoch 57/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1337 - mae: 0.2793\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.3412 - mae: 0.3916\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.3277 - mae: 0.3869\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3447 - mae: 0.3938\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3376 - mae: 0.3925\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3310 - mae: 0.3948\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3453 - mae: 0.3995\n528/528 [==============================] - 0s 803us/step - loss: 0.3424 - mae: 0.3989 - val_loss: 0.3602 - val_mae: 0.4307\nEpoch 58/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2636 - mae: 0.3828\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3664 - mae: 0.4019\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3179 - mae: 0.3912\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3020 - mae: 0.3898\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3267 - mae: 0.3972\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3311 - mae: 0.3964\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3342 - mae: 0.3963\n528/528 [==============================] - 0s 806us/step - loss: 0.3394 - mae: 0.3961 - val_loss: 0.3359 - val_mae: 0.3948\nEpoch 59/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2525 - mae: 0.3932\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3647 - mae: 0.4074\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3770 - mae: 0.4000\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3682 - mae: 0.4018\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3538 - mae: 0.4006\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3433 - mae: 0.3995\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3442 - mae: 0.3957\n528/528 [==============================] - 0s 798us/step - loss: 0.3407 - mae: 0.3951 - val_loss: 0.3696 - val_mae: 0.4288\nEpoch 60/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2479 - mae: 0.4528\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3104 - mae: 0.3890\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3080 - mae: 0.3939\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3013 - mae: 0.3945\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3228 - mae: 0.3946\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3131 - mae: 0.3934\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3431 - mae: 0.3975\n528/528 [==============================] - 0s 796us/step - loss: 0.3415 - mae: 0.3969 - val_loss: 0.3475 - val_mae: 0.4129\nEpoch 61/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2279 - mae: 0.3898\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3659 - mae: 0.3981\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3157 - mae: 0.3864\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3199 - mae: 0.3869\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3114 - mae: 0.3883\n398/528 [=====================&gt;........] - ETA: 0s - loss: 0.3242 - mae: 0.3902\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3191 - mae: 0.3917\n528/528 [==============================] - 0s 813us/step - loss: 0.3419 - mae: 0.3961 - val_loss: 0.3737 - val_mae: 0.4361\nEpoch 62/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.5517 - mae: 0.5979\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3186 - mae: 0.3908\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3495 - mae: 0.4007\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3443 - mae: 0.3969\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3360 - mae: 0.3970\n423/528 [=======================&gt;......] - ETA: 0s - loss: 0.3212 - mae: 0.3935\n505/528 [===========================&gt;..] - ETA: 0s - loss: 0.3427 - mae: 0.3966\n528/528 [==============================] - 0s 805us/step - loss: 0.3391 - mae: 0.3961 - val_loss: 0.3402 - val_mae: 0.4082\nEpoch 63/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2331 - mae: 0.3821\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3423 - mae: 0.4061\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3621 - mae: 0.3937\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3342 - mae: 0.3879\n337/528 [==================&gt;...........] - ETA: 0s - loss: 0.3505 - mae: 0.3934\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3398 - mae: 0.3933\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3381 - mae: 0.3939\n528/528 [==============================] - 0s 801us/step - loss: 0.3389 - mae: 0.3947 - val_loss: 0.3277 - val_mae: 0.3947\nEpoch 64/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3752 - mae: 0.5068\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2854 - mae: 0.3908\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.2836 - mae: 0.3868\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3028 - mae: 0.3909\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3260 - mae: 0.3927\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3258 - mae: 0.3923\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3381 - mae: 0.3942\n528/528 [==============================] - 0s 801us/step - loss: 0.3364 - mae: 0.3943 - val_loss: 0.3747 - val_mae: 0.4415\nEpoch 65/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2198 - mae: 0.3162\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3995 - mae: 0.4146\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3955 - mae: 0.4086\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3573 - mae: 0.4019\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3749 - mae: 0.4061\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3509 - mae: 0.3995\n507/528 [===========================&gt;..] - ETA: 0s - loss: 0.3470 - mae: 0.3998\n528/528 [==============================] - 0s 788us/step - loss: 0.3409 - mae: 0.3975 - val_loss: 0.3310 - val_mae: 0.3920\nEpoch 66/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2837 - mae: 0.4719\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2743 - mae: 0.3871\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.3404 - mae: 0.4029\n243/528 [============&gt;.................] - ETA: 0s - loss: 0.3850 - mae: 0.4037\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3528 - mae: 0.3987\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3545 - mae: 0.3990\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3414 - mae: 0.3962\n528/528 [==============================] - 0s 815us/step - loss: 0.3392 - mae: 0.3963 - val_loss: 0.3520 - val_mae: 0.4056\nEpoch 67/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2105 - mae: 0.3434\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3171 - mae: 0.4001\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3311 - mae: 0.3944\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3555 - mae: 0.3990\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3586 - mae: 0.3997\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3420 - mae: 0.3961\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3462 - mae: 0.3967\n528/528 [==============================] - 0s 803us/step - loss: 0.3414 - mae: 0.3960 - val_loss: 0.3652 - val_mae: 0.4052\nEpoch 68/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3716 - mae: 0.4721\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.3405 - mae: 0.3958\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3368 - mae: 0.3947\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3646 - mae: 0.3973\n332/528 [=================&gt;............] - ETA: 0s - loss: 0.3607 - mae: 0.3974\n414/528 [======================&gt;.......] - ETA: 0s - loss: 0.3508 - mae: 0.3962\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3430 - mae: 0.3960\n528/528 [==============================] - 0s 807us/step - loss: 0.3393 - mae: 0.3960 - val_loss: 0.3505 - val_mae: 0.4035\nEpoch 69/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2232 - mae: 0.3417\n 59/528 [==&gt;...........................] - ETA: 0s - loss: 0.2615 - mae: 0.3765\n141/528 [=======&gt;......................] - ETA: 0s - loss: 0.3260 - mae: 0.3947\n227/528 [===========&gt;..................] - ETA: 0s - loss: 0.3270 - mae: 0.3921\n310/528 [================&gt;.............] - ETA: 0s - loss: 0.3398 - mae: 0.3935\n397/528 [=====================&gt;........] - ETA: 0s - loss: 0.3209 - mae: 0.3900\n482/528 [==========================&gt;...] - ETA: 0s - loss: 0.3204 - mae: 0.3915\n528/528 [==============================] - 0s 826us/step - loss: 0.3351 - mae: 0.3937 - val_loss: 0.3769 - val_mae: 0.4260\nEpoch 70/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2775 - mae: 0.4721\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2767 - mae: 0.3827\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.2722 - mae: 0.3821\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.2789 - mae: 0.3860\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.2996 - mae: 0.3906\n422/528 [======================&gt;.......] - ETA: 0s - loss: 0.3142 - mae: 0.3922\n508/528 [===========================&gt;..] - ETA: 0s - loss: 0.3076 - mae: 0.3905\n528/528 [==============================] - 0s 795us/step - loss: 0.3353 - mae: 0.3940 - val_loss: 0.3444 - val_mae: 0.4144\nEpoch 71/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2542 - mae: 0.3834\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2497 - mae: 0.3764\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.2886 - mae: 0.3879\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3164 - mae: 0.3915\n322/528 [=================&gt;............] - ETA: 0s - loss: 0.3039 - mae: 0.3900\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3275 - mae: 0.3932\n479/528 [==========================&gt;...] - ETA: 0s - loss: 0.3328 - mae: 0.3934\n528/528 [==============================] - 0s 836us/step - loss: 0.3386 - mae: 0.3946 - val_loss: 0.3353 - val_mae: 0.4057\nEpoch 72/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2457 - mae: 0.4135\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4738 - mae: 0.4066\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3927 - mae: 0.4052\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3739 - mae: 0.4051\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3460 - mae: 0.3967\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3536 - mae: 0.3954\n506/528 [===========================&gt;..] - ETA: 0s - loss: 0.3420 - mae: 0.3944\n528/528 [==============================] - 0s 837us/step - loss: 0.3363 - mae: 0.3923 - val_loss: 0.3557 - val_mae: 0.4063\nEpoch 73/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1510 - mae: 0.3051\n 57/528 [==&gt;...........................] - ETA: 0s - loss: 0.3975 - mae: 0.4041\n133/528 [======&gt;.......................] - ETA: 0s - loss: 0.3345 - mae: 0.3885\n216/528 [===========&gt;..................] - ETA: 0s - loss: 0.3276 - mae: 0.3851\n301/528 [================&gt;.............] - ETA: 0s - loss: 0.3344 - mae: 0.3890\n386/528 [====================&gt;.........] - ETA: 0s - loss: 0.3264 - mae: 0.3901\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3296 - mae: 0.3911\n528/528 [==============================] - 0s 841us/step - loss: 0.3362 - mae: 0.3934 - val_loss: 0.3595 - val_mae: 0.4134\nEpoch 74/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2225 - mae: 0.4201\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3067 - mae: 0.3739\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3400 - mae: 0.3898\n228/528 [===========&gt;..................] - ETA: 0s - loss: 0.3135 - mae: 0.3874\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3043 - mae: 0.3875\n394/528 [=====================&gt;........] - ETA: 0s - loss: 0.3419 - mae: 0.3911\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3400 - mae: 0.3938\n528/528 [==============================] - 0s 823us/step - loss: 0.3360 - mae: 0.3931 - val_loss: 0.3292 - val_mae: 0.3948\nEpoch 75/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1148 - mae: 0.2772\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2673 - mae: 0.3711\n157/528 [=======&gt;......................] - ETA: 0s - loss: 0.3107 - mae: 0.3746\n236/528 [============&gt;.................] - ETA: 0s - loss: 0.2889 - mae: 0.3747\n314/528 [================&gt;.............] - ETA: 0s - loss: 0.3113 - mae: 0.3816\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3094 - mae: 0.3847\n466/528 [=========================&gt;....] - ETA: 0s - loss: 0.3272 - mae: 0.3882\n528/528 [==============================] - 0s 851us/step - loss: 0.3353 - mae: 0.3910 - val_loss: 0.3717 - val_mae: 0.4230\nEpoch 76/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1685 - mae: 0.3308\n 63/528 [==&gt;...........................] - ETA: 0s - loss: 0.2840 - mae: 0.3916\n145/528 [=======&gt;......................] - ETA: 0s - loss: 0.3116 - mae: 0.3918\n224/528 [===========&gt;..................] - ETA: 0s - loss: 0.3146 - mae: 0.3969\n305/528 [================&gt;.............] - ETA: 0s - loss: 0.3417 - mae: 0.3978\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3364 - mae: 0.3914\n470/528 [=========================&gt;....] - ETA: 0s - loss: 0.3365 - mae: 0.3956\n528/528 [==============================] - 0s 841us/step - loss: 0.3354 - mae: 0.3940 - val_loss: 0.3352 - val_mae: 0.3985\nEpoch 77/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.0566 - mae: 0.1957\n 75/528 [===&gt;..........................] - ETA: 0s - loss: 0.3603 - mae: 0.3889\n154/528 [=======&gt;......................] - ETA: 0s - loss: 0.3351 - mae: 0.3937\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3330 - mae: 0.3918\n316/528 [================&gt;.............] - ETA: 0s - loss: 0.3558 - mae: 0.3918\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3434 - mae: 0.3933\n483/528 [==========================&gt;...] - ETA: 0s - loss: 0.3492 - mae: 0.3957\n528/528 [==============================] - 0s 823us/step - loss: 0.3390 - mae: 0.3933 - val_loss: 0.3476 - val_mae: 0.4043\nEpoch 78/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1263 - mae: 0.2906\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3916 - mae: 0.3902\n153/528 [=======&gt;......................] - ETA: 0s - loss: 0.3421 - mae: 0.3950\n231/528 [============&gt;.................] - ETA: 0s - loss: 0.3486 - mae: 0.3955\n307/528 [================&gt;.............] - ETA: 0s - loss: 0.3668 - mae: 0.3983\n379/528 [====================&gt;.........] - ETA: 0s - loss: 0.3481 - mae: 0.3965\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3537 - mae: 0.3967\n528/528 [==============================] - 0s 866us/step - loss: 0.3370 - mae: 0.3930 - val_loss: 0.3351 - val_mae: 0.4007\nEpoch 79/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3080 - mae: 0.4295\n 71/528 [===&gt;..........................] - ETA: 0s - loss: 0.2981 - mae: 0.3780\n142/528 [=======&gt;......................] - ETA: 0s - loss: 0.3287 - mae: 0.3907\n217/528 [===========&gt;..................] - ETA: 0s - loss: 0.3144 - mae: 0.3917\n296/528 [===============&gt;..............] - ETA: 0s - loss: 0.3100 - mae: 0.3904\n371/528 [====================&gt;.........] - ETA: 0s - loss: 0.3109 - mae: 0.3910\n454/528 [========================&gt;.....] - ETA: 0s - loss: 0.3353 - mae: 0.3942\n528/528 [==============================] - 0s 861us/step - loss: 0.3394 - mae: 0.3947 - val_loss: 0.3526 - val_mae: 0.4184\nEpoch 80/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2391 - mae: 0.3909\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3391 - mae: 0.3975\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3376 - mae: 0.3905\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3255 - mae: 0.3899\n338/528 [==================&gt;...........] - ETA: 0s - loss: 0.3318 - mae: 0.3910\n420/528 [======================&gt;.......] - ETA: 0s - loss: 0.3359 - mae: 0.3915\n497/528 [===========================&gt;..] - ETA: 0s - loss: 0.3246 - mae: 0.3879\n528/528 [==============================] - 0s 840us/step - loss: 0.3374 - mae: 0.3903 - val_loss: 0.3403 - val_mae: 0.3953\nEpoch 81/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2723 - mae: 0.4415\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3247 - mae: 0.3873\n161/528 [========&gt;.....................] - ETA: 0s - loss: 0.3112 - mae: 0.3877\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.3185 - mae: 0.3882\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3295 - mae: 0.3885\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3251 - mae: 0.3894\n478/528 [==========================&gt;...] - ETA: 0s - loss: 0.3454 - mae: 0.3944\n528/528 [==============================] - 0s 847us/step - loss: 0.3369 - mae: 0.3923 - val_loss: 0.3415 - val_mae: 0.3951\nEpoch 82/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2302 - mae: 0.3768\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.2527 - mae: 0.3793\n146/528 [=======&gt;......................] - ETA: 0s - loss: 0.3109 - mae: 0.3852\n209/528 [==========&gt;...................] - ETA: 0s - loss: 0.2997 - mae: 0.3845\n275/528 [==============&gt;...............] - ETA: 0s - loss: 0.3081 - mae: 0.3831\n345/528 [==================&gt;...........] - ETA: 0s - loss: 0.3052 - mae: 0.3853\n411/528 [======================&gt;.......] - ETA: 0s - loss: 0.3258 - mae: 0.3898\n490/528 [==========================&gt;...] - ETA: 0s - loss: 0.3329 - mae: 0.3900\n528/528 [==============================] - 0s 923us/step - loss: 0.3381 - mae: 0.3909 - val_loss: 0.3586 - val_mae: 0.4218\nEpoch 83/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2114 - mae: 0.3902\n 77/528 [===&gt;..........................] - ETA: 0s - loss: 0.2923 - mae: 0.3965\n160/528 [========&gt;.....................] - ETA: 0s - loss: 0.2630 - mae: 0.3834\n239/528 [============&gt;.................] - ETA: 0s - loss: 0.2869 - mae: 0.3893\n315/528 [================&gt;.............] - ETA: 0s - loss: 0.3074 - mae: 0.3883\n389/528 [=====================&gt;........] - ETA: 0s - loss: 0.3178 - mae: 0.3888\n446/528 [========================&gt;.....] - ETA: 0s - loss: 0.3281 - mae: 0.3903\n509/528 [===========================&gt;..] - ETA: 0s - loss: 0.3402 - mae: 0.3913\n528/528 [==============================] - 0s 891us/step - loss: 0.3377 - mae: 0.3906 - val_loss: 0.3502 - val_mae: 0.4019\nEpoch 84/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2066 - mae: 0.3536\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3763 - mae: 0.3959\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3148 - mae: 0.3855\n244/528 [============&gt;.................] - ETA: 0s - loss: 0.3481 - mae: 0.3929\n317/528 [=================&gt;............] - ETA: 0s - loss: 0.3654 - mae: 0.3978\n393/528 [=====================&gt;........] - ETA: 0s - loss: 0.3462 - mae: 0.3937\n464/528 [=========================&gt;....] - ETA: 0s - loss: 0.3337 - mae: 0.3930\n528/528 [==============================] - 0s 866us/step - loss: 0.3353 - mae: 0.3928 - val_loss: 0.3335 - val_mae: 0.4013\nEpoch 85/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1227 - mae: 0.2889\n 74/528 [===&gt;..........................] - ETA: 0s - loss: 0.3151 - mae: 0.3894\n151/528 [=======&gt;......................] - ETA: 0s - loss: 0.3629 - mae: 0.3977\n229/528 [============&gt;.................] - ETA: 0s - loss: 0.3723 - mae: 0.3986\n304/528 [================&gt;.............] - ETA: 0s - loss: 0.3438 - mae: 0.3925\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3636 - mae: 0.3955\n457/528 [========================&gt;.....] - ETA: 0s - loss: 0.3531 - mae: 0.3961\n528/528 [==============================] - 0s 885us/step - loss: 0.3362 - mae: 0.3923 - val_loss: 0.3295 - val_mae: 0.3947\nEpoch 86/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1417 - mae: 0.3403\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3361 - mae: 0.3951\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3157 - mae: 0.3971\n251/528 [=============&gt;................] - ETA: 0s - loss: 0.3442 - mae: 0.3955\n336/528 [==================&gt;...........] - ETA: 0s - loss: 0.3285 - mae: 0.3938\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3297 - mae: 0.3945\n493/528 [===========================&gt;..] - ETA: 0s - loss: 0.3432 - mae: 0.3951\n528/528 [==============================] - 0s 817us/step - loss: 0.3365 - mae: 0.3927 - val_loss: 0.3497 - val_mae: 0.4130\nEpoch 87/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1125 - mae: 0.2870\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.3689 - mae: 0.3991\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3872 - mae: 0.4042\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3669 - mae: 0.3997\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3434 - mae: 0.3912\n416/528 [======================&gt;.......] - ETA: 0s - loss: 0.3504 - mae: 0.3946\n501/528 [===========================&gt;..] - ETA: 0s - loss: 0.3424 - mae: 0.3943\n528/528 [==============================] - 0s 822us/step - loss: 0.3371 - mae: 0.3928 - val_loss: 0.3771 - val_mae: 0.4164\nEpoch 88/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4488 - mae: 0.4520\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.2643 - mae: 0.3919\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.3715 - mae: 0.4071\n233/528 [============&gt;.................] - ETA: 0s - loss: 0.3397 - mae: 0.4004\n311/528 [================&gt;.............] - ETA: 0s - loss: 0.3644 - mae: 0.3987\n392/528 [=====================&gt;........] - ETA: 0s - loss: 0.3460 - mae: 0.3944\n473/528 [=========================&gt;....] - ETA: 0s - loss: 0.3429 - mae: 0.3916\n528/528 [==============================] - 0s 838us/step - loss: 0.3379 - mae: 0.3907 - val_loss: 0.3449 - val_mae: 0.4113\nEpoch 89/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.3057 - mae: 0.3751\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.2997 - mae: 0.3893\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3637 - mae: 0.3977\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3350 - mae: 0.3932\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3154 - mae: 0.3898\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3527 - mae: 0.3957\n499/528 [===========================&gt;..] - ETA: 0s - loss: 0.3396 - mae: 0.3934\n528/528 [==============================] - 0s 819us/step - loss: 0.3338 - mae: 0.3920 - val_loss: 0.3332 - val_mae: 0.3983\nEpoch 90/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1608 - mae: 0.3118\n 79/528 [===&gt;..........................] - ETA: 0s - loss: 0.2616 - mae: 0.3713\n156/528 [=======&gt;......................] - ETA: 0s - loss: 0.2933 - mae: 0.3796\n238/528 [============&gt;.................] - ETA: 0s - loss: 0.2999 - mae: 0.3801\n319/528 [=================&gt;............] - ETA: 0s - loss: 0.3010 - mae: 0.3833\n401/528 [=====================&gt;........] - ETA: 0s - loss: 0.3063 - mae: 0.3865\n469/528 [=========================&gt;....] - ETA: 0s - loss: 0.3372 - mae: 0.3906\n528/528 [==============================] - 0s 882us/step - loss: 0.3372 - mae: 0.3927 - val_loss: 0.3488 - val_mae: 0.4012\nEpoch 91/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.7779 - mae: 0.5176\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2822 - mae: 0.3786\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3091 - mae: 0.3856\n248/528 [=============&gt;................] - ETA: 0s - loss: 0.3519 - mae: 0.3909\n334/528 [=================&gt;............] - ETA: 0s - loss: 0.3299 - mae: 0.3904\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3405 - mae: 0.3931\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3416 - mae: 0.3931\n528/528 [==============================] - 0s 809us/step - loss: 0.3362 - mae: 0.3918 - val_loss: 0.3522 - val_mae: 0.4128\nEpoch 92/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2209 - mae: 0.3812\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3854 - mae: 0.4027\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3731 - mae: 0.4002\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3336 - mae: 0.3947\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3286 - mae: 0.3943\n382/528 [====================&gt;.........] - ETA: 0s - loss: 0.3302 - mae: 0.3919\n449/528 [========================&gt;.....] - ETA: 0s - loss: 0.3478 - mae: 0.3943\n517/528 [============================&gt;.] - ETA: 0s - loss: 0.3394 - mae: 0.3920\n528/528 [==============================] - 0s 887us/step - loss: 0.3368 - mae: 0.3914 - val_loss: 0.3404 - val_mae: 0.3923\nEpoch 93/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1803 - mae: 0.3292\n 84/528 [===&gt;..........................] - ETA: 0s - loss: 0.3402 - mae: 0.3919\n168/528 [========&gt;.....................] - ETA: 0s - loss: 0.3519 - mae: 0.3922\n252/528 [=============&gt;................] - ETA: 0s - loss: 0.3415 - mae: 0.3883\n335/528 [==================&gt;...........] - ETA: 0s - loss: 0.3237 - mae: 0.3879\n421/528 [======================&gt;.......] - ETA: 0s - loss: 0.3327 - mae: 0.3892\n504/528 [===========================&gt;..] - ETA: 0s - loss: 0.3381 - mae: 0.3897\n528/528 [==============================] - 0s 796us/step - loss: 0.3370 - mae: 0.3900 - val_loss: 0.3411 - val_mae: 0.4023\nEpoch 94/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2625 - mae: 0.4264\n 78/528 [===&gt;..........................] - ETA: 0s - loss: 0.3111 - mae: 0.3865\n162/528 [========&gt;.....................] - ETA: 0s - loss: 0.3232 - mae: 0.3888\n246/528 [============&gt;.................] - ETA: 0s - loss: 0.3413 - mae: 0.3933\n331/528 [=================&gt;............] - ETA: 0s - loss: 0.3658 - mae: 0.3971\n415/528 [======================&gt;.......] - ETA: 0s - loss: 0.3510 - mae: 0.3937\n498/528 [===========================&gt;..] - ETA: 0s - loss: 0.3386 - mae: 0.3924\n528/528 [==============================] - 0s 808us/step - loss: 0.3361 - mae: 0.3916 - val_loss: 0.3294 - val_mae: 0.3932\nEpoch 95/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.1341 - mae: 0.2701\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.2766 - mae: 0.3769\n163/528 [========&gt;.....................] - ETA: 0s - loss: 0.3525 - mae: 0.3896\n245/528 [============&gt;.................] - ETA: 0s - loss: 0.3414 - mae: 0.3843\n325/528 [=================&gt;............] - ETA: 0s - loss: 0.3530 - mae: 0.3884\n387/528 [====================&gt;.........] - ETA: 0s - loss: 0.3402 - mae: 0.3874\n467/528 [=========================&gt;....] - ETA: 0s - loss: 0.3444 - mae: 0.3898\n528/528 [==============================] - 0s 849us/step - loss: 0.3347 - mae: 0.3892 - val_loss: 0.3447 - val_mae: 0.4011\nEpoch 96/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2094 - mae: 0.3633\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2844 - mae: 0.3860\n166/528 [========&gt;.....................] - ETA: 0s - loss: 0.3072 - mae: 0.3852\n247/528 [=============&gt;................] - ETA: 0s - loss: 0.3034 - mae: 0.3863\n330/528 [=================&gt;............] - ETA: 0s - loss: 0.3333 - mae: 0.3914\n412/528 [======================&gt;.......] - ETA: 0s - loss: 0.3212 - mae: 0.3897\n492/528 [==========================&gt;...] - ETA: 0s - loss: 0.3190 - mae: 0.3902\n528/528 [==============================] - 0s 814us/step - loss: 0.3361 - mae: 0.3919 - val_loss: 0.3361 - val_mae: 0.4003\nEpoch 97/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2621 - mae: 0.3864\n 82/528 [===&gt;..........................] - ETA: 0s - loss: 0.2736 - mae: 0.3786\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.2640 - mae: 0.3777\n253/528 [=============&gt;................] - ETA: 0s - loss: 0.3098 - mae: 0.3820\n339/528 [==================&gt;...........] - ETA: 0s - loss: 0.3314 - mae: 0.3849\n424/528 [=======================&gt;......] - ETA: 0s - loss: 0.3381 - mae: 0.3882\n510/528 [===========================&gt;..] - ETA: 0s - loss: 0.3344 - mae: 0.3897\n528/528 [==============================] - 0s 790us/step - loss: 0.3370 - mae: 0.3908 - val_loss: 0.3618 - val_mae: 0.4105\nEpoch 98/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.2318 - mae: 0.3269\n 81/528 [===&gt;..........................] - ETA: 0s - loss: 0.3826 - mae: 0.3999\n164/528 [========&gt;.....................] - ETA: 0s - loss: 0.3753 - mae: 0.3947\n249/528 [=============&gt;................] - ETA: 0s - loss: 0.3321 - mae: 0.3895\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3676 - mae: 0.3925\n419/528 [======================&gt;.......] - ETA: 0s - loss: 0.3544 - mae: 0.3921\n500/528 [===========================&gt;..] - ETA: 0s - loss: 0.3396 - mae: 0.3904\n528/528 [==============================] - 0s 806us/step - loss: 0.3346 - mae: 0.3895 - val_loss: 0.3345 - val_mae: 0.3945\nEpoch 99/100\n\n  1/528 [..............................] - ETA: 0s - loss: 0.4252 - mae: 0.4196\n 80/528 [===&gt;..........................] - ETA: 0s - loss: 0.4366 - mae: 0.4108\n165/528 [========&gt;.....................] - ETA: 0s - loss: 0.3578 - mae: 0.4014\n250/528 [=============&gt;................] - ETA: 0s - loss: 0.3557 - mae: 0.3978\n333/528 [=================&gt;............] - ETA: 0s - loss: 0.3481 - mae: 0.3939\n417/528 [======================&gt;.......] - ETA: 0s - loss: 0.3448 - mae: 0.3933\n503/528 [===========================&gt;..] - ETA: 0s - loss: 0.3377 - mae: 0.3922\n528/528 [==============================] - 0s 800us/step - loss: 0.3358 - mae: 0.3918 - val_loss: 0.3743 - val_mae: 0.4392\nEpoch 100/100\n\n  1/528 [..............................] - ETA: 0s - loss: 1.2915 - mae: 0.5680\n 83/528 [===&gt;..........................] - ETA: 0s - loss: 0.3206 - mae: 0.3902\n167/528 [========&gt;.....................] - ETA: 0s - loss: 0.2968 - mae: 0.3865\n241/528 [============&gt;.................] - ETA: 0s - loss: 0.3100 - mae: 0.3850\n321/528 [=================&gt;............] - ETA: 0s - loss: 0.3429 - mae: 0.3924\n402/528 [=====================&gt;........] - ETA: 0s - loss: 0.3280 - mae: 0.3892\n486/528 [==========================&gt;...] - ETA: 0s - loss: 0.3434 - mae: 0.3914\n528/528 [==============================] - 0s 822us/step - loss: 0.3356 - mae: 0.3900 - val_loss: 0.3383 - val_mae: 0.3947\n\n\nsee code\nplot(history)\n\n\n\n\n\n\n\n\n\nWe know the three model’s performance metrics, the next question we need to answer is whether the data maintains the similar results on an out-of-sample dataset. Here we rely on Kuhn and Wickham (2022), yardstick package to compare performance between the models. It is probably a better approach to use a tidymodel’s workflow and recipes as it provides all the functions needed for preprocessing and modelling."
  },
  {
    "objectID": "posts/2023 South African Macroeconomic Database/Index.html",
    "href": "posts/2023 South African Macroeconomic Database/Index.html",
    "title": "2023 South African Macroeconomic Database",
    "section": "",
    "text": "CRAN Task Views contain important updates on packages, databases and other developments in the R community. Among the packages listed in the Time Series task view is the SAMADB R packages maintained by the Department of Economics at Stellenbosch University. The packages relies on EconData for weekly updates on South African macroeconomic data from Statistics South Africa(StatsSA) and the South African Reserve Bank (SARB).\nStatsSA and SARB are among a few governmental organisations that regularly publish data. Data collection can be a bit combersome since the data are often published in xlsx, csv or an exotic formats. In addition, the data often has multiple versions, to include, more recent data.Effectively, the package streamlines the data access via standardising,versioning and storing the data from the above mentioned institutions.\n\n\nsee code\nlapply(c(\"dplyr\",\"stringr\",\"janitor\",\"samadb\",\n         \"reactable\",\"reactablefmtr\",\"ggplot2\",\n         \"ggthemes\"),\n       require,character.only = TRUE) |&gt; \n  suppressMessages() |&gt; \n  suppressWarnings()\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] TRUE\n\n[[5]]\n[1] TRUE\n\n[[6]]\n[1] TRUE\n\n[[7]]\n[1] TRUE\n\n[[8]]\n[1] TRUE\n\n\nsee code\nextrafont::loadfonts(device = \"win\")\ntheme_set(theme_minimal())\n\n\n\n\nThe table below provides an interactive table of all the datasets available from the package. The table is derived from the sm_datasets() function, which returns a data.table object containing important such as the dataset id, the full name of the data, frequency of publication along with the number of records and series available.\n\n\nsee code\nsm_datasets() |&gt; \n  reactable(theme = espn(),\n            defaultColDef = colDef(),\n            searchable = TRUE,\n            filterable = TRUE)\n\n\n\n\nSAMADB_Datasets\n\n\nIn our walk-through, we rely on the Motor Trade sales from Statistics South Africa. The data ranges from 1998-01-01 - 2023-02-01, collected monthly. Below, we illustrade how to a straight-forward way of collecting the data from the EconData database. We specify the dsid listed in table above. Thereafter, replace variable names with their labels.\n\n\n\n\n\n\nLabelled Variables\n\n\n\nMany statistical analysis packages (SPSS,SAS and Stata etc.) utilise labels in their data analysis. This affords researchers the opportunity to encapsulate assign text labels with the associated values. In R it possible to make use of labelled vectors or factors without losing meaningful information.\n\n\n\n\nsee code\nMotor_Trade &lt;- sm_data(dsid=\"MOTOR_TRADE\")|&gt;data.frame()\n\n\nVariable_Labels &lt;- labelled::var_label(Motor_Trade)\n\nNULL -&gt; names(Variable_Labels)\nVariable_Labels &lt;- unlist(Variable_Labels)\n\nVariable_Labels &lt;- c(\"Date\",Variable_Labels)\n\nnames(Motor_Trade) &lt;- Variable_Labels\n\nMotor_Trade &lt;- Motor_Trade |&gt; \n  clean_names() |&gt; \n  labelled::remove_var_label()\n\n\nWith the data in hand, we can explore the dataset further, such as obtaining an overview of completeness(or lack thereof) of the dataset. Here, we rely on the skimr package to fulfil this task.\n\n\nsee code\nMotor_Trade |&gt;\n  skimr::skim()\n\n\n\n\n\n\nName\nMotor_Trade\n\n\nNumber of rows\n315\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nData summaryVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n1998-01-01\n2024-03-01\n2011-02-01\n315\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nworkshop_income_real_rand_millions\n92\n0.71\n2521.46\n469.64\n505\n2136.5\n2593\n2880.0\n3605\n▁▁▅▇▂\n\n\nused_vehicle_sales_real_rand_millions\n92\n0.71\n9520.31\n2855.90\n326\n7001.0\n9093\n11624.5\n16179\n▁▃▇▆▂\n\n\nnew_vehicle_sales_real_rand_millions\n92\n0.71\n12956.44\n3066.84\n1041\n10859.5\n13324\n14654.0\n19841\n▁▁▅▇▂\n\n\nincome_from_fuel_sales_real_rand_millions\n92\n0.71\n16088.20\n4627.66\n5773\n12301.0\n16483\n19293.5\n27406\n▂▃▇▅▂\n\n\ntotal_real_rand_millions_seasonally_adjusted\n0\n1.00\n42235.48\n19800.28\n9748\n25388.5\n42694\n57886.0\n80629\n▆▅▃▇▂\n\n\ntotal_real_rand_millions\n0\n1.00\n42230.63\n19880.97\n10024\n25492.5\n41314\n57749.0\n83220\n▇▆▅▇▂\n\n\nincome_from_convenient_store_sales_real_rand_millions\n92\n0.71\n1401.56\n223.26\n691\n1236.5\n1413\n1562.0\n2144\n▁▅▇▅▁\n\n\nincome_from_the_sales_of_accessories_real_rand_millions\n92\n0.71\n9898.57\n3280.47\n1902\n7224.5\n9939\n12426.0\n16876\n▂▆▆▇▂\n\n\n\n2023 Motor Trade Overview\n\n\nThe dataset contains some missing data from 1998-01-01 to 2005-08-01. Fortunately, there is a pattern in the missing values. Data was not collect for variables listed. From 2005-09-01 onward, StatsSA started collecting more detailed information about motor trade sector.\n\n\nsee code\nMotor_Trade &lt;- Motor_Trade[!is.na(Motor_Trade$income_from_fuel_sales_real_rand_million),] |&gt; \n#Timeseries Features\n    mutate(quarter = lubridate::quarter(date,type= \"year.quarter\"),\n           month = lubridate::month(date,label=TRUE,abbr=FALSE),\n           year = lubridate::year(date))\n\nrow.names(Motor_Trade) &lt;- NULL\n\n\n\n\nsee code\nMotor_Trade |&gt; \n  ggplot(aes(date,income_from_fuel_sales_real_rand_millions))+\n  geom_line()+\n  labs(title = \"2005 - 2023 Motor Trade Data\",\n       subtitle = \"Real Income From Fuel Sales Rand Millions\",\n       y= \"fuel sales (R Millions)\",\n       x = \"year\",\n       caption = \"Data Source: Krantz,S.2023.'South Africa Macroeconomic Database API'.R package version 0.2.6.\\nAvailable from: https://CRAN.R-Project.org/package=samadb'\")+\n  theme(text = element_text(family = \"IBM Plex Sans\"),\n    plot.title = element_text(face = \"bold\",hjust =0.5),\n        plot.subtitle = element_text(face = \"italic\",hjust=0.5),\n        plot.caption = element_text(size =7))\n\n\n\n\n2005 - 2023 Motor Trade Data\n\n\n\n\n\n\n\nsee code\nlibrary(forecast)\n\nFuel_Sales_Ts &lt;- ts(Motor_Trade[,c(\"income_from_fuel_sales_real_rand_millions\")],\n   start = c(2005,09,01),end = c(2023,02,01),frequency = 12)\n\nggAcf(Fuel_Sales_Ts,ci=0.95,lag.max=20)\n\n\n\n\n\n\n\n\n\nsee code\nautoplot(Fuel_Sales_Ts)+\n  autolayer(meanf(Fuel_Sales_Ts,lambda = 0,h=12),series = \"Mean\", PI=F)+\n  autolayer(rwf(Fuel_Sales_Ts,h=12,lambda =0),series= \"Naive\",PI=F)+\n  autolayer(rwf(Fuel_Sales_Ts,h=12,lambda = 0,drift=T,biasadj = T),series=\"Drift\",PI=F)+\n  ggtitle(label = \"2005 - 2024: Real Income From Fuel Sales\",\n        subtitle = \"(R) millions including forecast for 2024\")+\n  labs(caption = \"Data Source: Krantz,S.2023.'South Africa Macroeconomic Database API'.R package version 0.2.6.\\nAvailable from: https://CRAN.R-Project.org/package=samadb'\")+\n  theme(text = element_text(\"IBM Plex Sans\"),\n        plot.title = element_text(face = \"bold\",hjust=0.5),\n        plot.subtitle = element_text(face = \"italic\",hjust=0.5),\n        plot.caption = element_text(face = \"italic\",hjust=-0.01,size =6))"
  },
  {
    "objectID": "posts/2023 South African Macroeconomic Database/Index.html#available-datasets",
    "href": "posts/2023 South African Macroeconomic Database/Index.html#available-datasets",
    "title": "2023 South African Macroeconomic Database",
    "section": "",
    "text": "The table below provides an interactive table of all the datasets available from the package. The table is derived from the sm_datasets() function, which returns a data.table object containing important such as the dataset id, the full name of the data, frequency of publication along with the number of records and series available.\n\n\nsee code\nsm_datasets() |&gt; \n  reactable(theme = espn(),\n            defaultColDef = colDef(),\n            searchable = TRUE,\n            filterable = TRUE)\n\n\n\n\nSAMADB_Datasets\n\n\nIn our walk-through, we rely on the Motor Trade sales from Statistics South Africa. The data ranges from 1998-01-01 - 2023-02-01, collected monthly. Below, we illustrade how to a straight-forward way of collecting the data from the EconData database. We specify the dsid listed in table above. Thereafter, replace variable names with their labels.\n\n\n\n\n\n\nLabelled Variables\n\n\n\nMany statistical analysis packages (SPSS,SAS and Stata etc.) utilise labels in their data analysis. This affords researchers the opportunity to encapsulate assign text labels with the associated values. In R it possible to make use of labelled vectors or factors without losing meaningful information.\n\n\n\n\nsee code\nMotor_Trade &lt;- sm_data(dsid=\"MOTOR_TRADE\")|&gt;data.frame()\n\n\nVariable_Labels &lt;- labelled::var_label(Motor_Trade)\n\nNULL -&gt; names(Variable_Labels)\nVariable_Labels &lt;- unlist(Variable_Labels)\n\nVariable_Labels &lt;- c(\"Date\",Variable_Labels)\n\nnames(Motor_Trade) &lt;- Variable_Labels\n\nMotor_Trade &lt;- Motor_Trade |&gt; \n  clean_names() |&gt; \n  labelled::remove_var_label()\n\n\nWith the data in hand, we can explore the dataset further, such as obtaining an overview of completeness(or lack thereof) of the dataset. Here, we rely on the skimr package to fulfil this task.\n\n\nsee code\nMotor_Trade |&gt;\n  skimr::skim()\n\n\n\n\n\n\nName\nMotor_Trade\n\n\nNumber of rows\n315\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nData summaryVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\ndate\n0\n1\n1998-01-01\n2024-03-01\n2011-02-01\n315\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nworkshop_income_real_rand_millions\n92\n0.71\n2521.46\n469.64\n505\n2136.5\n2593\n2880.0\n3605\n▁▁▅▇▂\n\n\nused_vehicle_sales_real_rand_millions\n92\n0.71\n9520.31\n2855.90\n326\n7001.0\n9093\n11624.5\n16179\n▁▃▇▆▂\n\n\nnew_vehicle_sales_real_rand_millions\n92\n0.71\n12956.44\n3066.84\n1041\n10859.5\n13324\n14654.0\n19841\n▁▁▅▇▂\n\n\nincome_from_fuel_sales_real_rand_millions\n92\n0.71\n16088.20\n4627.66\n5773\n12301.0\n16483\n19293.5\n27406\n▂▃▇▅▂\n\n\ntotal_real_rand_millions_seasonally_adjusted\n0\n1.00\n42235.48\n19800.28\n9748\n25388.5\n42694\n57886.0\n80629\n▆▅▃▇▂\n\n\ntotal_real_rand_millions\n0\n1.00\n42230.63\n19880.97\n10024\n25492.5\n41314\n57749.0\n83220\n▇▆▅▇▂\n\n\nincome_from_convenient_store_sales_real_rand_millions\n92\n0.71\n1401.56\n223.26\n691\n1236.5\n1413\n1562.0\n2144\n▁▅▇▅▁\n\n\nincome_from_the_sales_of_accessories_real_rand_millions\n92\n0.71\n9898.57\n3280.47\n1902\n7224.5\n9939\n12426.0\n16876\n▂▆▆▇▂\n\n\n\n2023 Motor Trade Overview\n\n\nThe dataset contains some missing data from 1998-01-01 to 2005-08-01. Fortunately, there is a pattern in the missing values. Data was not collect for variables listed. From 2005-09-01 onward, StatsSA started collecting more detailed information about motor trade sector.\n\n\nsee code\nMotor_Trade &lt;- Motor_Trade[!is.na(Motor_Trade$income_from_fuel_sales_real_rand_million),] |&gt; \n#Timeseries Features\n    mutate(quarter = lubridate::quarter(date,type= \"year.quarter\"),\n           month = lubridate::month(date,label=TRUE,abbr=FALSE),\n           year = lubridate::year(date))\n\nrow.names(Motor_Trade) &lt;- NULL\n\n\n\n\nsee code\nMotor_Trade |&gt; \n  ggplot(aes(date,income_from_fuel_sales_real_rand_millions))+\n  geom_line()+\n  labs(title = \"2005 - 2023 Motor Trade Data\",\n       subtitle = \"Real Income From Fuel Sales Rand Millions\",\n       y= \"fuel sales (R Millions)\",\n       x = \"year\",\n       caption = \"Data Source: Krantz,S.2023.'South Africa Macroeconomic Database API'.R package version 0.2.6.\\nAvailable from: https://CRAN.R-Project.org/package=samadb'\")+\n  theme(text = element_text(family = \"IBM Plex Sans\"),\n    plot.title = element_text(face = \"bold\",hjust =0.5),\n        plot.subtitle = element_text(face = \"italic\",hjust=0.5),\n        plot.caption = element_text(size =7))\n\n\n\n\n2005 - 2023 Motor Trade Data\n\n\n\n\n\n\n\nsee code\nlibrary(forecast)\n\nFuel_Sales_Ts &lt;- ts(Motor_Trade[,c(\"income_from_fuel_sales_real_rand_millions\")],\n   start = c(2005,09,01),end = c(2023,02,01),frequency = 12)\n\nggAcf(Fuel_Sales_Ts,ci=0.95,lag.max=20)\n\n\n\n\n\n\n\n\n\nsee code\nautoplot(Fuel_Sales_Ts)+\n  autolayer(meanf(Fuel_Sales_Ts,lambda = 0,h=12),series = \"Mean\", PI=F)+\n  autolayer(rwf(Fuel_Sales_Ts,h=12,lambda =0),series= \"Naive\",PI=F)+\n  autolayer(rwf(Fuel_Sales_Ts,h=12,lambda = 0,drift=T,biasadj = T),series=\"Drift\",PI=F)+\n  ggtitle(label = \"2005 - 2024: Real Income From Fuel Sales\",\n        subtitle = \"(R) millions including forecast for 2024\")+\n  labs(caption = \"Data Source: Krantz,S.2023.'South Africa Macroeconomic Database API'.R package version 0.2.6.\\nAvailable from: https://CRAN.R-Project.org/package=samadb'\")+\n  theme(text = element_text(\"IBM Plex Sans\"),\n        plot.title = element_text(face = \"bold\",hjust=0.5),\n        plot.subtitle = element_text(face = \"italic\",hjust=0.5),\n        plot.caption = element_text(face = \"italic\",hjust=-0.01,size =6))"
  },
  {
    "objectID": "posts/2023 TidyTuesday Week 1/index.html",
    "href": "posts/2023 TidyTuesday Week 1/index.html",
    "title": "2023 TidyTuesday Week 1",
    "section": "",
    "text": "1 INTRODUCTION\nIt has a been more than a year since, I published a #TidyTuesday submission, a weekly, data visualisation activity featuring a varied range of datasets. For the first week of 2023, the activity encourages participants to Bring their own data. Fortunately, I have been seating on a dataset from Independent Electoral Commission of South Africa (2023) containing the 2021 Local Government Election Results. The dataset is detailed, including results down to voting station level. The IEC also provides a data dictionary along with detailed methodology on how the results can be interpreted. We aren’t here to reproduce that process (that is for another day). We simply want to enhance the visualisation of the results.\n\n\nsee code\nlapply(c(\"tidyverse\",\"janitor\",\"arrow\",\n         \"sf\",\"ggthemes\",\"showtext\",\n         \"leaflet\"),\n       require,character.only = TRUE) |&gt; \n  suppressWarnings() |&gt; \n  suppressMessages()\n\n\n[[1]]\n[1] TRUE\n\n[[2]]\n[1] TRUE\n\n[[3]]\n[1] TRUE\n\n[[4]]\n[1] TRUE\n\n[[5]]\n[1] TRUE\n\n[[6]]\n[1] TRUE\n\n[[7]]\n[1] TRUE\n\n\nsee code\nfont_add_google(\"IBM Plex Sans\")\nshowtext_auto()\n\n\n\n\n2 IMPORTANT DATA ASPECTS\nIn South Africa, the Municipal Demarcation Board (2023) , is the body responsible for the demarcation of South Africa into multiple levels such as District Municipalities, Metropolitan Municipalities, Local Municipalities and Voting Districts. In Local Government Elections, these demarcations in turn, determine seat allocation and across all types of municipalities.\nThere important nuances in respect to the Local Government Elections voting ballots; such as direct (Ward-level vote) and indirect votes(proportional representation). For purposes of this analysis, we will rely on illustrating voting outcomes at ward level. In effect, we have two datasets to work with, 2020 Municipal Demarcation Board ShapeFile and 2021 Local Government Election Results (Comma-Separated File).\nWrangling spatial data is made easy by the sf package ( Pebesma (2022) ). The voting results can be wrangled and joined to the sf object through the dplyr package ( Wickham (2022) ). Since this is R, there are a plethora of data visualisation packages to utilise as well. Here, we chiefly rely on two, ggplot2 and leaflet. The first can be used to create static maps while the latter offers a great set of tools for interactive visualisations. Below, we illustrate the process of importing that spatial data into R along with the csv of election results.\n\n\nsee code\nSA_Wards &lt;- st_read(\"./2020_Spatial_Data/SA_Wards2020.shp\")\n\n\nReading layer `SA_Wards2020' from data source \n  `C:\\Users\\Sivuyile\\Desktop\\RStudio\\2024\\2024_Personal_Site\\posts\\2023 TidyTuesday Week 1\\2020_Spatial_Data\\SA_Wards2020.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 4468 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 16.45189 ymin: -34.83417 xmax: 32.94498 ymax: -22.12503\nGeodetic CRS:  WGS 84\n\n\nsee code\nElection_Results &lt;- read_parquet(file = \"./Final_Dbs/2016 - 2021_Local_Gov_Election_Results_2022-04-27.parquet\") |&gt;\n  filter(election_year == 2021)\n\nglimpse(Election_Results)\n\n\nRows: 1,084,734\nColumns: 13\n$ source_file         &lt;chr&gt; \"./2021/EC.csv\", \"./2021/EC.csv\", \"./2021/EC.csv\",…\n$ province            &lt;chr&gt; \"Eastern Cape\", \"Eastern Cape\", \"Eastern Cape\", \"E…\n$ municipality        &lt;chr&gt; \"BUF - Buffalo City\", \"BUF - Buffalo City\", \"BUF -…\n$ ward                &lt;chr&gt; \"Ward 29200001\", \"Ward 29200001\", \"Ward 29200001\",…\n$ voting_district     &lt;dbl&gt; 10590151, 10590151, 10590151, 10590151, 10590151, …\n$ voting_station_name &lt;chr&gt; \"PEFFERVILLE CLINIC\", \"PEFFERVILLE CLINIC\", \"PEFFE…\n$ registered_voters   &lt;dbl&gt; 2724, 2724, 2724, 2724, 2724, 2724, 2724, 2724, 27…\n$ ballot_type         &lt;chr&gt; \"PR\", \"PR\", \"PR\", \"PR\", \"PR\", \"PR\", \"PR\", \"PR\", \"P…\n$ spoilt_votes        &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,…\n$ party_name          &lt;chr&gt; \"ABANTU BATHO CONGRESS\", \"AFRICA RESTORATION ALLIA…\n$ total_valid_votes   &lt;dbl&gt; 3, 6, 3, 7, 0, 286, 1, 1, 0, 0, 1, 0, 3, 615, 24, …\n$ date_generated      &lt;chr&gt; \"11/23/2021 4:17:50 PM\", \"11/23/2021 4:17:50 PM\", …\n$ election_year       &lt;dbl&gt; 2021, 2021, 2021, 2021, 2021, 2021, 2021, 2021, 20…\n\n\nAs mentioned above, we are only interested in Ward Ballot results, as a result, we filter out all indirect ballot types. Thereafter, we group the data by Province, Municipality and Ward and derive a sum of all valid votes. In other words, we exclude spoilt votes and do not consider voter turn out extra. We store the result in a data-frame called `Total _Votes`. As the name implies, the data-frame contains a sum of total valid votes per ward. Below, we add an additional variable, party-name, which helps us tally all the votes cast for a particular party or independent cast per ward. Finally, we filter for the maximum votes accumulated by the party/independent per ward.\n\n\nsee code\nTotal_Votes &lt;- Election_Results |&gt;\n  filter(ballot_type == \"Ward\") |&gt; \n  group_by(across(.cols=c(province,municipality,ward))) |&gt; \n  summarise(total_votes = sum(total_valid_votes),\n            .groups = \"drop\")\n\nWard_Results &lt;-  Total_Votes |&gt; \n  left_join(Election_Results |&gt; \n              filter(ballot_type == \"Ward\") |&gt;   \n  group_by(across(.cols=c(ward,party_name))) |&gt; \n  summarise(party_votes= sum(total_valid_votes)) |&gt;\n    filter(party_votes == max(party_votes)) |&gt; \n    ungroup()) |&gt; \n  mutate(support = 100/total_votes*party_votes)\n\nglimpse(Ward_Results)\n\n\nRows: 4,468\nColumns: 7\n$ province     &lt;chr&gt; \"Eastern Cape\", \"Eastern Cape\", \"Eastern Cape\", \"Eastern …\n$ municipality &lt;chr&gt; \"BUF - Buffalo City\", \"BUF - Buffalo City\", \"BUF - Buffal…\n$ ward         &lt;chr&gt; \"Ward 29200001\", \"Ward 29200002\", \"Ward 29200003\", \"Ward …\n$ total_votes  &lt;dbl&gt; 3803, 3299, 3326, 4524, 3506, 3421, 3446, 3917, 3359, 305…\n$ party_name   &lt;chr&gt; \"AFRICAN NATIONAL CONGRESS\", \"AFRICAN NATIONAL CONGRESS\",…\n$ party_votes  &lt;dbl&gt; 1748, 2883, 1630, 2561, 1912, 1420, 2174, 2397, 1513, 150…\n$ support      &lt;dbl&gt; 45.96371, 87.39012, 49.00782, 56.60920, 54.53508, 41.5083…\n\n\nTo finalise the ward results, the two data-frames are joined. Ultimately, we have a data-frame with the winner of the ward. To visualise the data, we join the spatial data to the ward results data-frame.\n\n\nsee code\nWard_Results &lt;- left_join(SA_Wards,Ward_Results |&gt;\n  mutate(ward = str_remove(ward,\"Ward\\\\s{1,}\")) |&gt; \n  rename(WardID = ward) |&gt; \n  select(-province))\n\n\nBefore completing our first visualisation, there are some mopping up required. These are mainly for aesthetic in nature, such as importing hex codes for each political party which largely resembles the respective party’s corporate colour and grouping colours for smaller parties (\\(parties with wards &lt; 2\\)).\n\n\nsee code\nDescriptives_Results &lt;- read_csv(file = \"./Final_Dbs/2021_Party_Results_Descriptives_2023-01-06.csv\")%&gt;% \n  sapply(.,as.character)%&gt;%\n  data.frame()\n\nDescriptives_Results$occurence &lt;- as.integer(Descriptives_Results$occurence)\n\nOther_Politics &lt;- paste(Descriptives_Results[Descriptives_Results$occurence &lt;=2,\"party_name\"],\n      collapse = \",\")\n\nWard_Results &lt;- Ward_Results |&gt;\n  mutate(party_name = case_when(party_name %in% c(\"AL JAMA-AH,KAROO GEMEENSKAP PARTY\",\"TEAM SUGAR SOUTH AFRICA\",\"UMSOBOMVU RESIDENTS ASSOCIATION\",\"ACTIONSA,AZANIA RESIDENT PARTY\",\"BREEDEVALLEI ONAFHANKLIK\",\"CAPRICORN INDEPENDENT COMMUNITY ACTIVISTS FORUM\",\"CEDERBERG FIRST RESIDENTS ASSOCIATION\",\"DIENSLEWERINGS PARTY\",\"FORUM 4 SERVICE DELIVERY\",\"INDEPENDENT SOUTH AFRICAN NATIONAL CIVIC ORGANISATION\",\"LAND PARTY,NAMAKWA CIVIC MOVEMENT\",\"PLETT DEMOCRATIC CONGRESS\",\"SIYATHEMBA COMMUNITY MOVEMENT\",\"TSOGANG CIVIC MOVEMENT,UNITED DEMOCRATIC MOVEMENT\"\n) ~ \"OTHER\",\n                                TRUE ~ party_name))\n\nWards_Plot &lt;- Ward_Results |&gt; \nggplot()+\n  geom_sf(aes(fill = party_name),colour=\"black\")+\n  scale_fill_manual(values = \n                      c(\"AFRICAN NATIONAL CONGRESS\"= \"#FFD700\",\n              \"DEMOCRATIC ALLIANCE\"= \"#00008B\",\n              \"INKATHA FREEDOM PARTY\"=\"#FFFF00\",\n              \"INDEPENDENT\"=\"#90EE90\",\n              \"ECONOMIC FREEDOM FIGHTERS\"=\"#8b0000\",\n              \"MAPSIXTEEN CIVIC MOVEMENT\"=\"#9F2B68\",\n              \"NATIONAL FREEDOM PARTY\"=\"#808080\",\n              \"VRYHEIDSFRONT PLUS\"=\"#FFA500\",\n              \"PATRIOTIC ALLIANCE\"=\"#39FF14\",\n              \"ABANTU BATHO CONGRESS\"=\"#ADD8E6\",\n              \"AFRICAN PEOPLE'S MOVEMENT\"=\"#FFFFE0\",\n              \"GOOD\"=\"#F5E236\",\n              \"INDEPENDENT CIVIC ORGANISATION OF SOUTH AFRICA\"=\"#FA1138\",\n              \"SETSOTO SERVICE DELIVERY FORUM\"=\"#A5FA11\",\n              \"AL JAMA-AH\"= \"#334A05\",\n              \"KAROO GEMEENSKAP PARTY\"=\"#5BF5A3\",\n              \"TEAM SUGAR SOUTH AFRICA\"=\"#F2FF03\",\n              \"UMSOBOMVU RESIDENTS ASSOCIATION\"=\"#141212\",\n              \"OTHER\" = \"#FFC0CB\"))+\n  labs(title = \"2021 Local Government Election Results\",\n       subtitle = \"Ballot Type (Ward): Winning Party per ward in the 2021 South African Local Government Elections.\\nThe results do not include other ballot types such as DC 40% or Proportional Representation.\",\n       caption = \"Data Source: https://www.elections.org.za/\\nPlot: Sivuyile Nzimeni(sivuyilenzimeni.netlify.app)\",\n       fill = \"Party Name\")+\n  theme_void()+\n  theme(text = element_text(\"IBM Plex Sans\"),\n        plot.title =element_text(hjust=0.5,face = \"bold\"),\n        plot.subtitle = element_text(hjust = 0.5,face = \"italic\"),\n        plot.caption = element_text(hjust=0.8,face = \"italic\"),\n        legend.position = \"bottom\")\n\nWard_Results &lt;-Ward_Results |&gt; \n  left_join(Descriptives_Results |&gt; select(-occurence))\n\nWard_Results &lt;- Ward_Results |&gt; \n  mutate(overview = paste0(\"&lt;strong&gt;\",Province,\"&lt;/strong&gt;\",\"&lt;br/&gt;\",\n                              \"&lt;strong&gt;\",Municipali,\"&lt;/strong&gt;\",\"&lt;br/&gt;\",\n                              '&lt;strong&gt;Ward ID&lt;/strong&gt;',\"&lt;br/&gt;\",WardID,\"&lt;br/&gt;\",\n                              \"&lt;strong&gt;Winner&lt;/strong&gt;:\",party_name,\"&lt;br/&gt;\",\n                              \"&lt;strong&gt;Support&lt;/strong&gt;: \",round(support,2),\"%\"),\n         colour = str_trim(colour))\n\nWard_Results &lt;- Ward_Results |&gt; \n  mutate(overview = lapply(overview,htmltools::HTML)) |&gt; \n  unnest(overview)\n\n\n\n\n3 VISUALISATION\n\n\nsee code\nWards_Plot\n\n\n\n\n\n\n\n\n\nThe resulting static visualisation illustrates that the African National Congress (ANC) won the majority of wards in South Africa followed by the Democratic Alliance (DA) in some urban areas. The visualisation above has be read in context.\n\nLand does not vote: the composition of wards is influenced by several factors such as population density, level of development, natural landscape etc. As such, it is possible to have a large ward (by land size) with minimal low density and vice versa.\nWard-Outcomes are partial: in Local Government Elections, voters have at least two ballots, direct votes and indirect votes. For Example, ActionSA obtained one ward in the 2021 LGE, they obtained more than 50 seats in the provinces where they competed.\nRigour: for a more comprehensive analysis, spatial econometrics offers a number of tools to help understand voting patterns over time. Naturally, the datasets required would need to be expanded to include Statistics South Africa (Census), previous voting patterns (IEC) and former demarcations (MDB).\n\n\n\n\n\n\n\nRendering Issue\n\n\n\nR has several packages for interactive visualisation. In the code, we attempted to use leaflet to render the interactive visualisation. The size of the data appears to be a hindrance, instead generating an error Fatal javascript OOM in Reached heap limit. Other users have experienced this issue. Follow Issue 2462 for more information and progress on the issue.\nThe rendering works locally. The script above provides the cleaning process before creating an interactive map in `leaflet` or another interactive visualisation library.\n\n\n\n\n4 SUMMARY\nIn the post, we imported a spatial data file from MDB along with election results from the IEC. Ward-Level outcomes are visualised through a choropleth map.\n\n\n\n\n\nReferences\n\nIndependent Electoral Commission of South Africa. 2023. ‘Municipal Election Results - Electoral Commission of South Africa’. https://results.elections.org.za/home/downloads/me-results.\n\n\nMunicipal Demarcation Board. 2023. ‘Municipal Demarcation Board’. https://dataportal-mdb-sa.opendata.arcgis.com/.\n\n\nPebesma, Edzer. 2022. Sf: Simple Features for r. https://CRAN.R-project.org/package=sf.\n\n\nWickham, Hadley. 2022. Tidyverse: Easily Install and Load the Tidyverse. https://CRAN.R-project.org/package=tidyverse."
  }
]